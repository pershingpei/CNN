{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR LSTM training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, labels_train = read_data(data_path=\"C:/Users/pershing/Desktop/UCI HAR Dataset/UCI HAR Dataset/train/\", split=\"train\") # train\n",
    "X_test, labels_test = read_data(data_path=\"C:/Users/pershing/Desktop/UCI HAR Dataset/UCI HAR Dataset/test/\", split=\"test\") # test\n",
    "\n",
    "# assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize\n",
    "X_train, X_test = standardize(X_train, X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train,\n",
    "                                                random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "lstm_size = 27         # 3 times the amount of channels\n",
    "lstm_layers = 2        # Number of layers\n",
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 1000\n",
    "\n",
    "# Fixed\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct inputs to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Construct the LSTM inputs and LSTM cells\n",
    "    lstm_in = tf.transpose(inputs_, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "    lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "    \n",
    "    # To cells\n",
    "    lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None) # or tf.nn.relu, tf.nn.sigmoid, tf.nn.tanh?\n",
    "    \n",
    "    # Open up the tensor into a list of seq_len pieces\n",
    "    lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define forward pass, cost function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32,\n",
    "                                                     initial_state = initial_state)\n",
    "    \n",
    "    # We only need the last output tensor to pass into a classifier\n",
    "    logits = tf.layers.dense(outputs[-1], n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost) # No grad clipping\n",
    "    \n",
    "    # Grad clipping\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate_)\n",
    "\n",
    "    gradients = train_op.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    optimizer = train_op.apply_gradients(capped_gradients)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints') == False):\n",
    "    !mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000 Iteration: 5 Train loss: 1.767469 Train acc: 0.200000\n",
      "Epoch: 1/1000 Iteration: 10 Train loss: 1.756223 Train acc: 0.205000\n",
      "Epoch: 1/1000 Iteration: 15 Train loss: 1.756073 Train acc: 0.240000\n",
      "Epoch: 2/1000 Iteration: 20 Train loss: 1.737835 Train acc: 0.260000\n",
      "Epoch: 2/1000 Iteration: 25 Train loss: 1.733431 Train acc: 0.231667\n",
      "Epoch: 2/1000 Iteration: 25 Validation loss: 1.721587 Validation acc: 0.342778\n",
      "Epoch: 3/1000 Iteration: 30 Train loss: 1.737162 Train acc: 0.250000\n",
      "Epoch: 3/1000 Iteration: 35 Train loss: 1.730019 Train acc: 0.273333\n",
      "Epoch: 4/1000 Iteration: 40 Train loss: 1.714589 Train acc: 0.325000\n",
      "Epoch: 4/1000 Iteration: 45 Train loss: 1.713629 Train acc: 0.300000\n",
      "Epoch: 5/1000 Iteration: 50 Train loss: 1.683239 Train acc: 0.376667\n",
      "Epoch: 5/1000 Iteration: 50 Validation loss: 1.670006 Validation acc: 0.378889\n",
      "Epoch: 6/1000 Iteration: 55 Train loss: 1.676913 Train acc: 0.328333\n",
      "Epoch: 6/1000 Iteration: 60 Train loss: 1.653180 Train acc: 0.346667\n",
      "Epoch: 7/1000 Iteration: 65 Train loss: 1.653355 Train acc: 0.366667\n",
      "Epoch: 7/1000 Iteration: 70 Train loss: 1.651355 Train acc: 0.360000\n",
      "Epoch: 8/1000 Iteration: 75 Train loss: 1.652854 Train acc: 0.370000\n",
      "Epoch: 8/1000 Iteration: 75 Validation loss: 1.618451 Validation acc: 0.406111\n",
      "Epoch: 8/1000 Iteration: 80 Train loss: 1.641519 Train acc: 0.368333\n",
      "Epoch: 9/1000 Iteration: 85 Train loss: 1.651830 Train acc: 0.335000\n",
      "Epoch: 9/1000 Iteration: 90 Train loss: 1.639820 Train acc: 0.321667\n",
      "Epoch: 10/1000 Iteration: 95 Train loss: 1.596407 Train acc: 0.398333\n",
      "Epoch: 11/1000 Iteration: 100 Train loss: 1.597203 Train acc: 0.378333\n",
      "Epoch: 11/1000 Iteration: 100 Validation loss: 1.566379 Validation acc: 0.437222\n",
      "Epoch: 11/1000 Iteration: 105 Train loss: 1.563675 Train acc: 0.396667\n",
      "Epoch: 12/1000 Iteration: 110 Train loss: 1.544266 Train acc: 0.400000\n",
      "Epoch: 12/1000 Iteration: 115 Train loss: 1.567773 Train acc: 0.386667\n",
      "Epoch: 13/1000 Iteration: 120 Train loss: 1.574795 Train acc: 0.378333\n",
      "Epoch: 13/1000 Iteration: 125 Train loss: 1.556497 Train acc: 0.426667\n",
      "Epoch: 13/1000 Iteration: 125 Validation loss: 1.514960 Validation acc: 0.466667\n",
      "Epoch: 14/1000 Iteration: 130 Train loss: 1.550557 Train acc: 0.418333\n",
      "Epoch: 14/1000 Iteration: 135 Train loss: 1.557156 Train acc: 0.380000\n",
      "Epoch: 15/1000 Iteration: 140 Train loss: 1.490329 Train acc: 0.426667\n",
      "Epoch: 16/1000 Iteration: 145 Train loss: 1.512414 Train acc: 0.415000\n",
      "Epoch: 16/1000 Iteration: 150 Train loss: 1.475333 Train acc: 0.455000\n",
      "Epoch: 16/1000 Iteration: 150 Validation loss: 1.466499 Validation acc: 0.491667\n",
      "Epoch: 17/1000 Iteration: 155 Train loss: 1.465281 Train acc: 0.443333\n",
      "Epoch: 17/1000 Iteration: 160 Train loss: 1.488558 Train acc: 0.431667\n",
      "Epoch: 18/1000 Iteration: 165 Train loss: 1.499500 Train acc: 0.411667\n",
      "Epoch: 18/1000 Iteration: 170 Train loss: 1.480747 Train acc: 0.440000\n",
      "Epoch: 19/1000 Iteration: 175 Train loss: 1.483718 Train acc: 0.430000\n",
      "Epoch: 19/1000 Iteration: 175 Validation loss: 1.422435 Validation acc: 0.519444\n",
      "Epoch: 19/1000 Iteration: 180 Train loss: 1.493726 Train acc: 0.393333\n",
      "Epoch: 20/1000 Iteration: 185 Train loss: 1.421969 Train acc: 0.478333\n",
      "Epoch: 21/1000 Iteration: 190 Train loss: 1.443815 Train acc: 0.433333\n",
      "Epoch: 21/1000 Iteration: 195 Train loss: 1.414867 Train acc: 0.460000\n",
      "Epoch: 22/1000 Iteration: 200 Train loss: 1.397360 Train acc: 0.481667\n",
      "Epoch: 22/1000 Iteration: 200 Validation loss: 1.380991 Validation acc: 0.551111\n",
      "Epoch: 22/1000 Iteration: 205 Train loss: 1.422821 Train acc: 0.470000\n",
      "Epoch: 23/1000 Iteration: 210 Train loss: 1.431180 Train acc: 0.453333\n",
      "Epoch: 23/1000 Iteration: 215 Train loss: 1.421586 Train acc: 0.466667\n",
      "Epoch: 24/1000 Iteration: 220 Train loss: 1.428618 Train acc: 0.461667\n",
      "Epoch: 24/1000 Iteration: 225 Train loss: 1.424184 Train acc: 0.458333\n",
      "Epoch: 24/1000 Iteration: 225 Validation loss: 1.338129 Validation acc: 0.576667\n",
      "Epoch: 25/1000 Iteration: 230 Train loss: 1.361646 Train acc: 0.498333\n",
      "Epoch: 26/1000 Iteration: 235 Train loss: 1.363436 Train acc: 0.511667\n",
      "Epoch: 26/1000 Iteration: 240 Train loss: 1.359766 Train acc: 0.501667\n",
      "Epoch: 27/1000 Iteration: 245 Train loss: 1.330769 Train acc: 0.540000\n",
      "Epoch: 27/1000 Iteration: 250 Train loss: 1.343550 Train acc: 0.531667\n",
      "Epoch: 27/1000 Iteration: 250 Validation loss: 1.287590 Validation acc: 0.615000\n",
      "Epoch: 28/1000 Iteration: 255 Train loss: 1.348275 Train acc: 0.518333\n",
      "Epoch: 28/1000 Iteration: 260 Train loss: 1.336933 Train acc: 0.558333\n",
      "Epoch: 29/1000 Iteration: 265 Train loss: 1.345228 Train acc: 0.523333\n",
      "Epoch: 29/1000 Iteration: 270 Train loss: 1.316913 Train acc: 0.556667\n",
      "Epoch: 30/1000 Iteration: 275 Train loss: 1.260267 Train acc: 0.575000\n",
      "Epoch: 30/1000 Iteration: 275 Validation loss: 1.223960 Validation acc: 0.669445\n",
      "Epoch: 31/1000 Iteration: 280 Train loss: 1.288542 Train acc: 0.558333\n",
      "Epoch: 31/1000 Iteration: 285 Train loss: 1.234882 Train acc: 0.603333\n",
      "Epoch: 32/1000 Iteration: 290 Train loss: 1.223390 Train acc: 0.591667\n",
      "Epoch: 32/1000 Iteration: 295 Train loss: 1.241483 Train acc: 0.570000\n",
      "Epoch: 33/1000 Iteration: 300 Train loss: 1.239831 Train acc: 0.570000\n",
      "Epoch: 33/1000 Iteration: 300 Validation loss: 1.148689 Validation acc: 0.683333\n",
      "Epoch: 33/1000 Iteration: 305 Train loss: 1.216945 Train acc: 0.593333\n",
      "Epoch: 34/1000 Iteration: 310 Train loss: 1.212547 Train acc: 0.593333\n",
      "Epoch: 34/1000 Iteration: 315 Train loss: 1.187271 Train acc: 0.608333\n",
      "Epoch: 35/1000 Iteration: 320 Train loss: 1.144893 Train acc: 0.621667\n",
      "Epoch: 36/1000 Iteration: 325 Train loss: 1.145848 Train acc: 0.628333\n",
      "Epoch: 36/1000 Iteration: 325 Validation loss: 1.071501 Validation acc: 0.675000\n",
      "Epoch: 36/1000 Iteration: 330 Train loss: 1.098195 Train acc: 0.636667\n",
      "Epoch: 37/1000 Iteration: 335 Train loss: 1.111651 Train acc: 0.613333\n",
      "Epoch: 37/1000 Iteration: 340 Train loss: 1.127582 Train acc: 0.616667\n",
      "Epoch: 38/1000 Iteration: 345 Train loss: 1.115027 Train acc: 0.616667\n",
      "Epoch: 38/1000 Iteration: 350 Train loss: 1.081309 Train acc: 0.661667\n",
      "Epoch: 38/1000 Iteration: 350 Validation loss: 1.004184 Validation acc: 0.673333\n",
      "Epoch: 39/1000 Iteration: 355 Train loss: 1.096796 Train acc: 0.613333\n",
      "Epoch: 39/1000 Iteration: 360 Train loss: 1.095314 Train acc: 0.608333\n",
      "Epoch: 40/1000 Iteration: 365 Train loss: 1.037908 Train acc: 0.630000\n",
      "Epoch: 41/1000 Iteration: 370 Train loss: 1.042461 Train acc: 0.631667\n",
      "Epoch: 41/1000 Iteration: 375 Train loss: 1.002315 Train acc: 0.648333\n",
      "Epoch: 41/1000 Iteration: 375 Validation loss: 0.947440 Validation acc: 0.692778\n",
      "Epoch: 42/1000 Iteration: 380 Train loss: 1.016705 Train acc: 0.623333\n",
      "Epoch: 42/1000 Iteration: 385 Train loss: 1.020789 Train acc: 0.610000\n",
      "Epoch: 43/1000 Iteration: 390 Train loss: 1.036708 Train acc: 0.610000\n",
      "Epoch: 43/1000 Iteration: 395 Train loss: 0.997638 Train acc: 0.635000\n",
      "Epoch: 44/1000 Iteration: 400 Train loss: 1.023132 Train acc: 0.608333\n",
      "Epoch: 44/1000 Iteration: 400 Validation loss: 0.899330 Validation acc: 0.698889\n",
      "Epoch: 44/1000 Iteration: 405 Train loss: 0.976529 Train acc: 0.658333\n",
      "Epoch: 45/1000 Iteration: 410 Train loss: 0.958513 Train acc: 0.651667\n",
      "Epoch: 46/1000 Iteration: 415 Train loss: 0.955184 Train acc: 0.631667\n",
      "Epoch: 46/1000 Iteration: 420 Train loss: 0.912806 Train acc: 0.680000\n",
      "Epoch: 47/1000 Iteration: 425 Train loss: 0.957532 Train acc: 0.643333\n",
      "Epoch: 47/1000 Iteration: 425 Validation loss: 0.858847 Validation acc: 0.706667\n",
      "Epoch: 47/1000 Iteration: 430 Train loss: 0.942178 Train acc: 0.636667\n",
      "Epoch: 48/1000 Iteration: 435 Train loss: 0.977314 Train acc: 0.621667\n",
      "Epoch: 48/1000 Iteration: 440 Train loss: 0.914527 Train acc: 0.668333\n",
      "Epoch: 49/1000 Iteration: 445 Train loss: 0.940430 Train acc: 0.625000\n",
      "Epoch: 49/1000 Iteration: 450 Train loss: 0.936958 Train acc: 0.651667\n",
      "Epoch: 49/1000 Iteration: 450 Validation loss: 0.824553 Validation acc: 0.715000\n",
      "Epoch: 50/1000 Iteration: 455 Train loss: 0.895565 Train acc: 0.643333\n",
      "Epoch: 51/1000 Iteration: 460 Train loss: 0.887210 Train acc: 0.681667\n",
      "Epoch: 51/1000 Iteration: 465 Train loss: 0.862063 Train acc: 0.695000\n",
      "Epoch: 52/1000 Iteration: 470 Train loss: 0.879306 Train acc: 0.663333\n",
      "Epoch: 52/1000 Iteration: 475 Train loss: 0.901705 Train acc: 0.656667\n",
      "Epoch: 52/1000 Iteration: 475 Validation loss: 0.795329 Validation acc: 0.721111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/1000 Iteration: 480 Train loss: 0.885078 Train acc: 0.678333\n",
      "Epoch: 53/1000 Iteration: 485 Train loss: 0.896425 Train acc: 0.646667\n",
      "Epoch: 54/1000 Iteration: 490 Train loss: 0.896924 Train acc: 0.640000\n",
      "Epoch: 54/1000 Iteration: 495 Train loss: 0.865573 Train acc: 0.670000\n",
      "Epoch: 55/1000 Iteration: 500 Train loss: 0.867245 Train acc: 0.645000\n",
      "Epoch: 55/1000 Iteration: 500 Validation loss: 0.767767 Validation acc: 0.722778\n",
      "Epoch: 56/1000 Iteration: 505 Train loss: 0.855851 Train acc: 0.671667\n",
      "Epoch: 56/1000 Iteration: 510 Train loss: 0.804948 Train acc: 0.696667\n",
      "Epoch: 57/1000 Iteration: 515 Train loss: 0.838512 Train acc: 0.661667\n",
      "Epoch: 57/1000 Iteration: 520 Train loss: 0.838546 Train acc: 0.686667\n",
      "Epoch: 58/1000 Iteration: 525 Train loss: 0.886293 Train acc: 0.655000\n",
      "Epoch: 58/1000 Iteration: 525 Validation loss: 0.742054 Validation acc: 0.734444\n",
      "Epoch: 58/1000 Iteration: 530 Train loss: 0.832618 Train acc: 0.653333\n",
      "Epoch: 59/1000 Iteration: 535 Train loss: 0.854649 Train acc: 0.660000\n",
      "Epoch: 59/1000 Iteration: 540 Train loss: 0.830454 Train acc: 0.666667\n",
      "Epoch: 60/1000 Iteration: 545 Train loss: 0.815720 Train acc: 0.676667\n",
      "Epoch: 61/1000 Iteration: 550 Train loss: 0.803977 Train acc: 0.690000\n",
      "Epoch: 61/1000 Iteration: 550 Validation loss: 0.717673 Validation acc: 0.748889\n",
      "Epoch: 61/1000 Iteration: 555 Train loss: 0.766765 Train acc: 0.695000\n",
      "Epoch: 62/1000 Iteration: 560 Train loss: 0.838687 Train acc: 0.658333\n",
      "Epoch: 62/1000 Iteration: 565 Train loss: 0.803874 Train acc: 0.675000\n",
      "Epoch: 63/1000 Iteration: 570 Train loss: 0.809398 Train acc: 0.698333\n",
      "Epoch: 63/1000 Iteration: 575 Train loss: 0.779563 Train acc: 0.696667\n",
      "Epoch: 63/1000 Iteration: 575 Validation loss: 0.695834 Validation acc: 0.764444\n",
      "Epoch: 64/1000 Iteration: 580 Train loss: 0.800938 Train acc: 0.690000\n",
      "Epoch: 64/1000 Iteration: 585 Train loss: 0.789394 Train acc: 0.690000\n",
      "Epoch: 65/1000 Iteration: 590 Train loss: 0.789063 Train acc: 0.708333\n",
      "Epoch: 66/1000 Iteration: 595 Train loss: 0.751573 Train acc: 0.708333\n",
      "Epoch: 66/1000 Iteration: 600 Train loss: 0.732290 Train acc: 0.710000\n",
      "Epoch: 66/1000 Iteration: 600 Validation loss: 0.670503 Validation acc: 0.781111\n",
      "Epoch: 67/1000 Iteration: 605 Train loss: 0.753214 Train acc: 0.731667\n",
      "Epoch: 67/1000 Iteration: 610 Train loss: 0.770705 Train acc: 0.688333\n",
      "Epoch: 68/1000 Iteration: 615 Train loss: 0.799057 Train acc: 0.693333\n",
      "Epoch: 68/1000 Iteration: 620 Train loss: 0.741146 Train acc: 0.705000\n",
      "Epoch: 69/1000 Iteration: 625 Train loss: 0.772471 Train acc: 0.698333\n",
      "Epoch: 69/1000 Iteration: 625 Validation loss: 0.646066 Validation acc: 0.795556\n",
      "Epoch: 69/1000 Iteration: 630 Train loss: 0.758730 Train acc: 0.690000\n",
      "Epoch: 70/1000 Iteration: 635 Train loss: 0.744219 Train acc: 0.703333\n",
      "Epoch: 71/1000 Iteration: 640 Train loss: 0.734273 Train acc: 0.736667\n",
      "Epoch: 71/1000 Iteration: 645 Train loss: 0.662559 Train acc: 0.765000\n",
      "Epoch: 72/1000 Iteration: 650 Train loss: 0.752084 Train acc: 0.703333\n",
      "Epoch: 72/1000 Iteration: 650 Validation loss: 0.620794 Validation acc: 0.804444\n",
      "Epoch: 72/1000 Iteration: 655 Train loss: 0.724971 Train acc: 0.728333\n",
      "Epoch: 73/1000 Iteration: 660 Train loss: 0.746762 Train acc: 0.708333\n",
      "Epoch: 73/1000 Iteration: 665 Train loss: 0.712165 Train acc: 0.738333\n",
      "Epoch: 74/1000 Iteration: 670 Train loss: 0.729873 Train acc: 0.728333\n",
      "Epoch: 74/1000 Iteration: 675 Train loss: 0.731230 Train acc: 0.720000\n",
      "Epoch: 74/1000 Iteration: 675 Validation loss: 0.593569 Validation acc: 0.811667\n",
      "Epoch: 75/1000 Iteration: 680 Train loss: 0.681464 Train acc: 0.765000\n",
      "Epoch: 76/1000 Iteration: 685 Train loss: 0.671763 Train acc: 0.758333\n",
      "Epoch: 76/1000 Iteration: 690 Train loss: 0.655872 Train acc: 0.740000\n",
      "Epoch: 77/1000 Iteration: 695 Train loss: 0.688776 Train acc: 0.733333\n",
      "Epoch: 77/1000 Iteration: 700 Train loss: 0.675253 Train acc: 0.756667\n",
      "Epoch: 77/1000 Iteration: 700 Validation loss: 0.566097 Validation acc: 0.824444\n",
      "Epoch: 78/1000 Iteration: 705 Train loss: 0.703455 Train acc: 0.770000\n",
      "Epoch: 78/1000 Iteration: 710 Train loss: 0.645562 Train acc: 0.758333\n",
      "Epoch: 79/1000 Iteration: 715 Train loss: 0.688455 Train acc: 0.735000\n",
      "Epoch: 79/1000 Iteration: 720 Train loss: 0.644508 Train acc: 0.775000\n",
      "Epoch: 80/1000 Iteration: 725 Train loss: 0.654765 Train acc: 0.766667\n",
      "Epoch: 80/1000 Iteration: 725 Validation loss: 0.540342 Validation acc: 0.820000\n",
      "Epoch: 81/1000 Iteration: 730 Train loss: 0.647491 Train acc: 0.756667\n",
      "Epoch: 81/1000 Iteration: 735 Train loss: 0.609170 Train acc: 0.776667\n",
      "Epoch: 82/1000 Iteration: 740 Train loss: 0.642238 Train acc: 0.758333\n",
      "Epoch: 82/1000 Iteration: 745 Train loss: 0.652021 Train acc: 0.758333\n",
      "Epoch: 83/1000 Iteration: 750 Train loss: 0.643563 Train acc: 0.761667\n",
      "Epoch: 83/1000 Iteration: 750 Validation loss: 0.515480 Validation acc: 0.830555\n",
      "Epoch: 83/1000 Iteration: 755 Train loss: 0.588936 Train acc: 0.793333\n",
      "Epoch: 84/1000 Iteration: 760 Train loss: 0.660468 Train acc: 0.741667\n",
      "Epoch: 84/1000 Iteration: 765 Train loss: 0.605986 Train acc: 0.756667\n",
      "Epoch: 85/1000 Iteration: 770 Train loss: 0.584473 Train acc: 0.778333\n",
      "Epoch: 86/1000 Iteration: 775 Train loss: 0.613343 Train acc: 0.755000\n",
      "Epoch: 86/1000 Iteration: 775 Validation loss: 0.493852 Validation acc: 0.832778\n",
      "Epoch: 86/1000 Iteration: 780 Train loss: 0.573503 Train acc: 0.790000\n",
      "Epoch: 87/1000 Iteration: 785 Train loss: 0.613386 Train acc: 0.783333\n",
      "Epoch: 87/1000 Iteration: 790 Train loss: 0.602538 Train acc: 0.781667\n",
      "Epoch: 88/1000 Iteration: 795 Train loss: 0.576317 Train acc: 0.788333\n",
      "Epoch: 88/1000 Iteration: 800 Train loss: 0.584739 Train acc: 0.788333\n",
      "Epoch: 88/1000 Iteration: 800 Validation loss: 0.476186 Validation acc: 0.840000\n",
      "Epoch: 89/1000 Iteration: 805 Train loss: 0.634821 Train acc: 0.756667\n",
      "Epoch: 89/1000 Iteration: 810 Train loss: 0.609691 Train acc: 0.761667\n",
      "Epoch: 90/1000 Iteration: 815 Train loss: 0.556851 Train acc: 0.790000\n",
      "Epoch: 91/1000 Iteration: 820 Train loss: 0.569296 Train acc: 0.795000\n",
      "Epoch: 91/1000 Iteration: 825 Train loss: 0.539277 Train acc: 0.806667\n",
      "Epoch: 91/1000 Iteration: 825 Validation loss: 0.459245 Validation acc: 0.848333\n",
      "Epoch: 92/1000 Iteration: 830 Train loss: 0.581156 Train acc: 0.786667\n",
      "Epoch: 92/1000 Iteration: 835 Train loss: 0.539239 Train acc: 0.815000\n",
      "Epoch: 93/1000 Iteration: 840 Train loss: 0.571036 Train acc: 0.798333\n",
      "Epoch: 93/1000 Iteration: 845 Train loss: 0.561192 Train acc: 0.801667\n",
      "Epoch: 94/1000 Iteration: 850 Train loss: 0.574730 Train acc: 0.800000\n",
      "Epoch: 94/1000 Iteration: 850 Validation loss: 0.444553 Validation acc: 0.861667\n",
      "Epoch: 94/1000 Iteration: 855 Train loss: 0.553936 Train acc: 0.820000\n",
      "Epoch: 95/1000 Iteration: 860 Train loss: 0.531471 Train acc: 0.820000\n",
      "Epoch: 96/1000 Iteration: 865 Train loss: 0.534559 Train acc: 0.813333\n",
      "Epoch: 96/1000 Iteration: 870 Train loss: 0.498004 Train acc: 0.836667\n",
      "Epoch: 97/1000 Iteration: 875 Train loss: 0.517173 Train acc: 0.835000\n",
      "Epoch: 97/1000 Iteration: 875 Validation loss: 0.432559 Validation acc: 0.868889\n",
      "Epoch: 97/1000 Iteration: 880 Train loss: 0.501282 Train acc: 0.838333\n",
      "Epoch: 98/1000 Iteration: 885 Train loss: 0.530909 Train acc: 0.813333\n",
      "Epoch: 98/1000 Iteration: 890 Train loss: 0.523160 Train acc: 0.825000\n",
      "Epoch: 99/1000 Iteration: 895 Train loss: 0.577971 Train acc: 0.788333\n",
      "Epoch: 99/1000 Iteration: 900 Train loss: 0.540736 Train acc: 0.808333\n",
      "Epoch: 99/1000 Iteration: 900 Validation loss: 0.419773 Validation acc: 0.875556\n",
      "Epoch: 100/1000 Iteration: 905 Train loss: 0.511613 Train acc: 0.835000\n",
      "Epoch: 101/1000 Iteration: 910 Train loss: 0.504058 Train acc: 0.815000\n",
      "Epoch: 101/1000 Iteration: 915 Train loss: 0.478003 Train acc: 0.826667\n",
      "Epoch: 102/1000 Iteration: 920 Train loss: 0.514963 Train acc: 0.801667\n",
      "Epoch: 102/1000 Iteration: 925 Train loss: 0.494239 Train acc: 0.821667\n",
      "Epoch: 102/1000 Iteration: 925 Validation loss: 0.408336 Validation acc: 0.884444\n",
      "Epoch: 103/1000 Iteration: 930 Train loss: 0.518861 Train acc: 0.808333\n",
      "Epoch: 103/1000 Iteration: 935 Train loss: 0.504664 Train acc: 0.836667\n",
      "Epoch: 104/1000 Iteration: 940 Train loss: 0.554072 Train acc: 0.791667\n",
      "Epoch: 104/1000 Iteration: 945 Train loss: 0.524882 Train acc: 0.828333\n",
      "Epoch: 105/1000 Iteration: 950 Train loss: 0.497634 Train acc: 0.825000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105/1000 Iteration: 950 Validation loss: 0.397472 Validation acc: 0.885000\n",
      "Epoch: 106/1000 Iteration: 955 Train loss: 0.491568 Train acc: 0.818333\n",
      "Epoch: 106/1000 Iteration: 960 Train loss: 0.464948 Train acc: 0.823333\n",
      "Epoch: 107/1000 Iteration: 965 Train loss: 0.478333 Train acc: 0.846667\n",
      "Epoch: 107/1000 Iteration: 970 Train loss: 0.459288 Train acc: 0.836667\n",
      "Epoch: 108/1000 Iteration: 975 Train loss: 0.511301 Train acc: 0.840000\n",
      "Epoch: 108/1000 Iteration: 975 Validation loss: 0.384261 Validation acc: 0.895000\n",
      "Epoch: 108/1000 Iteration: 980 Train loss: 0.461305 Train acc: 0.861667\n",
      "Epoch: 109/1000 Iteration: 985 Train loss: 0.521190 Train acc: 0.815000\n",
      "Epoch: 109/1000 Iteration: 990 Train loss: 0.502866 Train acc: 0.820000\n",
      "Epoch: 110/1000 Iteration: 995 Train loss: 0.484156 Train acc: 0.823333\n",
      "Epoch: 111/1000 Iteration: 1000 Train loss: 0.483702 Train acc: 0.833333\n",
      "Epoch: 111/1000 Iteration: 1000 Validation loss: 0.372711 Validation acc: 0.901111\n",
      "Epoch: 111/1000 Iteration: 1005 Train loss: 0.461134 Train acc: 0.830000\n",
      "Epoch: 112/1000 Iteration: 1010 Train loss: 0.450028 Train acc: 0.840000\n",
      "Epoch: 112/1000 Iteration: 1015 Train loss: 0.459517 Train acc: 0.850000\n",
      "Epoch: 113/1000 Iteration: 1020 Train loss: 0.467453 Train acc: 0.848333\n",
      "Epoch: 113/1000 Iteration: 1025 Train loss: 0.464362 Train acc: 0.841667\n",
      "Epoch: 113/1000 Iteration: 1025 Validation loss: 0.360299 Validation acc: 0.903889\n",
      "Epoch: 114/1000 Iteration: 1030 Train loss: 0.483352 Train acc: 0.853333\n",
      "Epoch: 114/1000 Iteration: 1035 Train loss: 0.446537 Train acc: 0.865000\n",
      "Epoch: 115/1000 Iteration: 1040 Train loss: 0.458172 Train acc: 0.840000\n",
      "Epoch: 116/1000 Iteration: 1045 Train loss: 0.440894 Train acc: 0.865000\n",
      "Epoch: 116/1000 Iteration: 1050 Train loss: 0.400306 Train acc: 0.893333\n",
      "Epoch: 116/1000 Iteration: 1050 Validation loss: 0.346459 Validation acc: 0.917222\n",
      "Epoch: 117/1000 Iteration: 1055 Train loss: 0.433748 Train acc: 0.873333\n",
      "Epoch: 117/1000 Iteration: 1060 Train loss: 0.427550 Train acc: 0.856667\n",
      "Epoch: 118/1000 Iteration: 1065 Train loss: 0.455754 Train acc: 0.878333\n",
      "Epoch: 118/1000 Iteration: 1070 Train loss: 0.419738 Train acc: 0.878333\n",
      "Epoch: 119/1000 Iteration: 1075 Train loss: 0.462978 Train acc: 0.846667\n",
      "Epoch: 119/1000 Iteration: 1075 Validation loss: 0.333190 Validation acc: 0.921667\n",
      "Epoch: 119/1000 Iteration: 1080 Train loss: 0.451868 Train acc: 0.866667\n",
      "Epoch: 120/1000 Iteration: 1085 Train loss: 0.418318 Train acc: 0.866667\n",
      "Epoch: 121/1000 Iteration: 1090 Train loss: 0.418676 Train acc: 0.875000\n",
      "Epoch: 121/1000 Iteration: 1095 Train loss: 0.406641 Train acc: 0.883333\n",
      "Epoch: 122/1000 Iteration: 1100 Train loss: 0.404889 Train acc: 0.881667\n",
      "Epoch: 122/1000 Iteration: 1100 Validation loss: 0.319074 Validation acc: 0.926667\n",
      "Epoch: 122/1000 Iteration: 1105 Train loss: 0.402429 Train acc: 0.870000\n",
      "Epoch: 123/1000 Iteration: 1110 Train loss: 0.406609 Train acc: 0.881667\n",
      "Epoch: 123/1000 Iteration: 1115 Train loss: 0.400188 Train acc: 0.896667\n",
      "Epoch: 124/1000 Iteration: 1120 Train loss: 0.448602 Train acc: 0.855000\n",
      "Epoch: 124/1000 Iteration: 1125 Train loss: 0.400629 Train acc: 0.875000\n",
      "Epoch: 124/1000 Iteration: 1125 Validation loss: 0.307277 Validation acc: 0.928889\n",
      "Epoch: 125/1000 Iteration: 1130 Train loss: 0.390629 Train acc: 0.898333\n",
      "Epoch: 126/1000 Iteration: 1135 Train loss: 0.391673 Train acc: 0.881667\n",
      "Epoch: 126/1000 Iteration: 1140 Train loss: 0.377174 Train acc: 0.893333\n",
      "Epoch: 127/1000 Iteration: 1145 Train loss: 0.383604 Train acc: 0.895000\n",
      "Epoch: 127/1000 Iteration: 1150 Train loss: 0.386194 Train acc: 0.888333\n",
      "Epoch: 127/1000 Iteration: 1150 Validation loss: 0.296749 Validation acc: 0.930556\n",
      "Epoch: 128/1000 Iteration: 1155 Train loss: 0.408574 Train acc: 0.890000\n",
      "Epoch: 128/1000 Iteration: 1160 Train loss: 0.370635 Train acc: 0.918333\n",
      "Epoch: 129/1000 Iteration: 1165 Train loss: 0.428898 Train acc: 0.873333\n",
      "Epoch: 129/1000 Iteration: 1170 Train loss: 0.363913 Train acc: 0.915000\n",
      "Epoch: 130/1000 Iteration: 1175 Train loss: 0.381341 Train acc: 0.888333\n",
      "Epoch: 130/1000 Iteration: 1175 Validation loss: 0.285966 Validation acc: 0.934444\n",
      "Epoch: 131/1000 Iteration: 1180 Train loss: 0.372131 Train acc: 0.893333\n",
      "Epoch: 131/1000 Iteration: 1185 Train loss: 0.338502 Train acc: 0.921667\n",
      "Epoch: 132/1000 Iteration: 1190 Train loss: 0.362900 Train acc: 0.903333\n",
      "Epoch: 132/1000 Iteration: 1195 Train loss: 0.352234 Train acc: 0.911667\n",
      "Epoch: 133/1000 Iteration: 1200 Train loss: 0.388529 Train acc: 0.905000\n",
      "Epoch: 133/1000 Iteration: 1200 Validation loss: 0.272592 Validation acc: 0.939444\n",
      "Epoch: 133/1000 Iteration: 1205 Train loss: 0.343404 Train acc: 0.918333\n",
      "Epoch: 134/1000 Iteration: 1210 Train loss: 0.411520 Train acc: 0.878333\n",
      "Epoch: 134/1000 Iteration: 1215 Train loss: 0.388753 Train acc: 0.903333\n",
      "Epoch: 135/1000 Iteration: 1220 Train loss: 0.358568 Train acc: 0.895000\n",
      "Epoch: 136/1000 Iteration: 1225 Train loss: 0.352424 Train acc: 0.896667\n",
      "Epoch: 136/1000 Iteration: 1225 Validation loss: 0.263816 Validation acc: 0.941111\n",
      "Epoch: 136/1000 Iteration: 1230 Train loss: 0.313272 Train acc: 0.923333\n",
      "Epoch: 137/1000 Iteration: 1235 Train loss: 0.340885 Train acc: 0.916667\n",
      "Epoch: 137/1000 Iteration: 1240 Train loss: 0.338694 Train acc: 0.926667\n",
      "Epoch: 138/1000 Iteration: 1245 Train loss: 0.376423 Train acc: 0.898333\n",
      "Epoch: 138/1000 Iteration: 1250 Train loss: 0.320094 Train acc: 0.925000\n",
      "Epoch: 138/1000 Iteration: 1250 Validation loss: 0.256427 Validation acc: 0.940556\n",
      "Epoch: 139/1000 Iteration: 1255 Train loss: 0.379905 Train acc: 0.893333\n",
      "Epoch: 139/1000 Iteration: 1260 Train loss: 0.358442 Train acc: 0.911667\n",
      "Epoch: 140/1000 Iteration: 1265 Train loss: 0.339461 Train acc: 0.913333\n",
      "Epoch: 141/1000 Iteration: 1270 Train loss: 0.337132 Train acc: 0.928333\n",
      "Epoch: 141/1000 Iteration: 1275 Train loss: 0.330750 Train acc: 0.918333\n",
      "Epoch: 141/1000 Iteration: 1275 Validation loss: 0.244198 Validation acc: 0.946111\n",
      "Epoch: 142/1000 Iteration: 1280 Train loss: 0.341836 Train acc: 0.921667\n",
      "Epoch: 142/1000 Iteration: 1285 Train loss: 0.335814 Train acc: 0.920000\n",
      "Epoch: 143/1000 Iteration: 1290 Train loss: 0.338674 Train acc: 0.905000\n",
      "Epoch: 143/1000 Iteration: 1295 Train loss: 0.308893 Train acc: 0.931667\n",
      "Epoch: 144/1000 Iteration: 1300 Train loss: 0.370369 Train acc: 0.895000\n",
      "Epoch: 144/1000 Iteration: 1300 Validation loss: 0.237156 Validation acc: 0.947222\n",
      "Epoch: 144/1000 Iteration: 1305 Train loss: 0.326505 Train acc: 0.916667\n",
      "Epoch: 145/1000 Iteration: 1310 Train loss: 0.348592 Train acc: 0.908333\n",
      "Epoch: 146/1000 Iteration: 1315 Train loss: 0.317370 Train acc: 0.930000\n",
      "Epoch: 146/1000 Iteration: 1320 Train loss: 0.290941 Train acc: 0.945000\n",
      "Epoch: 147/1000 Iteration: 1325 Train loss: 0.308338 Train acc: 0.928333\n",
      "Epoch: 147/1000 Iteration: 1325 Validation loss: 0.227795 Validation acc: 0.950556\n",
      "Epoch: 147/1000 Iteration: 1330 Train loss: 0.306534 Train acc: 0.926667\n",
      "Epoch: 148/1000 Iteration: 1335 Train loss: 0.339622 Train acc: 0.905000\n",
      "Epoch: 148/1000 Iteration: 1340 Train loss: 0.281364 Train acc: 0.955000\n",
      "Epoch: 149/1000 Iteration: 1345 Train loss: 0.359529 Train acc: 0.918333\n",
      "Epoch: 149/1000 Iteration: 1350 Train loss: 0.327668 Train acc: 0.930000\n",
      "Epoch: 149/1000 Iteration: 1350 Validation loss: 0.223997 Validation acc: 0.949444\n",
      "Epoch: 150/1000 Iteration: 1355 Train loss: 0.301011 Train acc: 0.931667\n",
      "Epoch: 151/1000 Iteration: 1360 Train loss: 0.311069 Train acc: 0.928333\n",
      "Epoch: 151/1000 Iteration: 1365 Train loss: 0.286364 Train acc: 0.938333\n",
      "Epoch: 152/1000 Iteration: 1370 Train loss: 0.309533 Train acc: 0.928333\n",
      "Epoch: 152/1000 Iteration: 1375 Train loss: 0.291517 Train acc: 0.931667\n",
      "Epoch: 152/1000 Iteration: 1375 Validation loss: 0.216071 Validation acc: 0.950556\n",
      "Epoch: 153/1000 Iteration: 1380 Train loss: 0.346079 Train acc: 0.930000\n",
      "Epoch: 153/1000 Iteration: 1385 Train loss: 0.283683 Train acc: 0.941667\n",
      "Epoch: 154/1000 Iteration: 1390 Train loss: 0.374295 Train acc: 0.891667\n",
      "Epoch: 154/1000 Iteration: 1395 Train loss: 0.312862 Train acc: 0.933333\n",
      "Epoch: 155/1000 Iteration: 1400 Train loss: 0.302397 Train acc: 0.925000\n",
      "Epoch: 155/1000 Iteration: 1400 Validation loss: 0.214031 Validation acc: 0.950556\n",
      "Epoch: 156/1000 Iteration: 1405 Train loss: 0.301151 Train acc: 0.930000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156/1000 Iteration: 1410 Train loss: 0.277829 Train acc: 0.933333\n",
      "Epoch: 157/1000 Iteration: 1415 Train loss: 0.308000 Train acc: 0.930000\n",
      "Epoch: 157/1000 Iteration: 1420 Train loss: 0.286149 Train acc: 0.935000\n",
      "Epoch: 158/1000 Iteration: 1425 Train loss: 0.322739 Train acc: 0.923333\n",
      "Epoch: 158/1000 Iteration: 1425 Validation loss: 0.215054 Validation acc: 0.948889\n",
      "Epoch: 158/1000 Iteration: 1430 Train loss: 0.276066 Train acc: 0.953333\n",
      "Epoch: 159/1000 Iteration: 1435 Train loss: 0.340987 Train acc: 0.911667\n",
      "Epoch: 159/1000 Iteration: 1440 Train loss: 0.304831 Train acc: 0.928333\n",
      "Epoch: 160/1000 Iteration: 1445 Train loss: 0.282488 Train acc: 0.940000\n",
      "Epoch: 161/1000 Iteration: 1450 Train loss: 0.294768 Train acc: 0.935000\n",
      "Epoch: 161/1000 Iteration: 1450 Validation loss: 0.207603 Validation acc: 0.949444\n",
      "Epoch: 161/1000 Iteration: 1455 Train loss: 0.254981 Train acc: 0.948333\n",
      "Epoch: 162/1000 Iteration: 1460 Train loss: 0.288811 Train acc: 0.948333\n",
      "Epoch: 162/1000 Iteration: 1465 Train loss: 0.272507 Train acc: 0.940000\n",
      "Epoch: 163/1000 Iteration: 1470 Train loss: 0.285907 Train acc: 0.926667\n",
      "Epoch: 163/1000 Iteration: 1475 Train loss: 0.268103 Train acc: 0.943333\n",
      "Epoch: 163/1000 Iteration: 1475 Validation loss: 0.204107 Validation acc: 0.950556\n",
      "Epoch: 164/1000 Iteration: 1480 Train loss: 0.353783 Train acc: 0.905000\n",
      "Epoch: 164/1000 Iteration: 1485 Train loss: 0.282378 Train acc: 0.940000\n",
      "Epoch: 165/1000 Iteration: 1490 Train loss: 0.271353 Train acc: 0.936667\n",
      "Epoch: 166/1000 Iteration: 1495 Train loss: 0.284569 Train acc: 0.938333\n",
      "Epoch: 166/1000 Iteration: 1500 Train loss: 0.237554 Train acc: 0.946667\n",
      "Epoch: 166/1000 Iteration: 1500 Validation loss: 0.197224 Validation acc: 0.952222\n",
      "Epoch: 167/1000 Iteration: 1505 Train loss: 0.286159 Train acc: 0.938333\n",
      "Epoch: 167/1000 Iteration: 1510 Train loss: 0.273765 Train acc: 0.945000\n",
      "Epoch: 168/1000 Iteration: 1515 Train loss: 0.273062 Train acc: 0.936667\n",
      "Epoch: 168/1000 Iteration: 1520 Train loss: 0.255708 Train acc: 0.950000\n",
      "Epoch: 169/1000 Iteration: 1525 Train loss: 0.313419 Train acc: 0.905000\n",
      "Epoch: 169/1000 Iteration: 1525 Validation loss: 0.196134 Validation acc: 0.952222\n",
      "Epoch: 169/1000 Iteration: 1530 Train loss: 0.278151 Train acc: 0.931667\n",
      "Epoch: 170/1000 Iteration: 1535 Train loss: 0.268909 Train acc: 0.936667\n",
      "Epoch: 171/1000 Iteration: 1540 Train loss: 0.264355 Train acc: 0.941667\n",
      "Epoch: 171/1000 Iteration: 1545 Train loss: 0.236984 Train acc: 0.948333\n",
      "Epoch: 172/1000 Iteration: 1550 Train loss: 0.282496 Train acc: 0.946667\n",
      "Epoch: 172/1000 Iteration: 1550 Validation loss: 0.194085 Validation acc: 0.951111\n",
      "Epoch: 172/1000 Iteration: 1555 Train loss: 0.252200 Train acc: 0.948333\n",
      "Epoch: 173/1000 Iteration: 1560 Train loss: 0.275669 Train acc: 0.943333\n",
      "Epoch: 173/1000 Iteration: 1565 Train loss: 0.236380 Train acc: 0.956667\n",
      "Epoch: 174/1000 Iteration: 1570 Train loss: 0.308010 Train acc: 0.918333\n",
      "Epoch: 174/1000 Iteration: 1575 Train loss: 0.277879 Train acc: 0.935000\n",
      "Epoch: 174/1000 Iteration: 1575 Validation loss: 0.192638 Validation acc: 0.950000\n",
      "Epoch: 175/1000 Iteration: 1580 Train loss: 0.254270 Train acc: 0.946667\n",
      "Epoch: 176/1000 Iteration: 1585 Train loss: 0.277890 Train acc: 0.943333\n",
      "Epoch: 176/1000 Iteration: 1590 Train loss: 0.243554 Train acc: 0.951667\n",
      "Epoch: 177/1000 Iteration: 1595 Train loss: 0.254937 Train acc: 0.946667\n",
      "Epoch: 177/1000 Iteration: 1600 Train loss: 0.249350 Train acc: 0.936667\n",
      "Epoch: 177/1000 Iteration: 1600 Validation loss: 0.189139 Validation acc: 0.951667\n",
      "Epoch: 178/1000 Iteration: 1605 Train loss: 0.263182 Train acc: 0.941667\n",
      "Epoch: 178/1000 Iteration: 1610 Train loss: 0.236066 Train acc: 0.958333\n",
      "Epoch: 179/1000 Iteration: 1615 Train loss: 0.315014 Train acc: 0.910000\n",
      "Epoch: 179/1000 Iteration: 1620 Train loss: 0.275343 Train acc: 0.933333\n",
      "Epoch: 180/1000 Iteration: 1625 Train loss: 0.252921 Train acc: 0.940000\n",
      "Epoch: 180/1000 Iteration: 1625 Validation loss: 0.187508 Validation acc: 0.952222\n",
      "Epoch: 181/1000 Iteration: 1630 Train loss: 0.260643 Train acc: 0.936667\n",
      "Epoch: 181/1000 Iteration: 1635 Train loss: 0.261877 Train acc: 0.945000\n",
      "Epoch: 182/1000 Iteration: 1640 Train loss: 0.264443 Train acc: 0.950000\n",
      "Epoch: 182/1000 Iteration: 1645 Train loss: 0.243823 Train acc: 0.941667\n",
      "Epoch: 183/1000 Iteration: 1650 Train loss: 0.281709 Train acc: 0.925000\n",
      "Epoch: 183/1000 Iteration: 1650 Validation loss: 0.182385 Validation acc: 0.952222\n",
      "Epoch: 183/1000 Iteration: 1655 Train loss: 0.230480 Train acc: 0.950000\n",
      "Epoch: 184/1000 Iteration: 1660 Train loss: 0.291213 Train acc: 0.923333\n",
      "Epoch: 184/1000 Iteration: 1665 Train loss: 0.256588 Train acc: 0.948333\n",
      "Epoch: 185/1000 Iteration: 1670 Train loss: 0.263191 Train acc: 0.931667\n",
      "Epoch: 186/1000 Iteration: 1675 Train loss: 0.242476 Train acc: 0.938333\n",
      "Epoch: 186/1000 Iteration: 1675 Validation loss: 0.180224 Validation acc: 0.952222\n",
      "Epoch: 186/1000 Iteration: 1680 Train loss: 0.220020 Train acc: 0.946667\n",
      "Epoch: 187/1000 Iteration: 1685 Train loss: 0.256443 Train acc: 0.938333\n",
      "Epoch: 187/1000 Iteration: 1690 Train loss: 0.250462 Train acc: 0.945000\n",
      "Epoch: 188/1000 Iteration: 1695 Train loss: 0.246713 Train acc: 0.941667\n",
      "Epoch: 188/1000 Iteration: 1700 Train loss: 0.221911 Train acc: 0.953333\n",
      "Epoch: 188/1000 Iteration: 1700 Validation loss: 0.180750 Validation acc: 0.952778\n",
      "Epoch: 189/1000 Iteration: 1705 Train loss: 0.288289 Train acc: 0.918333\n",
      "Epoch: 189/1000 Iteration: 1710 Train loss: 0.245537 Train acc: 0.945000\n",
      "Epoch: 190/1000 Iteration: 1715 Train loss: 0.232368 Train acc: 0.951667\n",
      "Epoch: 191/1000 Iteration: 1720 Train loss: 0.243102 Train acc: 0.943333\n",
      "Epoch: 191/1000 Iteration: 1725 Train loss: 0.252163 Train acc: 0.946667\n",
      "Epoch: 191/1000 Iteration: 1725 Validation loss: 0.189478 Validation acc: 0.951667\n",
      "Epoch: 192/1000 Iteration: 1730 Train loss: 0.250156 Train acc: 0.946667\n",
      "Epoch: 192/1000 Iteration: 1735 Train loss: 0.241658 Train acc: 0.935000\n",
      "Epoch: 193/1000 Iteration: 1740 Train loss: 0.249126 Train acc: 0.943333\n",
      "Epoch: 193/1000 Iteration: 1745 Train loss: 0.233093 Train acc: 0.946667\n",
      "Epoch: 194/1000 Iteration: 1750 Train loss: 0.281608 Train acc: 0.926667\n",
      "Epoch: 194/1000 Iteration: 1750 Validation loss: 0.177252 Validation acc: 0.951667\n",
      "Epoch: 194/1000 Iteration: 1755 Train loss: 0.261303 Train acc: 0.935000\n",
      "Epoch: 195/1000 Iteration: 1760 Train loss: 0.240212 Train acc: 0.931667\n",
      "Epoch: 196/1000 Iteration: 1765 Train loss: 0.235839 Train acc: 0.938333\n",
      "Epoch: 196/1000 Iteration: 1770 Train loss: 0.204871 Train acc: 0.956667\n",
      "Epoch: 197/1000 Iteration: 1775 Train loss: 0.248305 Train acc: 0.940000\n",
      "Epoch: 197/1000 Iteration: 1775 Validation loss: 0.170475 Validation acc: 0.953889\n",
      "Epoch: 197/1000 Iteration: 1780 Train loss: 0.250703 Train acc: 0.941667\n",
      "Epoch: 198/1000 Iteration: 1785 Train loss: 0.224155 Train acc: 0.946667\n",
      "Epoch: 198/1000 Iteration: 1790 Train loss: 0.213959 Train acc: 0.958333\n",
      "Epoch: 199/1000 Iteration: 1795 Train loss: 0.293257 Train acc: 0.920000\n",
      "Epoch: 199/1000 Iteration: 1800 Train loss: 0.246875 Train acc: 0.941667\n",
      "Epoch: 199/1000 Iteration: 1800 Validation loss: 0.168563 Validation acc: 0.955000\n",
      "Epoch: 200/1000 Iteration: 1805 Train loss: 0.252476 Train acc: 0.938333\n",
      "Epoch: 201/1000 Iteration: 1810 Train loss: 0.233309 Train acc: 0.958333\n",
      "Epoch: 201/1000 Iteration: 1815 Train loss: 0.212037 Train acc: 0.958333\n",
      "Epoch: 202/1000 Iteration: 1820 Train loss: 0.238265 Train acc: 0.948333\n",
      "Epoch: 202/1000 Iteration: 1825 Train loss: 0.221460 Train acc: 0.958333\n",
      "Epoch: 202/1000 Iteration: 1825 Validation loss: 0.165438 Validation acc: 0.956667\n",
      "Epoch: 203/1000 Iteration: 1830 Train loss: 0.240505 Train acc: 0.940000\n",
      "Epoch: 203/1000 Iteration: 1835 Train loss: 0.207110 Train acc: 0.951667\n",
      "Epoch: 204/1000 Iteration: 1840 Train loss: 0.282807 Train acc: 0.926667\n",
      "Epoch: 204/1000 Iteration: 1845 Train loss: 0.258621 Train acc: 0.936667\n",
      "Epoch: 205/1000 Iteration: 1850 Train loss: 0.222431 Train acc: 0.948333\n",
      "Epoch: 205/1000 Iteration: 1850 Validation loss: 0.164437 Validation acc: 0.956111\n",
      "Epoch: 206/1000 Iteration: 1855 Train loss: 0.230994 Train acc: 0.945000\n",
      "Epoch: 206/1000 Iteration: 1860 Train loss: 0.212726 Train acc: 0.950000\n",
      "Epoch: 207/1000 Iteration: 1865 Train loss: 0.223827 Train acc: 0.955000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207/1000 Iteration: 1870 Train loss: 0.214931 Train acc: 0.948333\n",
      "Epoch: 208/1000 Iteration: 1875 Train loss: 0.233686 Train acc: 0.951667\n",
      "Epoch: 208/1000 Iteration: 1875 Validation loss: 0.166253 Validation acc: 0.953889\n",
      "Epoch: 208/1000 Iteration: 1880 Train loss: 0.202362 Train acc: 0.960000\n",
      "Epoch: 209/1000 Iteration: 1885 Train loss: 0.264829 Train acc: 0.923333\n",
      "Epoch: 209/1000 Iteration: 1890 Train loss: 0.239950 Train acc: 0.945000\n",
      "Epoch: 210/1000 Iteration: 1895 Train loss: 0.221877 Train acc: 0.941667\n",
      "Epoch: 211/1000 Iteration: 1900 Train loss: 0.223887 Train acc: 0.950000\n",
      "Epoch: 211/1000 Iteration: 1900 Validation loss: 0.166858 Validation acc: 0.953333\n",
      "Epoch: 211/1000 Iteration: 1905 Train loss: 0.209005 Train acc: 0.943333\n",
      "Epoch: 212/1000 Iteration: 1910 Train loss: 0.232574 Train acc: 0.943333\n",
      "Epoch: 212/1000 Iteration: 1915 Train loss: 0.193503 Train acc: 0.960000\n",
      "Epoch: 213/1000 Iteration: 1920 Train loss: 0.235737 Train acc: 0.943333\n",
      "Epoch: 213/1000 Iteration: 1925 Train loss: 0.186856 Train acc: 0.968333\n",
      "Epoch: 213/1000 Iteration: 1925 Validation loss: 0.163680 Validation acc: 0.953889\n",
      "Epoch: 214/1000 Iteration: 1930 Train loss: 0.274980 Train acc: 0.915000\n",
      "Epoch: 214/1000 Iteration: 1935 Train loss: 0.234268 Train acc: 0.946667\n",
      "Epoch: 215/1000 Iteration: 1940 Train loss: 0.240458 Train acc: 0.945000\n",
      "Epoch: 216/1000 Iteration: 1945 Train loss: 0.222769 Train acc: 0.940000\n",
      "Epoch: 216/1000 Iteration: 1950 Train loss: 0.201005 Train acc: 0.956667\n",
      "Epoch: 216/1000 Iteration: 1950 Validation loss: 0.161096 Validation acc: 0.955000\n",
      "Epoch: 217/1000 Iteration: 1955 Train loss: 0.235743 Train acc: 0.948333\n",
      "Epoch: 217/1000 Iteration: 1960 Train loss: 0.202178 Train acc: 0.953333\n",
      "Epoch: 218/1000 Iteration: 1965 Train loss: 0.214809 Train acc: 0.946667\n",
      "Epoch: 218/1000 Iteration: 1970 Train loss: 0.211148 Train acc: 0.946667\n",
      "Epoch: 219/1000 Iteration: 1975 Train loss: 0.269849 Train acc: 0.920000\n",
      "Epoch: 219/1000 Iteration: 1975 Validation loss: 0.162911 Validation acc: 0.954444\n",
      "Epoch: 219/1000 Iteration: 1980 Train loss: 0.228333 Train acc: 0.941667\n",
      "Epoch: 220/1000 Iteration: 1985 Train loss: 0.210411 Train acc: 0.936667\n",
      "Epoch: 221/1000 Iteration: 1990 Train loss: 0.191389 Train acc: 0.961667\n",
      "Epoch: 221/1000 Iteration: 1995 Train loss: 0.207532 Train acc: 0.953333\n",
      "Epoch: 222/1000 Iteration: 2000 Train loss: 0.210269 Train acc: 0.958333\n",
      "Epoch: 222/1000 Iteration: 2000 Validation loss: 0.161583 Validation acc: 0.953889\n",
      "Epoch: 222/1000 Iteration: 2005 Train loss: 0.208478 Train acc: 0.941667\n",
      "Epoch: 223/1000 Iteration: 2010 Train loss: 0.217537 Train acc: 0.948333\n",
      "Epoch: 223/1000 Iteration: 2015 Train loss: 0.197410 Train acc: 0.963333\n",
      "Epoch: 224/1000 Iteration: 2020 Train loss: 0.263748 Train acc: 0.913333\n",
      "Epoch: 224/1000 Iteration: 2025 Train loss: 0.235232 Train acc: 0.948333\n",
      "Epoch: 224/1000 Iteration: 2025 Validation loss: 0.160496 Validation acc: 0.953333\n",
      "Epoch: 225/1000 Iteration: 2030 Train loss: 0.206726 Train acc: 0.948333\n",
      "Epoch: 226/1000 Iteration: 2035 Train loss: 0.203129 Train acc: 0.955000\n",
      "Epoch: 226/1000 Iteration: 2040 Train loss: 0.186694 Train acc: 0.961667\n",
      "Epoch: 227/1000 Iteration: 2045 Train loss: 0.204330 Train acc: 0.951667\n",
      "Epoch: 227/1000 Iteration: 2050 Train loss: 0.194937 Train acc: 0.956667\n",
      "Epoch: 227/1000 Iteration: 2050 Validation loss: 0.158993 Validation acc: 0.953889\n",
      "Epoch: 228/1000 Iteration: 2055 Train loss: 0.224227 Train acc: 0.941667\n",
      "Epoch: 228/1000 Iteration: 2060 Train loss: 0.180918 Train acc: 0.961667\n",
      "Epoch: 229/1000 Iteration: 2065 Train loss: 0.280085 Train acc: 0.915000\n",
      "Epoch: 229/1000 Iteration: 2070 Train loss: 0.238228 Train acc: 0.943333\n",
      "Epoch: 230/1000 Iteration: 2075 Train loss: 0.224459 Train acc: 0.948333\n",
      "Epoch: 230/1000 Iteration: 2075 Validation loss: 0.156260 Validation acc: 0.955000\n",
      "Epoch: 231/1000 Iteration: 2080 Train loss: 0.210643 Train acc: 0.945000\n",
      "Epoch: 231/1000 Iteration: 2085 Train loss: 0.206715 Train acc: 0.946667\n",
      "Epoch: 232/1000 Iteration: 2090 Train loss: 0.201912 Train acc: 0.958333\n",
      "Epoch: 232/1000 Iteration: 2095 Train loss: 0.190596 Train acc: 0.956667\n",
      "Epoch: 233/1000 Iteration: 2100 Train loss: 0.221257 Train acc: 0.938333\n",
      "Epoch: 233/1000 Iteration: 2100 Validation loss: 0.151497 Validation acc: 0.957222\n",
      "Epoch: 233/1000 Iteration: 2105 Train loss: 0.182097 Train acc: 0.956667\n",
      "Epoch: 234/1000 Iteration: 2110 Train loss: 0.251042 Train acc: 0.928333\n",
      "Epoch: 234/1000 Iteration: 2115 Train loss: 0.219025 Train acc: 0.945000\n",
      "Epoch: 235/1000 Iteration: 2120 Train loss: 0.194247 Train acc: 0.951667\n",
      "Epoch: 236/1000 Iteration: 2125 Train loss: 0.209716 Train acc: 0.946667\n",
      "Epoch: 236/1000 Iteration: 2125 Validation loss: 0.155986 Validation acc: 0.954444\n",
      "Epoch: 236/1000 Iteration: 2130 Train loss: 0.167194 Train acc: 0.963333\n",
      "Epoch: 237/1000 Iteration: 2135 Train loss: 0.216484 Train acc: 0.951667\n",
      "Epoch: 237/1000 Iteration: 2140 Train loss: 0.202667 Train acc: 0.955000\n",
      "Epoch: 238/1000 Iteration: 2145 Train loss: 0.223581 Train acc: 0.945000\n",
      "Epoch: 238/1000 Iteration: 2150 Train loss: 0.179196 Train acc: 0.953333\n",
      "Epoch: 238/1000 Iteration: 2150 Validation loss: 0.153668 Validation acc: 0.955000\n",
      "Epoch: 239/1000 Iteration: 2155 Train loss: 0.241384 Train acc: 0.923333\n",
      "Epoch: 239/1000 Iteration: 2160 Train loss: 0.213788 Train acc: 0.948333\n",
      "Epoch: 240/1000 Iteration: 2165 Train loss: 0.191832 Train acc: 0.955000\n",
      "Epoch: 241/1000 Iteration: 2170 Train loss: 0.194343 Train acc: 0.958333\n",
      "Epoch: 241/1000 Iteration: 2175 Train loss: 0.188523 Train acc: 0.951667\n",
      "Epoch: 241/1000 Iteration: 2175 Validation loss: 0.150707 Validation acc: 0.956111\n",
      "Epoch: 242/1000 Iteration: 2180 Train loss: 0.206618 Train acc: 0.955000\n",
      "Epoch: 242/1000 Iteration: 2185 Train loss: 0.197534 Train acc: 0.933333\n",
      "Epoch: 243/1000 Iteration: 2190 Train loss: 0.197973 Train acc: 0.950000\n",
      "Epoch: 243/1000 Iteration: 2195 Train loss: 0.176479 Train acc: 0.963333\n",
      "Epoch: 244/1000 Iteration: 2200 Train loss: 0.252568 Train acc: 0.923333\n",
      "Epoch: 244/1000 Iteration: 2200 Validation loss: 0.150166 Validation acc: 0.956667\n",
      "Epoch: 244/1000 Iteration: 2205 Train loss: 0.216515 Train acc: 0.945000\n",
      "Epoch: 245/1000 Iteration: 2210 Train loss: 0.193765 Train acc: 0.946667\n",
      "Epoch: 246/1000 Iteration: 2215 Train loss: 0.207778 Train acc: 0.951667\n",
      "Epoch: 246/1000 Iteration: 2220 Train loss: 0.195486 Train acc: 0.951667\n",
      "Epoch: 247/1000 Iteration: 2225 Train loss: 0.205964 Train acc: 0.958333\n",
      "Epoch: 247/1000 Iteration: 2225 Validation loss: 0.150394 Validation acc: 0.955555\n",
      "Epoch: 247/1000 Iteration: 2230 Train loss: 0.183573 Train acc: 0.956667\n",
      "Epoch: 248/1000 Iteration: 2235 Train loss: 0.207065 Train acc: 0.941667\n",
      "Epoch: 248/1000 Iteration: 2240 Train loss: 0.177974 Train acc: 0.961667\n",
      "Epoch: 249/1000 Iteration: 2245 Train loss: 0.263176 Train acc: 0.923333\n",
      "Epoch: 249/1000 Iteration: 2250 Train loss: 0.207495 Train acc: 0.950000\n",
      "Epoch: 249/1000 Iteration: 2250 Validation loss: 0.148082 Validation acc: 0.956111\n",
      "Epoch: 250/1000 Iteration: 2255 Train loss: 0.193243 Train acc: 0.946667\n",
      "Epoch: 251/1000 Iteration: 2260 Train loss: 0.200322 Train acc: 0.953333\n",
      "Epoch: 251/1000 Iteration: 2265 Train loss: 0.182772 Train acc: 0.953333\n",
      "Epoch: 252/1000 Iteration: 2270 Train loss: 0.212551 Train acc: 0.953333\n",
      "Epoch: 252/1000 Iteration: 2275 Train loss: 0.183110 Train acc: 0.955000\n",
      "Epoch: 252/1000 Iteration: 2275 Validation loss: 0.148172 Validation acc: 0.956667\n",
      "Epoch: 253/1000 Iteration: 2280 Train loss: 0.196580 Train acc: 0.953333\n",
      "Epoch: 253/1000 Iteration: 2285 Train loss: 0.198592 Train acc: 0.953333\n",
      "Epoch: 254/1000 Iteration: 2290 Train loss: 0.244637 Train acc: 0.930000\n",
      "Epoch: 254/1000 Iteration: 2295 Train loss: 0.207739 Train acc: 0.950000\n",
      "Epoch: 255/1000 Iteration: 2300 Train loss: 0.177896 Train acc: 0.951667\n",
      "Epoch: 255/1000 Iteration: 2300 Validation loss: 0.146125 Validation acc: 0.956667\n",
      "Epoch: 256/1000 Iteration: 2305 Train loss: 0.192596 Train acc: 0.948333\n",
      "Epoch: 256/1000 Iteration: 2310 Train loss: 0.169729 Train acc: 0.951667\n",
      "Epoch: 257/1000 Iteration: 2315 Train loss: 0.209389 Train acc: 0.946667\n",
      "Epoch: 257/1000 Iteration: 2320 Train loss: 0.192077 Train acc: 0.950000\n",
      "Epoch: 258/1000 Iteration: 2325 Train loss: 0.243808 Train acc: 0.935000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 258/1000 Iteration: 2325 Validation loss: 0.143041 Validation acc: 0.956667\n",
      "Epoch: 258/1000 Iteration: 2330 Train loss: 0.185564 Train acc: 0.956667\n",
      "Epoch: 259/1000 Iteration: 2335 Train loss: 0.268562 Train acc: 0.918333\n",
      "Epoch: 259/1000 Iteration: 2340 Train loss: 0.201005 Train acc: 0.953333\n",
      "Epoch: 260/1000 Iteration: 2345 Train loss: 0.187179 Train acc: 0.955000\n",
      "Epoch: 261/1000 Iteration: 2350 Train loss: 0.194697 Train acc: 0.955000\n",
      "Epoch: 261/1000 Iteration: 2350 Validation loss: 0.146208 Validation acc: 0.956111\n",
      "Epoch: 261/1000 Iteration: 2355 Train loss: 0.181517 Train acc: 0.953333\n",
      "Epoch: 262/1000 Iteration: 2360 Train loss: 0.202738 Train acc: 0.948333\n",
      "Epoch: 262/1000 Iteration: 2365 Train loss: 0.179109 Train acc: 0.956667\n",
      "Epoch: 263/1000 Iteration: 2370 Train loss: 0.191990 Train acc: 0.951667\n",
      "Epoch: 263/1000 Iteration: 2375 Train loss: 0.189623 Train acc: 0.953333\n",
      "Epoch: 263/1000 Iteration: 2375 Validation loss: 0.147498 Validation acc: 0.953889\n",
      "Epoch: 264/1000 Iteration: 2380 Train loss: 0.230070 Train acc: 0.938333\n",
      "Epoch: 264/1000 Iteration: 2385 Train loss: 0.197820 Train acc: 0.950000\n",
      "Epoch: 265/1000 Iteration: 2390 Train loss: 0.201895 Train acc: 0.941667\n",
      "Epoch: 266/1000 Iteration: 2395 Train loss: 0.184311 Train acc: 0.940000\n",
      "Epoch: 266/1000 Iteration: 2400 Train loss: 0.179930 Train acc: 0.953333\n",
      "Epoch: 266/1000 Iteration: 2400 Validation loss: 0.143140 Validation acc: 0.956111\n",
      "Epoch: 267/1000 Iteration: 2405 Train loss: 0.188764 Train acc: 0.953333\n",
      "Epoch: 267/1000 Iteration: 2410 Train loss: 0.199568 Train acc: 0.945000\n",
      "Epoch: 268/1000 Iteration: 2415 Train loss: 0.200221 Train acc: 0.948333\n",
      "Epoch: 268/1000 Iteration: 2420 Train loss: 0.172577 Train acc: 0.971667\n",
      "Epoch: 269/1000 Iteration: 2425 Train loss: 0.232283 Train acc: 0.928333\n",
      "Epoch: 269/1000 Iteration: 2425 Validation loss: 0.144393 Validation acc: 0.955000\n",
      "Epoch: 269/1000 Iteration: 2430 Train loss: 0.208319 Train acc: 0.945000\n",
      "Epoch: 270/1000 Iteration: 2435 Train loss: 0.188976 Train acc: 0.951667\n",
      "Epoch: 271/1000 Iteration: 2440 Train loss: 0.183899 Train acc: 0.955000\n",
      "Epoch: 271/1000 Iteration: 2445 Train loss: 0.165780 Train acc: 0.960000\n",
      "Epoch: 272/1000 Iteration: 2450 Train loss: 0.166023 Train acc: 0.960000\n",
      "Epoch: 272/1000 Iteration: 2450 Validation loss: 0.148595 Validation acc: 0.953333\n",
      "Epoch: 272/1000 Iteration: 2455 Train loss: 0.176879 Train acc: 0.963333\n",
      "Epoch: 273/1000 Iteration: 2460 Train loss: 0.207382 Train acc: 0.938333\n",
      "Epoch: 273/1000 Iteration: 2465 Train loss: 0.164357 Train acc: 0.956667\n",
      "Epoch: 274/1000 Iteration: 2470 Train loss: 0.234212 Train acc: 0.920000\n",
      "Epoch: 274/1000 Iteration: 2475 Train loss: 0.197594 Train acc: 0.955000\n",
      "Epoch: 274/1000 Iteration: 2475 Validation loss: 0.144056 Validation acc: 0.955555\n",
      "Epoch: 275/1000 Iteration: 2480 Train loss: 0.187075 Train acc: 0.955000\n",
      "Epoch: 276/1000 Iteration: 2485 Train loss: 0.183333 Train acc: 0.956667\n",
      "Epoch: 276/1000 Iteration: 2490 Train loss: 0.175338 Train acc: 0.958333\n",
      "Epoch: 277/1000 Iteration: 2495 Train loss: 0.175423 Train acc: 0.958333\n",
      "Epoch: 277/1000 Iteration: 2500 Train loss: 0.192902 Train acc: 0.946667\n",
      "Epoch: 277/1000 Iteration: 2500 Validation loss: 0.140898 Validation acc: 0.956667\n",
      "Epoch: 278/1000 Iteration: 2505 Train loss: 0.201841 Train acc: 0.945000\n",
      "Epoch: 278/1000 Iteration: 2510 Train loss: 0.179979 Train acc: 0.955000\n",
      "Epoch: 279/1000 Iteration: 2515 Train loss: 0.226956 Train acc: 0.925000\n",
      "Epoch: 279/1000 Iteration: 2520 Train loss: 0.203337 Train acc: 0.950000\n",
      "Epoch: 280/1000 Iteration: 2525 Train loss: 0.172557 Train acc: 0.955000\n",
      "Epoch: 280/1000 Iteration: 2525 Validation loss: 0.145963 Validation acc: 0.954444\n",
      "Epoch: 281/1000 Iteration: 2530 Train loss: 0.200913 Train acc: 0.946667\n",
      "Epoch: 281/1000 Iteration: 2535 Train loss: 0.187672 Train acc: 0.950000\n",
      "Epoch: 282/1000 Iteration: 2540 Train loss: 0.177539 Train acc: 0.960000\n",
      "Epoch: 282/1000 Iteration: 2545 Train loss: 0.194927 Train acc: 0.950000\n",
      "Epoch: 283/1000 Iteration: 2550 Train loss: 0.182537 Train acc: 0.938333\n",
      "Epoch: 283/1000 Iteration: 2550 Validation loss: 0.138873 Validation acc: 0.956111\n",
      "Epoch: 283/1000 Iteration: 2555 Train loss: 0.185074 Train acc: 0.953333\n",
      "Epoch: 284/1000 Iteration: 2560 Train loss: 0.230047 Train acc: 0.930000\n",
      "Epoch: 284/1000 Iteration: 2565 Train loss: 0.203253 Train acc: 0.946667\n",
      "Epoch: 285/1000 Iteration: 2570 Train loss: 0.177613 Train acc: 0.953333\n",
      "Epoch: 286/1000 Iteration: 2575 Train loss: 0.178128 Train acc: 0.951667\n",
      "Epoch: 286/1000 Iteration: 2575 Validation loss: 0.138502 Validation acc: 0.956667\n",
      "Epoch: 286/1000 Iteration: 2580 Train loss: 0.177152 Train acc: 0.951667\n",
      "Epoch: 287/1000 Iteration: 2585 Train loss: 0.179964 Train acc: 0.958333\n",
      "Epoch: 287/1000 Iteration: 2590 Train loss: 0.169579 Train acc: 0.953333\n",
      "Epoch: 288/1000 Iteration: 2595 Train loss: 0.199032 Train acc: 0.940000\n",
      "Epoch: 288/1000 Iteration: 2600 Train loss: 0.177659 Train acc: 0.955000\n",
      "Epoch: 288/1000 Iteration: 2600 Validation loss: 0.142805 Validation acc: 0.954444\n",
      "Epoch: 289/1000 Iteration: 2605 Train loss: 0.211459 Train acc: 0.941667\n",
      "Epoch: 289/1000 Iteration: 2610 Train loss: 0.194406 Train acc: 0.951667\n",
      "Epoch: 290/1000 Iteration: 2615 Train loss: 0.189042 Train acc: 0.940000\n",
      "Epoch: 291/1000 Iteration: 2620 Train loss: 0.190674 Train acc: 0.953333\n",
      "Epoch: 291/1000 Iteration: 2625 Train loss: 0.163820 Train acc: 0.956667\n",
      "Epoch: 291/1000 Iteration: 2625 Validation loss: 0.143185 Validation acc: 0.953333\n",
      "Epoch: 292/1000 Iteration: 2630 Train loss: 0.164217 Train acc: 0.955000\n",
      "Epoch: 292/1000 Iteration: 2635 Train loss: 0.182686 Train acc: 0.948333\n",
      "Epoch: 293/1000 Iteration: 2640 Train loss: 0.195596 Train acc: 0.941667\n",
      "Epoch: 293/1000 Iteration: 2645 Train loss: 0.160497 Train acc: 0.956667\n",
      "Epoch: 294/1000 Iteration: 2650 Train loss: 0.223291 Train acc: 0.936667\n",
      "Epoch: 294/1000 Iteration: 2650 Validation loss: 0.147922 Validation acc: 0.953333\n",
      "Epoch: 294/1000 Iteration: 2655 Train loss: 0.202532 Train acc: 0.933333\n",
      "Epoch: 295/1000 Iteration: 2660 Train loss: 0.173660 Train acc: 0.950000\n",
      "Epoch: 296/1000 Iteration: 2665 Train loss: 0.171153 Train acc: 0.961667\n",
      "Epoch: 296/1000 Iteration: 2670 Train loss: 0.162797 Train acc: 0.963333\n",
      "Epoch: 297/1000 Iteration: 2675 Train loss: 0.168580 Train acc: 0.960000\n",
      "Epoch: 297/1000 Iteration: 2675 Validation loss: 0.136794 Validation acc: 0.956667\n",
      "Epoch: 297/1000 Iteration: 2680 Train loss: 0.173465 Train acc: 0.950000\n",
      "Epoch: 298/1000 Iteration: 2685 Train loss: 0.191978 Train acc: 0.946667\n",
      "Epoch: 298/1000 Iteration: 2690 Train loss: 0.168049 Train acc: 0.956667\n",
      "Epoch: 299/1000 Iteration: 2695 Train loss: 0.228738 Train acc: 0.925000\n",
      "Epoch: 299/1000 Iteration: 2700 Train loss: 0.218938 Train acc: 0.940000\n",
      "Epoch: 299/1000 Iteration: 2700 Validation loss: 0.148201 Validation acc: 0.952222\n",
      "Epoch: 300/1000 Iteration: 2705 Train loss: 0.180366 Train acc: 0.953333\n",
      "Epoch: 301/1000 Iteration: 2710 Train loss: 0.170298 Train acc: 0.951667\n",
      "Epoch: 301/1000 Iteration: 2715 Train loss: 0.186019 Train acc: 0.945000\n",
      "Epoch: 302/1000 Iteration: 2720 Train loss: 0.168863 Train acc: 0.960000\n",
      "Epoch: 302/1000 Iteration: 2725 Train loss: 0.170036 Train acc: 0.955000\n",
      "Epoch: 302/1000 Iteration: 2725 Validation loss: 0.135802 Validation acc: 0.957778\n",
      "Epoch: 303/1000 Iteration: 2730 Train loss: 0.198131 Train acc: 0.936667\n",
      "Epoch: 303/1000 Iteration: 2735 Train loss: 0.155297 Train acc: 0.955000\n",
      "Epoch: 304/1000 Iteration: 2740 Train loss: 0.218359 Train acc: 0.935000\n",
      "Epoch: 304/1000 Iteration: 2745 Train loss: 0.187531 Train acc: 0.945000\n",
      "Epoch: 305/1000 Iteration: 2750 Train loss: 0.170075 Train acc: 0.961667\n",
      "Epoch: 305/1000 Iteration: 2750 Validation loss: 0.136643 Validation acc: 0.956667\n",
      "Epoch: 306/1000 Iteration: 2755 Train loss: 0.171752 Train acc: 0.951667\n",
      "Epoch: 306/1000 Iteration: 2760 Train loss: 0.169166 Train acc: 0.951667\n",
      "Epoch: 307/1000 Iteration: 2765 Train loss: 0.175207 Train acc: 0.965000\n",
      "Epoch: 307/1000 Iteration: 2770 Train loss: 0.176406 Train acc: 0.945000\n",
      "Epoch: 308/1000 Iteration: 2775 Train loss: 0.180232 Train acc: 0.953333\n",
      "Epoch: 308/1000 Iteration: 2775 Validation loss: 0.138311 Validation acc: 0.953889\n",
      "Epoch: 308/1000 Iteration: 2780 Train loss: 0.169479 Train acc: 0.960000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 309/1000 Iteration: 2785 Train loss: 0.202041 Train acc: 0.930000\n",
      "Epoch: 309/1000 Iteration: 2790 Train loss: 0.190682 Train acc: 0.950000\n",
      "Epoch: 310/1000 Iteration: 2795 Train loss: 0.171347 Train acc: 0.955000\n",
      "Epoch: 311/1000 Iteration: 2800 Train loss: 0.164423 Train acc: 0.963333\n",
      "Epoch: 311/1000 Iteration: 2800 Validation loss: 0.136227 Validation acc: 0.956111\n",
      "Epoch: 311/1000 Iteration: 2805 Train loss: 0.168693 Train acc: 0.953333\n",
      "Epoch: 312/1000 Iteration: 2810 Train loss: 0.189006 Train acc: 0.948333\n",
      "Epoch: 312/1000 Iteration: 2815 Train loss: 0.175783 Train acc: 0.950000\n",
      "Epoch: 313/1000 Iteration: 2820 Train loss: 0.174338 Train acc: 0.948333\n",
      "Epoch: 313/1000 Iteration: 2825 Train loss: 0.162231 Train acc: 0.965000\n",
      "Epoch: 313/1000 Iteration: 2825 Validation loss: 0.137912 Validation acc: 0.956667\n",
      "Epoch: 314/1000 Iteration: 2830 Train loss: 0.218495 Train acc: 0.936667\n",
      "Epoch: 314/1000 Iteration: 2835 Train loss: 0.189239 Train acc: 0.945000\n",
      "Epoch: 315/1000 Iteration: 2840 Train loss: 0.157758 Train acc: 0.965000\n",
      "Epoch: 316/1000 Iteration: 2845 Train loss: 0.166130 Train acc: 0.956667\n",
      "Epoch: 316/1000 Iteration: 2850 Train loss: 0.170200 Train acc: 0.953333\n",
      "Epoch: 316/1000 Iteration: 2850 Validation loss: 0.137270 Validation acc: 0.957222\n",
      "Epoch: 317/1000 Iteration: 2855 Train loss: 0.164073 Train acc: 0.961667\n",
      "Epoch: 317/1000 Iteration: 2860 Train loss: 0.162088 Train acc: 0.948333\n",
      "Epoch: 318/1000 Iteration: 2865 Train loss: 0.194654 Train acc: 0.945000\n",
      "Epoch: 318/1000 Iteration: 2870 Train loss: 0.151602 Train acc: 0.965000\n",
      "Epoch: 319/1000 Iteration: 2875 Train loss: 0.220631 Train acc: 0.923333\n",
      "Epoch: 319/1000 Iteration: 2875 Validation loss: 0.134963 Validation acc: 0.957222\n",
      "Epoch: 319/1000 Iteration: 2880 Train loss: 0.191597 Train acc: 0.946667\n",
      "Epoch: 320/1000 Iteration: 2885 Train loss: 0.155008 Train acc: 0.955000\n",
      "Epoch: 321/1000 Iteration: 2890 Train loss: 0.152350 Train acc: 0.956667\n",
      "Epoch: 321/1000 Iteration: 2895 Train loss: 0.152872 Train acc: 0.960000\n",
      "Epoch: 322/1000 Iteration: 2900 Train loss: 0.182033 Train acc: 0.958333\n",
      "Epoch: 322/1000 Iteration: 2900 Validation loss: 0.133795 Validation acc: 0.957222\n",
      "Epoch: 322/1000 Iteration: 2905 Train loss: 0.171697 Train acc: 0.956667\n",
      "Epoch: 323/1000 Iteration: 2910 Train loss: 0.191260 Train acc: 0.948333\n",
      "Epoch: 323/1000 Iteration: 2915 Train loss: 0.158578 Train acc: 0.958333\n",
      "Epoch: 324/1000 Iteration: 2920 Train loss: 0.212387 Train acc: 0.930000\n",
      "Epoch: 324/1000 Iteration: 2925 Train loss: 0.195530 Train acc: 0.940000\n",
      "Epoch: 324/1000 Iteration: 2925 Validation loss: 0.156916 Validation acc: 0.950556\n",
      "Epoch: 325/1000 Iteration: 2930 Train loss: 0.183651 Train acc: 0.946667\n",
      "Epoch: 326/1000 Iteration: 2935 Train loss: 0.169227 Train acc: 0.951667\n",
      "Epoch: 326/1000 Iteration: 2940 Train loss: 0.149884 Train acc: 0.963333\n",
      "Epoch: 327/1000 Iteration: 2945 Train loss: 0.167916 Train acc: 0.965000\n",
      "Epoch: 327/1000 Iteration: 2950 Train loss: 0.170091 Train acc: 0.941667\n",
      "Epoch: 327/1000 Iteration: 2950 Validation loss: 0.136174 Validation acc: 0.956667\n",
      "Epoch: 328/1000 Iteration: 2955 Train loss: 0.176439 Train acc: 0.938333\n",
      "Epoch: 328/1000 Iteration: 2960 Train loss: 0.154526 Train acc: 0.961667\n",
      "Epoch: 329/1000 Iteration: 2965 Train loss: 0.243372 Train acc: 0.928333\n",
      "Epoch: 329/1000 Iteration: 2970 Train loss: 0.171114 Train acc: 0.951667\n",
      "Epoch: 330/1000 Iteration: 2975 Train loss: 0.163535 Train acc: 0.958333\n",
      "Epoch: 330/1000 Iteration: 2975 Validation loss: 0.137157 Validation acc: 0.956111\n",
      "Epoch: 331/1000 Iteration: 2980 Train loss: 0.166249 Train acc: 0.958333\n",
      "Epoch: 331/1000 Iteration: 2985 Train loss: 0.157762 Train acc: 0.955000\n",
      "Epoch: 332/1000 Iteration: 2990 Train loss: 0.183428 Train acc: 0.953333\n",
      "Epoch: 332/1000 Iteration: 2995 Train loss: 0.154008 Train acc: 0.960000\n",
      "Epoch: 333/1000 Iteration: 3000 Train loss: 0.183857 Train acc: 0.941667\n",
      "Epoch: 333/1000 Iteration: 3000 Validation loss: 0.136042 Validation acc: 0.956667\n",
      "Epoch: 333/1000 Iteration: 3005 Train loss: 0.150809 Train acc: 0.965000\n",
      "Epoch: 334/1000 Iteration: 3010 Train loss: 0.220147 Train acc: 0.930000\n",
      "Epoch: 334/1000 Iteration: 3015 Train loss: 0.186543 Train acc: 0.946667\n",
      "Epoch: 335/1000 Iteration: 3020 Train loss: 0.160018 Train acc: 0.955000\n",
      "Epoch: 336/1000 Iteration: 3025 Train loss: 0.157455 Train acc: 0.958333\n",
      "Epoch: 336/1000 Iteration: 3025 Validation loss: 0.135816 Validation acc: 0.956111\n",
      "Epoch: 336/1000 Iteration: 3030 Train loss: 0.166041 Train acc: 0.953333\n",
      "Epoch: 337/1000 Iteration: 3035 Train loss: 0.168782 Train acc: 0.955000\n",
      "Epoch: 337/1000 Iteration: 3040 Train loss: 0.166368 Train acc: 0.953333\n",
      "Epoch: 338/1000 Iteration: 3045 Train loss: 0.174422 Train acc: 0.941667\n",
      "Epoch: 338/1000 Iteration: 3050 Train loss: 0.141584 Train acc: 0.961667\n",
      "Epoch: 338/1000 Iteration: 3050 Validation loss: 0.134919 Validation acc: 0.956667\n",
      "Epoch: 339/1000 Iteration: 3055 Train loss: 0.206901 Train acc: 0.933333\n",
      "Epoch: 339/1000 Iteration: 3060 Train loss: 0.175185 Train acc: 0.956667\n",
      "Epoch: 340/1000 Iteration: 3065 Train loss: 0.153321 Train acc: 0.953333\n",
      "Epoch: 341/1000 Iteration: 3070 Train loss: 0.167788 Train acc: 0.958333\n",
      "Epoch: 341/1000 Iteration: 3075 Train loss: 0.159315 Train acc: 0.958333\n",
      "Epoch: 341/1000 Iteration: 3075 Validation loss: 0.135652 Validation acc: 0.956111\n",
      "Epoch: 342/1000 Iteration: 3080 Train loss: 0.180932 Train acc: 0.951667\n",
      "Epoch: 342/1000 Iteration: 3085 Train loss: 0.163773 Train acc: 0.953333\n",
      "Epoch: 343/1000 Iteration: 3090 Train loss: 0.190339 Train acc: 0.938333\n",
      "Epoch: 343/1000 Iteration: 3095 Train loss: 0.163705 Train acc: 0.965000\n",
      "Epoch: 344/1000 Iteration: 3100 Train loss: 0.189166 Train acc: 0.943333\n",
      "Epoch: 344/1000 Iteration: 3100 Validation loss: 0.134821 Validation acc: 0.956111\n",
      "Epoch: 344/1000 Iteration: 3105 Train loss: 0.189205 Train acc: 0.950000\n",
      "Epoch: 345/1000 Iteration: 3110 Train loss: 0.159733 Train acc: 0.950000\n",
      "Epoch: 346/1000 Iteration: 3115 Train loss: 0.158422 Train acc: 0.956667\n",
      "Epoch: 346/1000 Iteration: 3120 Train loss: 0.150919 Train acc: 0.956667\n",
      "Epoch: 347/1000 Iteration: 3125 Train loss: 0.149943 Train acc: 0.961667\n",
      "Epoch: 347/1000 Iteration: 3125 Validation loss: 0.133167 Validation acc: 0.957222\n",
      "Epoch: 347/1000 Iteration: 3130 Train loss: 0.151276 Train acc: 0.956667\n",
      "Epoch: 348/1000 Iteration: 3135 Train loss: 0.183279 Train acc: 0.943333\n",
      "Epoch: 348/1000 Iteration: 3140 Train loss: 0.154920 Train acc: 0.958333\n",
      "Epoch: 349/1000 Iteration: 3145 Train loss: 0.183236 Train acc: 0.940000\n",
      "Epoch: 349/1000 Iteration: 3150 Train loss: 0.193787 Train acc: 0.955000\n",
      "Epoch: 349/1000 Iteration: 3150 Validation loss: 0.133597 Validation acc: 0.957222\n",
      "Epoch: 350/1000 Iteration: 3155 Train loss: 0.158592 Train acc: 0.965000\n",
      "Epoch: 351/1000 Iteration: 3160 Train loss: 0.160277 Train acc: 0.943333\n",
      "Epoch: 351/1000 Iteration: 3165 Train loss: 0.152713 Train acc: 0.961667\n",
      "Epoch: 352/1000 Iteration: 3170 Train loss: 0.182230 Train acc: 0.950000\n",
      "Epoch: 352/1000 Iteration: 3175 Train loss: 0.165572 Train acc: 0.950000\n",
      "Epoch: 352/1000 Iteration: 3175 Validation loss: 0.133501 Validation acc: 0.958333\n",
      "Epoch: 353/1000 Iteration: 3180 Train loss: 0.170382 Train acc: 0.950000\n",
      "Epoch: 353/1000 Iteration: 3185 Train loss: 0.135394 Train acc: 0.965000\n",
      "Epoch: 354/1000 Iteration: 3190 Train loss: 0.194829 Train acc: 0.936667\n",
      "Epoch: 354/1000 Iteration: 3195 Train loss: 0.189083 Train acc: 0.950000\n",
      "Epoch: 355/1000 Iteration: 3200 Train loss: 0.160892 Train acc: 0.956667\n",
      "Epoch: 355/1000 Iteration: 3200 Validation loss: 0.134612 Validation acc: 0.957222\n",
      "Epoch: 356/1000 Iteration: 3205 Train loss: 0.153872 Train acc: 0.956667\n",
      "Epoch: 356/1000 Iteration: 3210 Train loss: 0.157377 Train acc: 0.960000\n",
      "Epoch: 357/1000 Iteration: 3215 Train loss: 0.145033 Train acc: 0.960000\n",
      "Epoch: 357/1000 Iteration: 3220 Train loss: 0.151994 Train acc: 0.963333\n",
      "Epoch: 358/1000 Iteration: 3225 Train loss: 0.170684 Train acc: 0.948333\n",
      "Epoch: 358/1000 Iteration: 3225 Validation loss: 0.134648 Validation acc: 0.956111\n",
      "Epoch: 358/1000 Iteration: 3230 Train loss: 0.152241 Train acc: 0.955000\n",
      "Epoch: 359/1000 Iteration: 3235 Train loss: 0.185328 Train acc: 0.941667\n",
      "Epoch: 359/1000 Iteration: 3240 Train loss: 0.181655 Train acc: 0.956667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360/1000 Iteration: 3245 Train loss: 0.156177 Train acc: 0.956667\n",
      "Epoch: 361/1000 Iteration: 3250 Train loss: 0.147692 Train acc: 0.953333\n",
      "Epoch: 361/1000 Iteration: 3250 Validation loss: 0.133836 Validation acc: 0.957222\n",
      "Epoch: 361/1000 Iteration: 3255 Train loss: 0.159993 Train acc: 0.955000\n",
      "Epoch: 362/1000 Iteration: 3260 Train loss: 0.167141 Train acc: 0.953333\n",
      "Epoch: 362/1000 Iteration: 3265 Train loss: 0.165760 Train acc: 0.953333\n",
      "Epoch: 363/1000 Iteration: 3270 Train loss: 0.169901 Train acc: 0.945000\n",
      "Epoch: 363/1000 Iteration: 3275 Train loss: 0.140433 Train acc: 0.960000\n",
      "Epoch: 363/1000 Iteration: 3275 Validation loss: 0.135544 Validation acc: 0.956667\n",
      "Epoch: 364/1000 Iteration: 3280 Train loss: 0.202716 Train acc: 0.940000\n",
      "Epoch: 364/1000 Iteration: 3285 Train loss: 0.185663 Train acc: 0.945000\n",
      "Epoch: 365/1000 Iteration: 3290 Train loss: 0.156795 Train acc: 0.951667\n",
      "Epoch: 366/1000 Iteration: 3295 Train loss: 0.156749 Train acc: 0.961667\n",
      "Epoch: 366/1000 Iteration: 3300 Train loss: 0.154491 Train acc: 0.960000\n",
      "Epoch: 366/1000 Iteration: 3300 Validation loss: 0.126936 Validation acc: 0.957778\n",
      "Epoch: 367/1000 Iteration: 3305 Train loss: 0.161345 Train acc: 0.958333\n",
      "Epoch: 367/1000 Iteration: 3310 Train loss: 0.165460 Train acc: 0.960000\n",
      "Epoch: 368/1000 Iteration: 3315 Train loss: 0.166289 Train acc: 0.946667\n",
      "Epoch: 368/1000 Iteration: 3320 Train loss: 0.143570 Train acc: 0.963333\n",
      "Epoch: 369/1000 Iteration: 3325 Train loss: 0.185303 Train acc: 0.945000\n",
      "Epoch: 369/1000 Iteration: 3325 Validation loss: 0.129395 Validation acc: 0.955555\n",
      "Epoch: 369/1000 Iteration: 3330 Train loss: 0.187513 Train acc: 0.940000\n",
      "Epoch: 370/1000 Iteration: 3335 Train loss: 0.165391 Train acc: 0.951667\n",
      "Epoch: 371/1000 Iteration: 3340 Train loss: 0.168977 Train acc: 0.951667\n",
      "Epoch: 371/1000 Iteration: 3345 Train loss: 0.144190 Train acc: 0.961667\n",
      "Epoch: 372/1000 Iteration: 3350 Train loss: 0.173235 Train acc: 0.953333\n",
      "Epoch: 372/1000 Iteration: 3350 Validation loss: 0.131277 Validation acc: 0.955555\n",
      "Epoch: 372/1000 Iteration: 3355 Train loss: 0.160171 Train acc: 0.946667\n",
      "Epoch: 373/1000 Iteration: 3360 Train loss: 0.169839 Train acc: 0.955000\n",
      "Epoch: 373/1000 Iteration: 3365 Train loss: 0.129514 Train acc: 0.965000\n",
      "Epoch: 374/1000 Iteration: 3370 Train loss: 0.187369 Train acc: 0.936667\n",
      "Epoch: 374/1000 Iteration: 3375 Train loss: 0.166377 Train acc: 0.955000\n",
      "Epoch: 374/1000 Iteration: 3375 Validation loss: 0.131341 Validation acc: 0.955555\n",
      "Epoch: 375/1000 Iteration: 3380 Train loss: 0.157167 Train acc: 0.961667\n",
      "Epoch: 376/1000 Iteration: 3385 Train loss: 0.148388 Train acc: 0.961667\n",
      "Epoch: 376/1000 Iteration: 3390 Train loss: 0.143507 Train acc: 0.961667\n",
      "Epoch: 377/1000 Iteration: 3395 Train loss: 0.157762 Train acc: 0.966667\n",
      "Epoch: 377/1000 Iteration: 3400 Train loss: 0.160787 Train acc: 0.950000\n",
      "Epoch: 377/1000 Iteration: 3400 Validation loss: 0.133130 Validation acc: 0.956111\n",
      "Epoch: 378/1000 Iteration: 3405 Train loss: 0.152244 Train acc: 0.943333\n",
      "Epoch: 378/1000 Iteration: 3410 Train loss: 0.132243 Train acc: 0.965000\n",
      "Epoch: 379/1000 Iteration: 3415 Train loss: 0.195282 Train acc: 0.940000\n",
      "Epoch: 379/1000 Iteration: 3420 Train loss: 0.182924 Train acc: 0.946667\n",
      "Epoch: 380/1000 Iteration: 3425 Train loss: 0.161617 Train acc: 0.953333\n",
      "Epoch: 380/1000 Iteration: 3425 Validation loss: 0.133044 Validation acc: 0.956667\n",
      "Epoch: 381/1000 Iteration: 3430 Train loss: 0.143117 Train acc: 0.955000\n",
      "Epoch: 381/1000 Iteration: 3435 Train loss: 0.160299 Train acc: 0.950000\n",
      "Epoch: 382/1000 Iteration: 3440 Train loss: 0.144625 Train acc: 0.966667\n",
      "Epoch: 382/1000 Iteration: 3445 Train loss: 0.153886 Train acc: 0.956667\n",
      "Epoch: 383/1000 Iteration: 3450 Train loss: 0.164057 Train acc: 0.955000\n",
      "Epoch: 383/1000 Iteration: 3450 Validation loss: 0.132684 Validation acc: 0.957222\n",
      "Epoch: 383/1000 Iteration: 3455 Train loss: 0.133683 Train acc: 0.965000\n",
      "Epoch: 384/1000 Iteration: 3460 Train loss: 0.175376 Train acc: 0.940000\n",
      "Epoch: 384/1000 Iteration: 3465 Train loss: 0.179057 Train acc: 0.941667\n",
      "Epoch: 385/1000 Iteration: 3470 Train loss: 0.145967 Train acc: 0.958333\n",
      "Epoch: 386/1000 Iteration: 3475 Train loss: 0.174509 Train acc: 0.953333\n",
      "Epoch: 386/1000 Iteration: 3475 Validation loss: 0.126780 Validation acc: 0.958333\n",
      "Epoch: 386/1000 Iteration: 3480 Train loss: 0.141998 Train acc: 0.956667\n",
      "Epoch: 387/1000 Iteration: 3485 Train loss: 0.145676 Train acc: 0.953333\n",
      "Epoch: 387/1000 Iteration: 3490 Train loss: 0.146614 Train acc: 0.955000\n",
      "Epoch: 388/1000 Iteration: 3495 Train loss: 0.159408 Train acc: 0.958333\n",
      "Epoch: 388/1000 Iteration: 3500 Train loss: 0.142461 Train acc: 0.960000\n",
      "Epoch: 388/1000 Iteration: 3500 Validation loss: 0.130547 Validation acc: 0.955000\n",
      "Epoch: 389/1000 Iteration: 3505 Train loss: 0.180340 Train acc: 0.926667\n",
      "Epoch: 389/1000 Iteration: 3510 Train loss: 0.160020 Train acc: 0.955000\n",
      "Epoch: 390/1000 Iteration: 3515 Train loss: 0.148903 Train acc: 0.943333\n",
      "Epoch: 391/1000 Iteration: 3520 Train loss: 0.147319 Train acc: 0.960000\n",
      "Epoch: 391/1000 Iteration: 3525 Train loss: 0.144115 Train acc: 0.958333\n",
      "Epoch: 391/1000 Iteration: 3525 Validation loss: 0.131000 Validation acc: 0.955555\n",
      "Epoch: 392/1000 Iteration: 3530 Train loss: 0.155798 Train acc: 0.955000\n",
      "Epoch: 392/1000 Iteration: 3535 Train loss: 0.157345 Train acc: 0.950000\n",
      "Epoch: 393/1000 Iteration: 3540 Train loss: 0.156433 Train acc: 0.945000\n",
      "Epoch: 393/1000 Iteration: 3545 Train loss: 0.137379 Train acc: 0.960000\n",
      "Epoch: 394/1000 Iteration: 3550 Train loss: 0.214125 Train acc: 0.923333\n",
      "Epoch: 394/1000 Iteration: 3550 Validation loss: 0.130384 Validation acc: 0.956111\n",
      "Epoch: 394/1000 Iteration: 3555 Train loss: 0.162509 Train acc: 0.950000\n",
      "Epoch: 395/1000 Iteration: 3560 Train loss: 0.148952 Train acc: 0.961667\n",
      "Epoch: 396/1000 Iteration: 3565 Train loss: 0.141931 Train acc: 0.961667\n",
      "Epoch: 396/1000 Iteration: 3570 Train loss: 0.143587 Train acc: 0.961667\n",
      "Epoch: 397/1000 Iteration: 3575 Train loss: 0.148661 Train acc: 0.956667\n",
      "Epoch: 397/1000 Iteration: 3575 Validation loss: 0.130551 Validation acc: 0.956667\n",
      "Epoch: 397/1000 Iteration: 3580 Train loss: 0.149011 Train acc: 0.955000\n",
      "Epoch: 398/1000 Iteration: 3585 Train loss: 0.157734 Train acc: 0.960000\n",
      "Epoch: 398/1000 Iteration: 3590 Train loss: 0.145652 Train acc: 0.955000\n",
      "Epoch: 399/1000 Iteration: 3595 Train loss: 0.185142 Train acc: 0.941667\n",
      "Epoch: 399/1000 Iteration: 3600 Train loss: 0.163762 Train acc: 0.955000\n",
      "Epoch: 399/1000 Iteration: 3600 Validation loss: 0.129676 Validation acc: 0.957222\n",
      "Epoch: 400/1000 Iteration: 3605 Train loss: 0.135933 Train acc: 0.965000\n",
      "Epoch: 401/1000 Iteration: 3610 Train loss: 0.144154 Train acc: 0.950000\n",
      "Epoch: 401/1000 Iteration: 3615 Train loss: 0.155776 Train acc: 0.951667\n",
      "Epoch: 402/1000 Iteration: 3620 Train loss: 0.143753 Train acc: 0.953333\n",
      "Epoch: 402/1000 Iteration: 3625 Train loss: 0.138896 Train acc: 0.955000\n",
      "Epoch: 402/1000 Iteration: 3625 Validation loss: 0.129478 Validation acc: 0.956111\n",
      "Epoch: 403/1000 Iteration: 3630 Train loss: 0.149352 Train acc: 0.953333\n",
      "Epoch: 403/1000 Iteration: 3635 Train loss: 0.142753 Train acc: 0.956667\n",
      "Epoch: 404/1000 Iteration: 3640 Train loss: 0.180656 Train acc: 0.940000\n",
      "Epoch: 404/1000 Iteration: 3645 Train loss: 0.163465 Train acc: 0.953333\n",
      "Epoch: 405/1000 Iteration: 3650 Train loss: 0.146064 Train acc: 0.956667\n",
      "Epoch: 405/1000 Iteration: 3650 Validation loss: 0.129357 Validation acc: 0.957222\n",
      "Epoch: 406/1000 Iteration: 3655 Train loss: 0.147336 Train acc: 0.960000\n",
      "Epoch: 406/1000 Iteration: 3660 Train loss: 0.137151 Train acc: 0.953333\n",
      "Epoch: 407/1000 Iteration: 3665 Train loss: 0.151447 Train acc: 0.955000\n",
      "Epoch: 407/1000 Iteration: 3670 Train loss: 0.144528 Train acc: 0.956667\n",
      "Epoch: 408/1000 Iteration: 3675 Train loss: 0.161414 Train acc: 0.941667\n",
      "Epoch: 408/1000 Iteration: 3675 Validation loss: 0.130102 Validation acc: 0.958333\n",
      "Epoch: 408/1000 Iteration: 3680 Train loss: 0.137112 Train acc: 0.968333\n",
      "Epoch: 409/1000 Iteration: 3685 Train loss: 0.200471 Train acc: 0.928333\n",
      "Epoch: 409/1000 Iteration: 3690 Train loss: 0.168076 Train acc: 0.946667\n",
      "Epoch: 410/1000 Iteration: 3695 Train loss: 0.151994 Train acc: 0.950000\n",
      "Epoch: 411/1000 Iteration: 3700 Train loss: 0.135506 Train acc: 0.965000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 411/1000 Iteration: 3700 Validation loss: 0.130574 Validation acc: 0.957778\n",
      "Epoch: 411/1000 Iteration: 3705 Train loss: 0.160015 Train acc: 0.948333\n",
      "Epoch: 412/1000 Iteration: 3710 Train loss: 0.160477 Train acc: 0.950000\n",
      "Epoch: 412/1000 Iteration: 3715 Train loss: 0.163775 Train acc: 0.943333\n",
      "Epoch: 413/1000 Iteration: 3720 Train loss: 0.158811 Train acc: 0.943333\n",
      "Epoch: 413/1000 Iteration: 3725 Train loss: 0.128445 Train acc: 0.965000\n",
      "Epoch: 413/1000 Iteration: 3725 Validation loss: 0.130519 Validation acc: 0.956667\n",
      "Epoch: 414/1000 Iteration: 3730 Train loss: 0.199005 Train acc: 0.940000\n",
      "Epoch: 414/1000 Iteration: 3735 Train loss: 0.186059 Train acc: 0.950000\n",
      "Epoch: 415/1000 Iteration: 3740 Train loss: 0.161261 Train acc: 0.958333\n",
      "Epoch: 416/1000 Iteration: 3745 Train loss: 0.147928 Train acc: 0.948333\n",
      "Epoch: 416/1000 Iteration: 3750 Train loss: 0.149787 Train acc: 0.951667\n",
      "Epoch: 416/1000 Iteration: 3750 Validation loss: 0.131373 Validation acc: 0.956111\n",
      "Epoch: 417/1000 Iteration: 3755 Train loss: 0.145965 Train acc: 0.958333\n",
      "Epoch: 417/1000 Iteration: 3760 Train loss: 0.152719 Train acc: 0.955000\n",
      "Epoch: 418/1000 Iteration: 3765 Train loss: 0.173265 Train acc: 0.938333\n",
      "Epoch: 418/1000 Iteration: 3770 Train loss: 0.132500 Train acc: 0.961667\n",
      "Epoch: 419/1000 Iteration: 3775 Train loss: 0.185981 Train acc: 0.928333\n",
      "Epoch: 419/1000 Iteration: 3775 Validation loss: 0.131541 Validation acc: 0.956111\n",
      "Epoch: 419/1000 Iteration: 3780 Train loss: 0.176675 Train acc: 0.948333\n",
      "Epoch: 420/1000 Iteration: 3785 Train loss: 0.138824 Train acc: 0.960000\n",
      "Epoch: 421/1000 Iteration: 3790 Train loss: 0.149733 Train acc: 0.955000\n",
      "Epoch: 421/1000 Iteration: 3795 Train loss: 0.126295 Train acc: 0.960000\n",
      "Epoch: 422/1000 Iteration: 3800 Train loss: 0.157528 Train acc: 0.951667\n",
      "Epoch: 422/1000 Iteration: 3800 Validation loss: 0.129278 Validation acc: 0.957222\n",
      "Epoch: 422/1000 Iteration: 3805 Train loss: 0.150694 Train acc: 0.956667\n",
      "Epoch: 423/1000 Iteration: 3810 Train loss: 0.154837 Train acc: 0.953333\n",
      "Epoch: 423/1000 Iteration: 3815 Train loss: 0.137604 Train acc: 0.956667\n",
      "Epoch: 424/1000 Iteration: 3820 Train loss: 0.203137 Train acc: 0.918333\n",
      "Epoch: 424/1000 Iteration: 3825 Train loss: 0.172125 Train acc: 0.945000\n",
      "Epoch: 424/1000 Iteration: 3825 Validation loss: 0.127435 Validation acc: 0.957778\n",
      "Epoch: 425/1000 Iteration: 3830 Train loss: 0.142933 Train acc: 0.958333\n",
      "Epoch: 426/1000 Iteration: 3835 Train loss: 0.145157 Train acc: 0.956667\n",
      "Epoch: 426/1000 Iteration: 3840 Train loss: 0.128734 Train acc: 0.963333\n",
      "Epoch: 427/1000 Iteration: 3845 Train loss: 0.139198 Train acc: 0.956667\n",
      "Epoch: 427/1000 Iteration: 3850 Train loss: 0.145087 Train acc: 0.956667\n",
      "Epoch: 427/1000 Iteration: 3850 Validation loss: 0.129923 Validation acc: 0.956111\n",
      "Epoch: 428/1000 Iteration: 3855 Train loss: 0.157727 Train acc: 0.955000\n",
      "Epoch: 428/1000 Iteration: 3860 Train loss: 0.125740 Train acc: 0.965000\n",
      "Epoch: 429/1000 Iteration: 3865 Train loss: 0.167944 Train acc: 0.948333\n",
      "Epoch: 429/1000 Iteration: 3870 Train loss: 0.157164 Train acc: 0.945000\n",
      "Epoch: 430/1000 Iteration: 3875 Train loss: 0.153302 Train acc: 0.950000\n",
      "Epoch: 430/1000 Iteration: 3875 Validation loss: 0.121350 Validation acc: 0.960000\n",
      "Epoch: 431/1000 Iteration: 3880 Train loss: 0.137117 Train acc: 0.958333\n",
      "Epoch: 431/1000 Iteration: 3885 Train loss: 0.150692 Train acc: 0.948333\n",
      "Epoch: 432/1000 Iteration: 3890 Train loss: 0.158809 Train acc: 0.960000\n",
      "Epoch: 432/1000 Iteration: 3895 Train loss: 0.152585 Train acc: 0.953333\n",
      "Epoch: 433/1000 Iteration: 3900 Train loss: 0.170282 Train acc: 0.945000\n",
      "Epoch: 433/1000 Iteration: 3900 Validation loss: 0.121936 Validation acc: 0.958889\n",
      "Epoch: 433/1000 Iteration: 3905 Train loss: 0.129979 Train acc: 0.963333\n",
      "Epoch: 434/1000 Iteration: 3910 Train loss: 0.177925 Train acc: 0.938333\n",
      "Epoch: 434/1000 Iteration: 3915 Train loss: 0.155641 Train acc: 0.953333\n",
      "Epoch: 435/1000 Iteration: 3920 Train loss: 0.151219 Train acc: 0.948333\n",
      "Epoch: 436/1000 Iteration: 3925 Train loss: 0.135741 Train acc: 0.960000\n",
      "Epoch: 436/1000 Iteration: 3925 Validation loss: 0.120353 Validation acc: 0.960556\n",
      "Epoch: 436/1000 Iteration: 3930 Train loss: 0.142449 Train acc: 0.953333\n",
      "Epoch: 437/1000 Iteration: 3935 Train loss: 0.136910 Train acc: 0.968333\n",
      "Epoch: 437/1000 Iteration: 3940 Train loss: 0.155509 Train acc: 0.958333\n",
      "Epoch: 438/1000 Iteration: 3945 Train loss: 0.166072 Train acc: 0.941667\n",
      "Epoch: 438/1000 Iteration: 3950 Train loss: 0.117864 Train acc: 0.966667\n",
      "Epoch: 438/1000 Iteration: 3950 Validation loss: 0.123555 Validation acc: 0.958889\n",
      "Epoch: 439/1000 Iteration: 3955 Train loss: 0.175526 Train acc: 0.938333\n",
      "Epoch: 439/1000 Iteration: 3960 Train loss: 0.160988 Train acc: 0.951667\n",
      "Epoch: 440/1000 Iteration: 3965 Train loss: 0.151018 Train acc: 0.950000\n",
      "Epoch: 441/1000 Iteration: 3970 Train loss: 0.143076 Train acc: 0.950000\n",
      "Epoch: 441/1000 Iteration: 3975 Train loss: 0.128036 Train acc: 0.965000\n",
      "Epoch: 441/1000 Iteration: 3975 Validation loss: 0.121918 Validation acc: 0.958333\n",
      "Epoch: 442/1000 Iteration: 3980 Train loss: 0.145234 Train acc: 0.956667\n",
      "Epoch: 442/1000 Iteration: 3985 Train loss: 0.153252 Train acc: 0.946667\n",
      "Epoch: 443/1000 Iteration: 3990 Train loss: 0.154996 Train acc: 0.948333\n",
      "Epoch: 443/1000 Iteration: 3995 Train loss: 0.135670 Train acc: 0.960000\n",
      "Epoch: 444/1000 Iteration: 4000 Train loss: 0.186172 Train acc: 0.938333\n",
      "Epoch: 444/1000 Iteration: 4000 Validation loss: 0.123922 Validation acc: 0.958333\n",
      "Epoch: 444/1000 Iteration: 4005 Train loss: 0.163422 Train acc: 0.941667\n",
      "Epoch: 445/1000 Iteration: 4010 Train loss: 0.147414 Train acc: 0.951667\n",
      "Epoch: 446/1000 Iteration: 4015 Train loss: 0.150060 Train acc: 0.946667\n",
      "Epoch: 446/1000 Iteration: 4020 Train loss: 0.142067 Train acc: 0.958333\n",
      "Epoch: 447/1000 Iteration: 4025 Train loss: 0.139824 Train acc: 0.961667\n",
      "Epoch: 447/1000 Iteration: 4025 Validation loss: 0.125477 Validation acc: 0.957778\n",
      "Epoch: 447/1000 Iteration: 4030 Train loss: 0.136353 Train acc: 0.965000\n",
      "Epoch: 448/1000 Iteration: 4035 Train loss: 0.153877 Train acc: 0.946667\n",
      "Epoch: 448/1000 Iteration: 4040 Train loss: 0.125008 Train acc: 0.961667\n",
      "Epoch: 449/1000 Iteration: 4045 Train loss: 0.169827 Train acc: 0.936667\n",
      "Epoch: 449/1000 Iteration: 4050 Train loss: 0.169467 Train acc: 0.940000\n",
      "Epoch: 449/1000 Iteration: 4050 Validation loss: 0.123288 Validation acc: 0.957222\n",
      "Epoch: 450/1000 Iteration: 4055 Train loss: 0.150115 Train acc: 0.951667\n",
      "Epoch: 451/1000 Iteration: 4060 Train loss: 0.149877 Train acc: 0.953333\n",
      "Epoch: 451/1000 Iteration: 4065 Train loss: 0.139680 Train acc: 0.950000\n",
      "Epoch: 452/1000 Iteration: 4070 Train loss: 0.155587 Train acc: 0.950000\n",
      "Epoch: 452/1000 Iteration: 4075 Train loss: 0.131853 Train acc: 0.963333\n",
      "Epoch: 452/1000 Iteration: 4075 Validation loss: 0.122636 Validation acc: 0.958333\n",
      "Epoch: 453/1000 Iteration: 4080 Train loss: 0.161049 Train acc: 0.946667\n",
      "Epoch: 453/1000 Iteration: 4085 Train loss: 0.126398 Train acc: 0.966667\n",
      "Epoch: 454/1000 Iteration: 4090 Train loss: 0.183275 Train acc: 0.933333\n",
      "Epoch: 454/1000 Iteration: 4095 Train loss: 0.169404 Train acc: 0.945000\n",
      "Epoch: 455/1000 Iteration: 4100 Train loss: 0.141053 Train acc: 0.948333\n",
      "Epoch: 455/1000 Iteration: 4100 Validation loss: 0.124394 Validation acc: 0.956111\n",
      "Epoch: 456/1000 Iteration: 4105 Train loss: 0.148854 Train acc: 0.956667\n",
      "Epoch: 456/1000 Iteration: 4110 Train loss: 0.135527 Train acc: 0.958333\n",
      "Epoch: 457/1000 Iteration: 4115 Train loss: 0.138548 Train acc: 0.956667\n",
      "Epoch: 457/1000 Iteration: 4120 Train loss: 0.149236 Train acc: 0.956667\n",
      "Epoch: 458/1000 Iteration: 4125 Train loss: 0.142784 Train acc: 0.951667\n",
      "Epoch: 458/1000 Iteration: 4125 Validation loss: 0.124587 Validation acc: 0.956667\n",
      "Epoch: 458/1000 Iteration: 4130 Train loss: 0.135892 Train acc: 0.953333\n",
      "Epoch: 459/1000 Iteration: 4135 Train loss: 0.189856 Train acc: 0.941667\n",
      "Epoch: 459/1000 Iteration: 4140 Train loss: 0.154078 Train acc: 0.950000\n",
      "Epoch: 460/1000 Iteration: 4145 Train loss: 0.134520 Train acc: 0.955000\n",
      "Epoch: 461/1000 Iteration: 4150 Train loss: 0.127364 Train acc: 0.963333\n",
      "Epoch: 461/1000 Iteration: 4150 Validation loss: 0.126061 Validation acc: 0.956667\n",
      "Epoch: 461/1000 Iteration: 4155 Train loss: 0.131684 Train acc: 0.956667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 462/1000 Iteration: 4160 Train loss: 0.140730 Train acc: 0.963333\n",
      "Epoch: 462/1000 Iteration: 4165 Train loss: 0.136875 Train acc: 0.958333\n",
      "Epoch: 463/1000 Iteration: 4170 Train loss: 0.167496 Train acc: 0.940000\n",
      "Epoch: 463/1000 Iteration: 4175 Train loss: 0.127059 Train acc: 0.965000\n",
      "Epoch: 463/1000 Iteration: 4175 Validation loss: 0.128712 Validation acc: 0.956667\n",
      "Epoch: 464/1000 Iteration: 4180 Train loss: 0.158310 Train acc: 0.943333\n",
      "Epoch: 464/1000 Iteration: 4185 Train loss: 0.158755 Train acc: 0.950000\n",
      "Epoch: 465/1000 Iteration: 4190 Train loss: 0.136946 Train acc: 0.953333\n",
      "Epoch: 466/1000 Iteration: 4195 Train loss: 0.138255 Train acc: 0.953333\n",
      "Epoch: 466/1000 Iteration: 4200 Train loss: 0.147566 Train acc: 0.953333\n",
      "Epoch: 466/1000 Iteration: 4200 Validation loss: 0.125975 Validation acc: 0.956667\n",
      "Epoch: 467/1000 Iteration: 4205 Train loss: 0.145466 Train acc: 0.960000\n",
      "Epoch: 467/1000 Iteration: 4210 Train loss: 0.135918 Train acc: 0.953333\n",
      "Epoch: 468/1000 Iteration: 4215 Train loss: 0.155406 Train acc: 0.938333\n",
      "Epoch: 468/1000 Iteration: 4220 Train loss: 0.127410 Train acc: 0.963333\n",
      "Epoch: 469/1000 Iteration: 4225 Train loss: 0.173632 Train acc: 0.930000\n",
      "Epoch: 469/1000 Iteration: 4225 Validation loss: 0.125986 Validation acc: 0.956111\n",
      "Epoch: 469/1000 Iteration: 4230 Train loss: 0.156955 Train acc: 0.946667\n",
      "Epoch: 470/1000 Iteration: 4235 Train loss: 0.139350 Train acc: 0.951667\n",
      "Epoch: 471/1000 Iteration: 4240 Train loss: 0.139957 Train acc: 0.968333\n",
      "Epoch: 471/1000 Iteration: 4245 Train loss: 0.147835 Train acc: 0.955000\n",
      "Epoch: 472/1000 Iteration: 4250 Train loss: 0.147064 Train acc: 0.956667\n",
      "Epoch: 472/1000 Iteration: 4250 Validation loss: 0.125269 Validation acc: 0.958333\n",
      "Epoch: 472/1000 Iteration: 4255 Train loss: 0.142494 Train acc: 0.950000\n",
      "Epoch: 473/1000 Iteration: 4260 Train loss: 0.164630 Train acc: 0.951667\n",
      "Epoch: 473/1000 Iteration: 4265 Train loss: 0.118578 Train acc: 0.961667\n",
      "Epoch: 474/1000 Iteration: 4270 Train loss: 0.167517 Train acc: 0.940000\n",
      "Epoch: 474/1000 Iteration: 4275 Train loss: 0.158639 Train acc: 0.956667\n",
      "Epoch: 474/1000 Iteration: 4275 Validation loss: 0.125917 Validation acc: 0.957778\n",
      "Epoch: 475/1000 Iteration: 4280 Train loss: 0.129222 Train acc: 0.960000\n",
      "Epoch: 476/1000 Iteration: 4285 Train loss: 0.135104 Train acc: 0.961667\n",
      "Epoch: 476/1000 Iteration: 4290 Train loss: 0.123031 Train acc: 0.966667\n",
      "Epoch: 477/1000 Iteration: 4295 Train loss: 0.141195 Train acc: 0.960000\n",
      "Epoch: 477/1000 Iteration: 4300 Train loss: 0.143129 Train acc: 0.946667\n",
      "Epoch: 477/1000 Iteration: 4300 Validation loss: 0.129496 Validation acc: 0.956111\n",
      "Epoch: 478/1000 Iteration: 4305 Train loss: 0.155761 Train acc: 0.948333\n",
      "Epoch: 478/1000 Iteration: 4310 Train loss: 0.122208 Train acc: 0.963333\n",
      "Epoch: 479/1000 Iteration: 4315 Train loss: 0.171534 Train acc: 0.945000\n",
      "Epoch: 479/1000 Iteration: 4320 Train loss: 0.158969 Train acc: 0.951667\n",
      "Epoch: 480/1000 Iteration: 4325 Train loss: 0.133492 Train acc: 0.956667\n",
      "Epoch: 480/1000 Iteration: 4325 Validation loss: 0.126573 Validation acc: 0.956667\n",
      "Epoch: 481/1000 Iteration: 4330 Train loss: 0.132743 Train acc: 0.956667\n",
      "Epoch: 481/1000 Iteration: 4335 Train loss: 0.132303 Train acc: 0.956667\n",
      "Epoch: 482/1000 Iteration: 4340 Train loss: 0.146466 Train acc: 0.965000\n",
      "Epoch: 482/1000 Iteration: 4345 Train loss: 0.121834 Train acc: 0.958333\n",
      "Epoch: 483/1000 Iteration: 4350 Train loss: 0.144822 Train acc: 0.955000\n",
      "Epoch: 483/1000 Iteration: 4350 Validation loss: 0.125779 Validation acc: 0.956667\n",
      "Epoch: 483/1000 Iteration: 4355 Train loss: 0.119149 Train acc: 0.965000\n",
      "Epoch: 484/1000 Iteration: 4360 Train loss: 0.167582 Train acc: 0.931667\n",
      "Epoch: 484/1000 Iteration: 4365 Train loss: 0.142866 Train acc: 0.951667\n",
      "Epoch: 485/1000 Iteration: 4370 Train loss: 0.130569 Train acc: 0.961667\n",
      "Epoch: 486/1000 Iteration: 4375 Train loss: 0.145380 Train acc: 0.950000\n",
      "Epoch: 486/1000 Iteration: 4375 Validation loss: 0.125063 Validation acc: 0.958333\n",
      "Epoch: 486/1000 Iteration: 4380 Train loss: 0.127064 Train acc: 0.958333\n",
      "Epoch: 487/1000 Iteration: 4385 Train loss: 0.133051 Train acc: 0.963333\n",
      "Epoch: 487/1000 Iteration: 4390 Train loss: 0.148453 Train acc: 0.948333\n",
      "Epoch: 488/1000 Iteration: 4395 Train loss: 0.149368 Train acc: 0.953333\n",
      "Epoch: 488/1000 Iteration: 4400 Train loss: 0.127487 Train acc: 0.960000\n",
      "Epoch: 488/1000 Iteration: 4400 Validation loss: 0.127433 Validation acc: 0.955000\n",
      "Epoch: 489/1000 Iteration: 4405 Train loss: 0.172561 Train acc: 0.935000\n",
      "Epoch: 489/1000 Iteration: 4410 Train loss: 0.149270 Train acc: 0.958333\n",
      "Epoch: 490/1000 Iteration: 4415 Train loss: 0.120744 Train acc: 0.960000\n",
      "Epoch: 491/1000 Iteration: 4420 Train loss: 0.142645 Train acc: 0.955000\n",
      "Epoch: 491/1000 Iteration: 4425 Train loss: 0.129391 Train acc: 0.960000\n",
      "Epoch: 491/1000 Iteration: 4425 Validation loss: 0.127297 Validation acc: 0.957222\n",
      "Epoch: 492/1000 Iteration: 4430 Train loss: 0.123916 Train acc: 0.965000\n",
      "Epoch: 492/1000 Iteration: 4435 Train loss: 0.133605 Train acc: 0.958333\n",
      "Epoch: 493/1000 Iteration: 4440 Train loss: 0.141061 Train acc: 0.946667\n",
      "Epoch: 493/1000 Iteration: 4445 Train loss: 0.125560 Train acc: 0.968333\n",
      "Epoch: 494/1000 Iteration: 4450 Train loss: 0.167479 Train acc: 0.943333\n",
      "Epoch: 494/1000 Iteration: 4450 Validation loss: 0.126061 Validation acc: 0.956667\n",
      "Epoch: 494/1000 Iteration: 4455 Train loss: 0.161935 Train acc: 0.953333\n",
      "Epoch: 495/1000 Iteration: 4460 Train loss: 0.128620 Train acc: 0.956667\n",
      "Epoch: 496/1000 Iteration: 4465 Train loss: 0.142380 Train acc: 0.948333\n",
      "Epoch: 496/1000 Iteration: 4470 Train loss: 0.116000 Train acc: 0.965000\n",
      "Epoch: 497/1000 Iteration: 4475 Train loss: 0.142717 Train acc: 0.948333\n",
      "Epoch: 497/1000 Iteration: 4475 Validation loss: 0.128451 Validation acc: 0.957222\n",
      "Epoch: 497/1000 Iteration: 4480 Train loss: 0.131354 Train acc: 0.958333\n",
      "Epoch: 498/1000 Iteration: 4485 Train loss: 0.149070 Train acc: 0.950000\n",
      "Epoch: 498/1000 Iteration: 4490 Train loss: 0.115511 Train acc: 0.970000\n",
      "Epoch: 499/1000 Iteration: 4495 Train loss: 0.163510 Train acc: 0.938333\n",
      "Epoch: 499/1000 Iteration: 4500 Train loss: 0.149872 Train acc: 0.951667\n",
      "Epoch: 499/1000 Iteration: 4500 Validation loss: 0.127221 Validation acc: 0.955555\n",
      "Epoch: 500/1000 Iteration: 4505 Train loss: 0.144981 Train acc: 0.950000\n",
      "Epoch: 501/1000 Iteration: 4510 Train loss: 0.137544 Train acc: 0.958333\n",
      "Epoch: 501/1000 Iteration: 4515 Train loss: 0.126346 Train acc: 0.963333\n",
      "Epoch: 502/1000 Iteration: 4520 Train loss: 0.139491 Train acc: 0.965000\n",
      "Epoch: 502/1000 Iteration: 4525 Train loss: 0.136433 Train acc: 0.956667\n",
      "Epoch: 502/1000 Iteration: 4525 Validation loss: 0.127326 Validation acc: 0.955000\n",
      "Epoch: 503/1000 Iteration: 4530 Train loss: 0.142794 Train acc: 0.953333\n",
      "Epoch: 503/1000 Iteration: 4535 Train loss: 0.131441 Train acc: 0.958333\n",
      "Epoch: 504/1000 Iteration: 4540 Train loss: 0.159363 Train acc: 0.941667\n",
      "Epoch: 504/1000 Iteration: 4545 Train loss: 0.155297 Train acc: 0.953333\n",
      "Epoch: 505/1000 Iteration: 4550 Train loss: 0.126771 Train acc: 0.955000\n",
      "Epoch: 505/1000 Iteration: 4550 Validation loss: 0.126717 Validation acc: 0.956111\n",
      "Epoch: 506/1000 Iteration: 4555 Train loss: 0.123579 Train acc: 0.956667\n",
      "Epoch: 506/1000 Iteration: 4560 Train loss: 0.124753 Train acc: 0.966667\n",
      "Epoch: 507/1000 Iteration: 4565 Train loss: 0.134020 Train acc: 0.961667\n",
      "Epoch: 507/1000 Iteration: 4570 Train loss: 0.141672 Train acc: 0.945000\n",
      "Epoch: 508/1000 Iteration: 4575 Train loss: 0.149744 Train acc: 0.951667\n",
      "Epoch: 508/1000 Iteration: 4575 Validation loss: 0.126313 Validation acc: 0.956667\n",
      "Epoch: 508/1000 Iteration: 4580 Train loss: 0.115361 Train acc: 0.963333\n",
      "Epoch: 509/1000 Iteration: 4585 Train loss: 0.165146 Train acc: 0.931667\n",
      "Epoch: 509/1000 Iteration: 4590 Train loss: 0.166108 Train acc: 0.948333\n",
      "Epoch: 510/1000 Iteration: 4595 Train loss: 0.138487 Train acc: 0.948333\n",
      "Epoch: 511/1000 Iteration: 4600 Train loss: 0.139009 Train acc: 0.961667\n",
      "Epoch: 511/1000 Iteration: 4600 Validation loss: 0.131232 Validation acc: 0.955555\n",
      "Epoch: 511/1000 Iteration: 4605 Train loss: 0.125165 Train acc: 0.970000\n",
      "Epoch: 512/1000 Iteration: 4610 Train loss: 0.118254 Train acc: 0.971667\n",
      "Epoch: 512/1000 Iteration: 4615 Train loss: 0.134934 Train acc: 0.961667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 513/1000 Iteration: 4620 Train loss: 0.160280 Train acc: 0.940000\n",
      "Epoch: 513/1000 Iteration: 4625 Train loss: 0.113009 Train acc: 0.965000\n",
      "Epoch: 513/1000 Iteration: 4625 Validation loss: 0.121173 Validation acc: 0.957778\n",
      "Epoch: 514/1000 Iteration: 4630 Train loss: 0.172607 Train acc: 0.930000\n",
      "Epoch: 514/1000 Iteration: 4635 Train loss: 0.158868 Train acc: 0.946667\n",
      "Epoch: 515/1000 Iteration: 4640 Train loss: 0.124170 Train acc: 0.960000\n",
      "Epoch: 516/1000 Iteration: 4645 Train loss: 0.126488 Train acc: 0.961667\n",
      "Epoch: 516/1000 Iteration: 4650 Train loss: 0.120044 Train acc: 0.963333\n",
      "Epoch: 516/1000 Iteration: 4650 Validation loss: 0.120756 Validation acc: 0.957778\n",
      "Epoch: 517/1000 Iteration: 4655 Train loss: 0.132433 Train acc: 0.963333\n",
      "Epoch: 517/1000 Iteration: 4660 Train loss: 0.138992 Train acc: 0.958333\n",
      "Epoch: 518/1000 Iteration: 4665 Train loss: 0.153535 Train acc: 0.948333\n",
      "Epoch: 518/1000 Iteration: 4670 Train loss: 0.111910 Train acc: 0.970000\n",
      "Epoch: 519/1000 Iteration: 4675 Train loss: 0.171731 Train acc: 0.925000\n",
      "Epoch: 519/1000 Iteration: 4675 Validation loss: 0.122668 Validation acc: 0.957222\n",
      "Epoch: 519/1000 Iteration: 4680 Train loss: 0.148042 Train acc: 0.951667\n",
      "Epoch: 520/1000 Iteration: 4685 Train loss: 0.126219 Train acc: 0.956667\n",
      "Epoch: 521/1000 Iteration: 4690 Train loss: 0.139067 Train acc: 0.961667\n",
      "Epoch: 521/1000 Iteration: 4695 Train loss: 0.124796 Train acc: 0.963333\n",
      "Epoch: 522/1000 Iteration: 4700 Train loss: 0.117586 Train acc: 0.956667\n",
      "Epoch: 522/1000 Iteration: 4700 Validation loss: 0.123018 Validation acc: 0.957778\n",
      "Epoch: 522/1000 Iteration: 4705 Train loss: 0.133867 Train acc: 0.955000\n",
      "Epoch: 523/1000 Iteration: 4710 Train loss: 0.160685 Train acc: 0.945000\n",
      "Epoch: 523/1000 Iteration: 4715 Train loss: 0.121981 Train acc: 0.956667\n",
      "Epoch: 524/1000 Iteration: 4720 Train loss: 0.169735 Train acc: 0.943333\n",
      "Epoch: 524/1000 Iteration: 4725 Train loss: 0.154114 Train acc: 0.951667\n",
      "Epoch: 524/1000 Iteration: 4725 Validation loss: 0.123460 Validation acc: 0.956667\n",
      "Epoch: 525/1000 Iteration: 4730 Train loss: 0.138494 Train acc: 0.945000\n",
      "Epoch: 526/1000 Iteration: 4735 Train loss: 0.130908 Train acc: 0.970000\n",
      "Epoch: 526/1000 Iteration: 4740 Train loss: 0.132817 Train acc: 0.956667\n",
      "Epoch: 527/1000 Iteration: 4745 Train loss: 0.121157 Train acc: 0.961667\n",
      "Epoch: 527/1000 Iteration: 4750 Train loss: 0.135234 Train acc: 0.955000\n",
      "Epoch: 527/1000 Iteration: 4750 Validation loss: 0.123131 Validation acc: 0.957222\n",
      "Epoch: 528/1000 Iteration: 4755 Train loss: 0.148543 Train acc: 0.955000\n",
      "Epoch: 528/1000 Iteration: 4760 Train loss: 0.119508 Train acc: 0.955000\n",
      "Epoch: 529/1000 Iteration: 4765 Train loss: 0.171772 Train acc: 0.938333\n",
      "Epoch: 529/1000 Iteration: 4770 Train loss: 0.150125 Train acc: 0.958333\n",
      "Epoch: 530/1000 Iteration: 4775 Train loss: 0.126241 Train acc: 0.956667\n",
      "Epoch: 530/1000 Iteration: 4775 Validation loss: 0.125944 Validation acc: 0.956111\n",
      "Epoch: 531/1000 Iteration: 4780 Train loss: 0.134488 Train acc: 0.953333\n",
      "Epoch: 531/1000 Iteration: 4785 Train loss: 0.110473 Train acc: 0.966667\n",
      "Epoch: 532/1000 Iteration: 4790 Train loss: 0.130171 Train acc: 0.966667\n",
      "Epoch: 532/1000 Iteration: 4795 Train loss: 0.137259 Train acc: 0.951667\n",
      "Epoch: 533/1000 Iteration: 4800 Train loss: 0.146331 Train acc: 0.948333\n",
      "Epoch: 533/1000 Iteration: 4800 Validation loss: 0.124548 Validation acc: 0.956667\n",
      "Epoch: 533/1000 Iteration: 4805 Train loss: 0.112951 Train acc: 0.966667\n",
      "Epoch: 534/1000 Iteration: 4810 Train loss: 0.164099 Train acc: 0.950000\n",
      "Epoch: 534/1000 Iteration: 4815 Train loss: 0.147560 Train acc: 0.948333\n",
      "Epoch: 535/1000 Iteration: 4820 Train loss: 0.135098 Train acc: 0.948333\n",
      "Epoch: 536/1000 Iteration: 4825 Train loss: 0.128228 Train acc: 0.958333\n",
      "Epoch: 536/1000 Iteration: 4825 Validation loss: 0.125476 Validation acc: 0.956667\n",
      "Epoch: 536/1000 Iteration: 4830 Train loss: 0.113347 Train acc: 0.966667\n",
      "Epoch: 537/1000 Iteration: 4835 Train loss: 0.139404 Train acc: 0.963333\n",
      "Epoch: 537/1000 Iteration: 4840 Train loss: 0.133818 Train acc: 0.951667\n",
      "Epoch: 538/1000 Iteration: 4845 Train loss: 0.129512 Train acc: 0.960000\n",
      "Epoch: 538/1000 Iteration: 4850 Train loss: 0.113405 Train acc: 0.965000\n",
      "Epoch: 538/1000 Iteration: 4850 Validation loss: 0.122920 Validation acc: 0.957222\n",
      "Epoch: 539/1000 Iteration: 4855 Train loss: 0.160126 Train acc: 0.935000\n",
      "Epoch: 539/1000 Iteration: 4860 Train loss: 0.140248 Train acc: 0.953333\n",
      "Epoch: 540/1000 Iteration: 4865 Train loss: 0.120123 Train acc: 0.956667\n",
      "Epoch: 541/1000 Iteration: 4870 Train loss: 0.130808 Train acc: 0.960000\n",
      "Epoch: 541/1000 Iteration: 4875 Train loss: 0.109359 Train acc: 0.966667\n",
      "Epoch: 541/1000 Iteration: 4875 Validation loss: 0.126355 Validation acc: 0.954444\n",
      "Epoch: 542/1000 Iteration: 4880 Train loss: 0.139530 Train acc: 0.958333\n",
      "Epoch: 542/1000 Iteration: 4885 Train loss: 0.140255 Train acc: 0.956667\n",
      "Epoch: 543/1000 Iteration: 4890 Train loss: 0.146762 Train acc: 0.951667\n",
      "Epoch: 543/1000 Iteration: 4895 Train loss: 0.121715 Train acc: 0.961667\n",
      "Epoch: 544/1000 Iteration: 4900 Train loss: 0.177630 Train acc: 0.928333\n",
      "Epoch: 544/1000 Iteration: 4900 Validation loss: 0.119403 Validation acc: 0.957778\n",
      "Epoch: 544/1000 Iteration: 4905 Train loss: 0.146020 Train acc: 0.955000\n",
      "Epoch: 545/1000 Iteration: 4910 Train loss: 0.118927 Train acc: 0.965000\n",
      "Epoch: 546/1000 Iteration: 4915 Train loss: 0.131516 Train acc: 0.953333\n",
      "Epoch: 546/1000 Iteration: 4920 Train loss: 0.125036 Train acc: 0.958333\n",
      "Epoch: 547/1000 Iteration: 4925 Train loss: 0.147277 Train acc: 0.950000\n",
      "Epoch: 547/1000 Iteration: 4925 Validation loss: 0.130610 Validation acc: 0.952778\n",
      "Epoch: 547/1000 Iteration: 4930 Train loss: 0.145447 Train acc: 0.956667\n",
      "Epoch: 548/1000 Iteration: 4935 Train loss: 0.139072 Train acc: 0.953333\n",
      "Epoch: 548/1000 Iteration: 4940 Train loss: 0.115909 Train acc: 0.968333\n",
      "Epoch: 549/1000 Iteration: 4945 Train loss: 0.150490 Train acc: 0.936667\n",
      "Epoch: 549/1000 Iteration: 4950 Train loss: 0.145132 Train acc: 0.953333\n",
      "Epoch: 549/1000 Iteration: 4950 Validation loss: 0.123219 Validation acc: 0.958889\n",
      "Epoch: 550/1000 Iteration: 4955 Train loss: 0.139084 Train acc: 0.951667\n",
      "Epoch: 551/1000 Iteration: 4960 Train loss: 0.123851 Train acc: 0.961667\n",
      "Epoch: 551/1000 Iteration: 4965 Train loss: 0.122879 Train acc: 0.963333\n",
      "Epoch: 552/1000 Iteration: 4970 Train loss: 0.131623 Train acc: 0.958333\n",
      "Epoch: 552/1000 Iteration: 4975 Train loss: 0.126794 Train acc: 0.955000\n",
      "Epoch: 552/1000 Iteration: 4975 Validation loss: 0.122722 Validation acc: 0.957778\n",
      "Epoch: 553/1000 Iteration: 4980 Train loss: 0.152736 Train acc: 0.948333\n",
      "Epoch: 553/1000 Iteration: 4985 Train loss: 0.103880 Train acc: 0.973333\n",
      "Epoch: 554/1000 Iteration: 4990 Train loss: 0.155041 Train acc: 0.945000\n",
      "Epoch: 554/1000 Iteration: 4995 Train loss: 0.158842 Train acc: 0.951667\n",
      "Epoch: 555/1000 Iteration: 5000 Train loss: 0.120449 Train acc: 0.963333\n",
      "Epoch: 555/1000 Iteration: 5000 Validation loss: 0.123194 Validation acc: 0.957778\n",
      "Epoch: 556/1000 Iteration: 5005 Train loss: 0.135313 Train acc: 0.955000\n",
      "Epoch: 556/1000 Iteration: 5010 Train loss: 0.113868 Train acc: 0.965000\n",
      "Epoch: 557/1000 Iteration: 5015 Train loss: 0.120882 Train acc: 0.958333\n",
      "Epoch: 557/1000 Iteration: 5020 Train loss: 0.123520 Train acc: 0.960000\n",
      "Epoch: 558/1000 Iteration: 5025 Train loss: 0.143505 Train acc: 0.950000\n",
      "Epoch: 558/1000 Iteration: 5025 Validation loss: 0.123701 Validation acc: 0.957222\n",
      "Epoch: 558/1000 Iteration: 5030 Train loss: 0.110761 Train acc: 0.966667\n",
      "Epoch: 559/1000 Iteration: 5035 Train loss: 0.172228 Train acc: 0.935000\n",
      "Epoch: 559/1000 Iteration: 5040 Train loss: 0.145586 Train acc: 0.961667\n",
      "Epoch: 560/1000 Iteration: 5045 Train loss: 0.135420 Train acc: 0.956667\n",
      "Epoch: 561/1000 Iteration: 5050 Train loss: 0.134522 Train acc: 0.953333\n",
      "Epoch: 561/1000 Iteration: 5050 Validation loss: 0.123241 Validation acc: 0.956111\n",
      "Epoch: 561/1000 Iteration: 5055 Train loss: 0.111459 Train acc: 0.966667\n",
      "Epoch: 562/1000 Iteration: 5060 Train loss: 0.117745 Train acc: 0.968333\n",
      "Epoch: 562/1000 Iteration: 5065 Train loss: 0.121965 Train acc: 0.960000\n",
      "Epoch: 563/1000 Iteration: 5070 Train loss: 0.145481 Train acc: 0.941667\n",
      "Epoch: 563/1000 Iteration: 5075 Train loss: 0.120206 Train acc: 0.965000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 563/1000 Iteration: 5075 Validation loss: 0.122661 Validation acc: 0.957222\n",
      "Epoch: 564/1000 Iteration: 5080 Train loss: 0.166620 Train acc: 0.940000\n",
      "Epoch: 564/1000 Iteration: 5085 Train loss: 0.141772 Train acc: 0.958333\n",
      "Epoch: 565/1000 Iteration: 5090 Train loss: 0.127244 Train acc: 0.956667\n",
      "Epoch: 566/1000 Iteration: 5095 Train loss: 0.128553 Train acc: 0.953333\n",
      "Epoch: 566/1000 Iteration: 5100 Train loss: 0.114651 Train acc: 0.968333\n",
      "Epoch: 566/1000 Iteration: 5100 Validation loss: 0.122639 Validation acc: 0.955555\n",
      "Epoch: 567/1000 Iteration: 5105 Train loss: 0.121809 Train acc: 0.963333\n",
      "Epoch: 567/1000 Iteration: 5110 Train loss: 0.130333 Train acc: 0.948333\n",
      "Epoch: 568/1000 Iteration: 5115 Train loss: 0.131419 Train acc: 0.948333\n",
      "Epoch: 568/1000 Iteration: 5120 Train loss: 0.113967 Train acc: 0.975000\n",
      "Epoch: 569/1000 Iteration: 5125 Train loss: 0.167595 Train acc: 0.941667\n",
      "Epoch: 569/1000 Iteration: 5125 Validation loss: 0.121520 Validation acc: 0.957222\n",
      "Epoch: 569/1000 Iteration: 5130 Train loss: 0.143486 Train acc: 0.951667\n",
      "Epoch: 570/1000 Iteration: 5135 Train loss: 0.134874 Train acc: 0.955000\n",
      "Epoch: 571/1000 Iteration: 5140 Train loss: 0.141888 Train acc: 0.951667\n",
      "Epoch: 571/1000 Iteration: 5145 Train loss: 0.116373 Train acc: 0.968333\n",
      "Epoch: 572/1000 Iteration: 5150 Train loss: 0.138665 Train acc: 0.956667\n",
      "Epoch: 572/1000 Iteration: 5150 Validation loss: 0.122780 Validation acc: 0.956111\n",
      "Epoch: 572/1000 Iteration: 5155 Train loss: 0.123295 Train acc: 0.960000\n",
      "Epoch: 573/1000 Iteration: 5160 Train loss: 0.136314 Train acc: 0.955000\n",
      "Epoch: 573/1000 Iteration: 5165 Train loss: 0.106888 Train acc: 0.965000\n",
      "Epoch: 574/1000 Iteration: 5170 Train loss: 0.155780 Train acc: 0.946667\n",
      "Epoch: 574/1000 Iteration: 5175 Train loss: 0.143067 Train acc: 0.950000\n",
      "Epoch: 574/1000 Iteration: 5175 Validation loss: 0.123724 Validation acc: 0.956111\n",
      "Epoch: 575/1000 Iteration: 5180 Train loss: 0.124545 Train acc: 0.960000\n",
      "Epoch: 576/1000 Iteration: 5185 Train loss: 0.130527 Train acc: 0.958333\n",
      "Epoch: 576/1000 Iteration: 5190 Train loss: 0.111993 Train acc: 0.966667\n",
      "Epoch: 577/1000 Iteration: 5195 Train loss: 0.123368 Train acc: 0.960000\n",
      "Epoch: 577/1000 Iteration: 5200 Train loss: 0.117336 Train acc: 0.960000\n",
      "Epoch: 577/1000 Iteration: 5200 Validation loss: 0.122601 Validation acc: 0.957778\n",
      "Epoch: 578/1000 Iteration: 5205 Train loss: 0.140826 Train acc: 0.948333\n",
      "Epoch: 578/1000 Iteration: 5210 Train loss: 0.111908 Train acc: 0.966667\n",
      "Epoch: 579/1000 Iteration: 5215 Train loss: 0.156211 Train acc: 0.930000\n",
      "Epoch: 579/1000 Iteration: 5220 Train loss: 0.133796 Train acc: 0.956667\n",
      "Epoch: 580/1000 Iteration: 5225 Train loss: 0.133536 Train acc: 0.956667\n",
      "Epoch: 580/1000 Iteration: 5225 Validation loss: 0.119450 Validation acc: 0.957222\n",
      "Epoch: 581/1000 Iteration: 5230 Train loss: 0.123558 Train acc: 0.960000\n",
      "Epoch: 581/1000 Iteration: 5235 Train loss: 0.128832 Train acc: 0.955000\n",
      "Epoch: 582/1000 Iteration: 5240 Train loss: 0.134218 Train acc: 0.950000\n",
      "Epoch: 582/1000 Iteration: 5245 Train loss: 0.129818 Train acc: 0.958333\n",
      "Epoch: 583/1000 Iteration: 5250 Train loss: 0.134554 Train acc: 0.950000\n",
      "Epoch: 583/1000 Iteration: 5250 Validation loss: 0.118422 Validation acc: 0.957222\n",
      "Epoch: 583/1000 Iteration: 5255 Train loss: 0.118889 Train acc: 0.960000\n",
      "Epoch: 584/1000 Iteration: 5260 Train loss: 0.161418 Train acc: 0.940000\n",
      "Epoch: 584/1000 Iteration: 5265 Train loss: 0.133948 Train acc: 0.955000\n",
      "Epoch: 585/1000 Iteration: 5270 Train loss: 0.133250 Train acc: 0.950000\n",
      "Epoch: 586/1000 Iteration: 5275 Train loss: 0.123766 Train acc: 0.956667\n",
      "Epoch: 586/1000 Iteration: 5275 Validation loss: 0.116466 Validation acc: 0.957222\n",
      "Epoch: 586/1000 Iteration: 5280 Train loss: 0.103703 Train acc: 0.970000\n",
      "Epoch: 587/1000 Iteration: 5285 Train loss: 0.128969 Train acc: 0.955000\n",
      "Epoch: 587/1000 Iteration: 5290 Train loss: 0.113570 Train acc: 0.961667\n",
      "Epoch: 588/1000 Iteration: 5295 Train loss: 0.121993 Train acc: 0.955000\n",
      "Epoch: 588/1000 Iteration: 5300 Train loss: 0.095842 Train acc: 0.971667\n",
      "Epoch: 588/1000 Iteration: 5300 Validation loss: 0.116869 Validation acc: 0.957222\n",
      "Epoch: 589/1000 Iteration: 5305 Train loss: 0.156625 Train acc: 0.945000\n",
      "Epoch: 589/1000 Iteration: 5310 Train loss: 0.143166 Train acc: 0.953333\n",
      "Epoch: 590/1000 Iteration: 5315 Train loss: 0.133857 Train acc: 0.951667\n",
      "Epoch: 591/1000 Iteration: 5320 Train loss: 0.124602 Train acc: 0.955000\n",
      "Epoch: 591/1000 Iteration: 5325 Train loss: 0.115956 Train acc: 0.961667\n",
      "Epoch: 591/1000 Iteration: 5325 Validation loss: 0.116819 Validation acc: 0.956667\n",
      "Epoch: 592/1000 Iteration: 5330 Train loss: 0.131222 Train acc: 0.955000\n",
      "Epoch: 592/1000 Iteration: 5335 Train loss: 0.132481 Train acc: 0.953333\n",
      "Epoch: 593/1000 Iteration: 5340 Train loss: 0.132762 Train acc: 0.950000\n",
      "Epoch: 593/1000 Iteration: 5345 Train loss: 0.113613 Train acc: 0.966667\n",
      "Epoch: 594/1000 Iteration: 5350 Train loss: 0.169146 Train acc: 0.936667\n",
      "Epoch: 594/1000 Iteration: 5350 Validation loss: 0.117086 Validation acc: 0.956667\n",
      "Epoch: 594/1000 Iteration: 5355 Train loss: 0.149264 Train acc: 0.950000\n",
      "Epoch: 595/1000 Iteration: 5360 Train loss: 0.113103 Train acc: 0.956667\n",
      "Epoch: 596/1000 Iteration: 5365 Train loss: 0.129223 Train acc: 0.955000\n",
      "Epoch: 596/1000 Iteration: 5370 Train loss: 0.113181 Train acc: 0.953333\n",
      "Epoch: 597/1000 Iteration: 5375 Train loss: 0.130803 Train acc: 0.963333\n",
      "Epoch: 597/1000 Iteration: 5375 Validation loss: 0.118227 Validation acc: 0.955000\n",
      "Epoch: 597/1000 Iteration: 5380 Train loss: 0.125285 Train acc: 0.956667\n",
      "Epoch: 598/1000 Iteration: 5385 Train loss: 0.142301 Train acc: 0.956667\n",
      "Epoch: 598/1000 Iteration: 5390 Train loss: 0.114086 Train acc: 0.973333\n",
      "Epoch: 599/1000 Iteration: 5395 Train loss: 0.155009 Train acc: 0.938333\n",
      "Epoch: 599/1000 Iteration: 5400 Train loss: 0.147255 Train acc: 0.956667\n",
      "Epoch: 599/1000 Iteration: 5400 Validation loss: 0.115014 Validation acc: 0.956111\n",
      "Epoch: 600/1000 Iteration: 5405 Train loss: 0.114436 Train acc: 0.958333\n",
      "Epoch: 601/1000 Iteration: 5410 Train loss: 0.131061 Train acc: 0.953333\n",
      "Epoch: 601/1000 Iteration: 5415 Train loss: 0.109904 Train acc: 0.963333\n",
      "Epoch: 602/1000 Iteration: 5420 Train loss: 0.115590 Train acc: 0.961667\n",
      "Epoch: 602/1000 Iteration: 5425 Train loss: 0.122645 Train acc: 0.963333\n",
      "Epoch: 602/1000 Iteration: 5425 Validation loss: 0.116219 Validation acc: 0.957222\n",
      "Epoch: 603/1000 Iteration: 5430 Train loss: 0.126806 Train acc: 0.958333\n",
      "Epoch: 603/1000 Iteration: 5435 Train loss: 0.098220 Train acc: 0.970000\n",
      "Epoch: 604/1000 Iteration: 5440 Train loss: 0.171515 Train acc: 0.930000\n",
      "Epoch: 604/1000 Iteration: 5445 Train loss: 0.140301 Train acc: 0.958333\n",
      "Epoch: 605/1000 Iteration: 5450 Train loss: 0.123648 Train acc: 0.955000\n",
      "Epoch: 605/1000 Iteration: 5450 Validation loss: 0.117402 Validation acc: 0.956667\n",
      "Epoch: 606/1000 Iteration: 5455 Train loss: 0.123235 Train acc: 0.956667\n",
      "Epoch: 606/1000 Iteration: 5460 Train loss: 0.111545 Train acc: 0.970000\n",
      "Epoch: 607/1000 Iteration: 5465 Train loss: 0.115248 Train acc: 0.961667\n",
      "Epoch: 607/1000 Iteration: 5470 Train loss: 0.118268 Train acc: 0.953333\n",
      "Epoch: 608/1000 Iteration: 5475 Train loss: 0.130709 Train acc: 0.956667\n",
      "Epoch: 608/1000 Iteration: 5475 Validation loss: 0.116888 Validation acc: 0.955555\n",
      "Epoch: 608/1000 Iteration: 5480 Train loss: 0.113888 Train acc: 0.955000\n",
      "Epoch: 609/1000 Iteration: 5485 Train loss: 0.148630 Train acc: 0.933333\n",
      "Epoch: 609/1000 Iteration: 5490 Train loss: 0.141480 Train acc: 0.948333\n",
      "Epoch: 610/1000 Iteration: 5495 Train loss: 0.116574 Train acc: 0.961667\n",
      "Epoch: 611/1000 Iteration: 5500 Train loss: 0.135991 Train acc: 0.956667\n",
      "Epoch: 611/1000 Iteration: 5500 Validation loss: 0.117317 Validation acc: 0.956667\n",
      "Epoch: 611/1000 Iteration: 5505 Train loss: 0.105453 Train acc: 0.961667\n",
      "Epoch: 612/1000 Iteration: 5510 Train loss: 0.127527 Train acc: 0.963333\n",
      "Epoch: 612/1000 Iteration: 5515 Train loss: 0.131876 Train acc: 0.951667\n",
      "Epoch: 613/1000 Iteration: 5520 Train loss: 0.139253 Train acc: 0.945000\n",
      "Epoch: 613/1000 Iteration: 5525 Train loss: 0.105575 Train acc: 0.963333\n",
      "Epoch: 613/1000 Iteration: 5525 Validation loss: 0.117884 Validation acc: 0.956111\n",
      "Epoch: 614/1000 Iteration: 5530 Train loss: 0.166151 Train acc: 0.940000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 614/1000 Iteration: 5535 Train loss: 0.135968 Train acc: 0.955000\n",
      "Epoch: 615/1000 Iteration: 5540 Train loss: 0.126524 Train acc: 0.951667\n",
      "Epoch: 616/1000 Iteration: 5545 Train loss: 0.131357 Train acc: 0.953333\n",
      "Epoch: 616/1000 Iteration: 5550 Train loss: 0.123703 Train acc: 0.961667\n",
      "Epoch: 616/1000 Iteration: 5550 Validation loss: 0.119681 Validation acc: 0.955555\n",
      "Epoch: 617/1000 Iteration: 5555 Train loss: 0.121202 Train acc: 0.958333\n",
      "Epoch: 617/1000 Iteration: 5560 Train loss: 0.128365 Train acc: 0.956667\n",
      "Epoch: 618/1000 Iteration: 5565 Train loss: 0.142747 Train acc: 0.938333\n",
      "Epoch: 618/1000 Iteration: 5570 Train loss: 0.111511 Train acc: 0.965000\n",
      "Epoch: 619/1000 Iteration: 5575 Train loss: 0.159121 Train acc: 0.931667\n",
      "Epoch: 619/1000 Iteration: 5575 Validation loss: 0.118432 Validation acc: 0.956111\n",
      "Epoch: 619/1000 Iteration: 5580 Train loss: 0.140690 Train acc: 0.953333\n",
      "Epoch: 620/1000 Iteration: 5585 Train loss: 0.119894 Train acc: 0.956667\n",
      "Epoch: 621/1000 Iteration: 5590 Train loss: 0.116955 Train acc: 0.961667\n",
      "Epoch: 621/1000 Iteration: 5595 Train loss: 0.111474 Train acc: 0.966667\n",
      "Epoch: 622/1000 Iteration: 5600 Train loss: 0.127013 Train acc: 0.960000\n",
      "Epoch: 622/1000 Iteration: 5600 Validation loss: 0.118217 Validation acc: 0.956667\n",
      "Epoch: 622/1000 Iteration: 5605 Train loss: 0.126367 Train acc: 0.960000\n",
      "Epoch: 623/1000 Iteration: 5610 Train loss: 0.141920 Train acc: 0.946667\n",
      "Epoch: 623/1000 Iteration: 5615 Train loss: 0.105295 Train acc: 0.966667\n",
      "Epoch: 624/1000 Iteration: 5620 Train loss: 0.161414 Train acc: 0.941667\n",
      "Epoch: 624/1000 Iteration: 5625 Train loss: 0.132685 Train acc: 0.950000\n",
      "Epoch: 624/1000 Iteration: 5625 Validation loss: 0.119094 Validation acc: 0.954444\n",
      "Epoch: 625/1000 Iteration: 5630 Train loss: 0.128821 Train acc: 0.948333\n",
      "Epoch: 626/1000 Iteration: 5635 Train loss: 0.122077 Train acc: 0.958333\n",
      "Epoch: 626/1000 Iteration: 5640 Train loss: 0.110912 Train acc: 0.963333\n",
      "Epoch: 627/1000 Iteration: 5645 Train loss: 0.106920 Train acc: 0.963333\n",
      "Epoch: 627/1000 Iteration: 5650 Train loss: 0.130679 Train acc: 0.961667\n",
      "Epoch: 627/1000 Iteration: 5650 Validation loss: 0.120886 Validation acc: 0.953889\n",
      "Epoch: 628/1000 Iteration: 5655 Train loss: 0.132937 Train acc: 0.948333\n",
      "Epoch: 628/1000 Iteration: 5660 Train loss: 0.101316 Train acc: 0.968333\n",
      "Epoch: 629/1000 Iteration: 5665 Train loss: 0.159523 Train acc: 0.938333\n",
      "Epoch: 629/1000 Iteration: 5670 Train loss: 0.152577 Train acc: 0.946667\n",
      "Epoch: 630/1000 Iteration: 5675 Train loss: 0.121777 Train acc: 0.956667\n",
      "Epoch: 630/1000 Iteration: 5675 Validation loss: 0.120504 Validation acc: 0.955555\n",
      "Epoch: 631/1000 Iteration: 5680 Train loss: 0.129816 Train acc: 0.951667\n",
      "Epoch: 631/1000 Iteration: 5685 Train loss: 0.113190 Train acc: 0.956667\n",
      "Epoch: 632/1000 Iteration: 5690 Train loss: 0.127334 Train acc: 0.946667\n",
      "Epoch: 632/1000 Iteration: 5695 Train loss: 0.114607 Train acc: 0.951667\n",
      "Epoch: 633/1000 Iteration: 5700 Train loss: 0.132925 Train acc: 0.946667\n",
      "Epoch: 633/1000 Iteration: 5700 Validation loss: 0.121116 Validation acc: 0.955555\n",
      "Epoch: 633/1000 Iteration: 5705 Train loss: 0.096481 Train acc: 0.960000\n",
      "Epoch: 634/1000 Iteration: 5710 Train loss: 0.152630 Train acc: 0.933333\n",
      "Epoch: 634/1000 Iteration: 5715 Train loss: 0.152839 Train acc: 0.951667\n",
      "Epoch: 635/1000 Iteration: 5720 Train loss: 0.114455 Train acc: 0.966667\n",
      "Epoch: 636/1000 Iteration: 5725 Train loss: 0.122733 Train acc: 0.958333\n",
      "Epoch: 636/1000 Iteration: 5725 Validation loss: 0.119399 Validation acc: 0.954444\n",
      "Epoch: 636/1000 Iteration: 5730 Train loss: 0.111464 Train acc: 0.958333\n",
      "Epoch: 637/1000 Iteration: 5735 Train loss: 0.124005 Train acc: 0.960000\n",
      "Epoch: 637/1000 Iteration: 5740 Train loss: 0.115630 Train acc: 0.956667\n",
      "Epoch: 638/1000 Iteration: 5745 Train loss: 0.129990 Train acc: 0.951667\n",
      "Epoch: 638/1000 Iteration: 5750 Train loss: 0.105073 Train acc: 0.970000\n",
      "Epoch: 638/1000 Iteration: 5750 Validation loss: 0.120216 Validation acc: 0.955000\n",
      "Epoch: 639/1000 Iteration: 5755 Train loss: 0.166542 Train acc: 0.933333\n",
      "Epoch: 639/1000 Iteration: 5760 Train loss: 0.132255 Train acc: 0.951667\n",
      "Epoch: 640/1000 Iteration: 5765 Train loss: 0.132527 Train acc: 0.945000\n",
      "Epoch: 641/1000 Iteration: 5770 Train loss: 0.120638 Train acc: 0.963333\n",
      "Epoch: 641/1000 Iteration: 5775 Train loss: 0.110877 Train acc: 0.963333\n",
      "Epoch: 641/1000 Iteration: 5775 Validation loss: 0.120699 Validation acc: 0.955000\n",
      "Epoch: 642/1000 Iteration: 5780 Train loss: 0.117320 Train acc: 0.965000\n",
      "Epoch: 642/1000 Iteration: 5785 Train loss: 0.126687 Train acc: 0.956667\n",
      "Epoch: 643/1000 Iteration: 5790 Train loss: 0.120229 Train acc: 0.956667\n",
      "Epoch: 643/1000 Iteration: 5795 Train loss: 0.096631 Train acc: 0.971667\n",
      "Epoch: 644/1000 Iteration: 5800 Train loss: 0.162953 Train acc: 0.938333\n",
      "Epoch: 644/1000 Iteration: 5800 Validation loss: 0.121701 Validation acc: 0.953889\n",
      "Epoch: 644/1000 Iteration: 5805 Train loss: 0.143328 Train acc: 0.953333\n",
      "Epoch: 645/1000 Iteration: 5810 Train loss: 0.118731 Train acc: 0.956667\n",
      "Epoch: 646/1000 Iteration: 5815 Train loss: 0.124736 Train acc: 0.958333\n",
      "Epoch: 646/1000 Iteration: 5820 Train loss: 0.109397 Train acc: 0.963333\n",
      "Epoch: 647/1000 Iteration: 5825 Train loss: 0.120871 Train acc: 0.961667\n",
      "Epoch: 647/1000 Iteration: 5825 Validation loss: 0.120249 Validation acc: 0.952778\n",
      "Epoch: 647/1000 Iteration: 5830 Train loss: 0.134433 Train acc: 0.951667\n",
      "Epoch: 648/1000 Iteration: 5835 Train loss: 0.133316 Train acc: 0.950000\n",
      "Epoch: 648/1000 Iteration: 5840 Train loss: 0.102336 Train acc: 0.971667\n",
      "Epoch: 649/1000 Iteration: 5845 Train loss: 0.167069 Train acc: 0.938333\n",
      "Epoch: 649/1000 Iteration: 5850 Train loss: 0.156299 Train acc: 0.950000\n",
      "Epoch: 649/1000 Iteration: 5850 Validation loss: 0.120458 Validation acc: 0.953889\n",
      "Epoch: 650/1000 Iteration: 5855 Train loss: 0.114283 Train acc: 0.961667\n",
      "Epoch: 651/1000 Iteration: 5860 Train loss: 0.139231 Train acc: 0.951667\n",
      "Epoch: 651/1000 Iteration: 5865 Train loss: 0.125122 Train acc: 0.948333\n",
      "Epoch: 652/1000 Iteration: 5870 Train loss: 0.126982 Train acc: 0.958333\n",
      "Epoch: 652/1000 Iteration: 5875 Train loss: 0.113834 Train acc: 0.963333\n",
      "Epoch: 652/1000 Iteration: 5875 Validation loss: 0.125438 Validation acc: 0.954444\n",
      "Epoch: 653/1000 Iteration: 5880 Train loss: 0.134315 Train acc: 0.946667\n",
      "Epoch: 653/1000 Iteration: 5885 Train loss: 0.099226 Train acc: 0.970000\n",
      "Epoch: 654/1000 Iteration: 5890 Train loss: 0.151947 Train acc: 0.945000\n",
      "Epoch: 654/1000 Iteration: 5895 Train loss: 0.133141 Train acc: 0.955000\n",
      "Epoch: 655/1000 Iteration: 5900 Train loss: 0.123439 Train acc: 0.961667\n",
      "Epoch: 655/1000 Iteration: 5900 Validation loss: 0.122396 Validation acc: 0.953333\n",
      "Epoch: 656/1000 Iteration: 5905 Train loss: 0.116129 Train acc: 0.955000\n",
      "Epoch: 656/1000 Iteration: 5910 Train loss: 0.107134 Train acc: 0.963333\n",
      "Epoch: 657/1000 Iteration: 5915 Train loss: 0.113178 Train acc: 0.958333\n",
      "Epoch: 657/1000 Iteration: 5920 Train loss: 0.116032 Train acc: 0.953333\n",
      "Epoch: 658/1000 Iteration: 5925 Train loss: 0.129331 Train acc: 0.951667\n",
      "Epoch: 658/1000 Iteration: 5925 Validation loss: 0.119435 Validation acc: 0.953889\n",
      "Epoch: 658/1000 Iteration: 5930 Train loss: 0.111700 Train acc: 0.968333\n",
      "Epoch: 659/1000 Iteration: 5935 Train loss: 0.153875 Train acc: 0.940000\n",
      "Epoch: 659/1000 Iteration: 5940 Train loss: 0.142045 Train acc: 0.951667\n",
      "Epoch: 660/1000 Iteration: 5945 Train loss: 0.124652 Train acc: 0.961667\n",
      "Epoch: 661/1000 Iteration: 5950 Train loss: 0.118016 Train acc: 0.966667\n",
      "Epoch: 661/1000 Iteration: 5950 Validation loss: 0.120060 Validation acc: 0.953889\n",
      "Epoch: 661/1000 Iteration: 5955 Train loss: 0.108466 Train acc: 0.961667\n",
      "Epoch: 662/1000 Iteration: 5960 Train loss: 0.109303 Train acc: 0.960000\n",
      "Epoch: 662/1000 Iteration: 5965 Train loss: 0.118104 Train acc: 0.961667\n",
      "Epoch: 663/1000 Iteration: 5970 Train loss: 0.131574 Train acc: 0.946667\n",
      "Epoch: 663/1000 Iteration: 5975 Train loss: 0.092666 Train acc: 0.965000\n",
      "Epoch: 663/1000 Iteration: 5975 Validation loss: 0.120321 Validation acc: 0.955555\n",
      "Epoch: 664/1000 Iteration: 5980 Train loss: 0.155105 Train acc: 0.940000\n",
      "Epoch: 664/1000 Iteration: 5985 Train loss: 0.135840 Train acc: 0.946667\n",
      "Epoch: 665/1000 Iteration: 5990 Train loss: 0.118227 Train acc: 0.956667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 666/1000 Iteration: 5995 Train loss: 0.114974 Train acc: 0.961667\n",
      "Epoch: 666/1000 Iteration: 6000 Train loss: 0.109139 Train acc: 0.961667\n",
      "Epoch: 666/1000 Iteration: 6000 Validation loss: 0.120580 Validation acc: 0.953889\n",
      "Epoch: 667/1000 Iteration: 6005 Train loss: 0.115931 Train acc: 0.961667\n",
      "Epoch: 667/1000 Iteration: 6010 Train loss: 0.110529 Train acc: 0.960000\n",
      "Epoch: 668/1000 Iteration: 6015 Train loss: 0.139227 Train acc: 0.951667\n",
      "Epoch: 668/1000 Iteration: 6020 Train loss: 0.090716 Train acc: 0.976667\n",
      "Epoch: 669/1000 Iteration: 6025 Train loss: 0.154919 Train acc: 0.933333\n",
      "Epoch: 669/1000 Iteration: 6025 Validation loss: 0.122170 Validation acc: 0.953333\n",
      "Epoch: 669/1000 Iteration: 6030 Train loss: 0.135833 Train acc: 0.951667\n",
      "Epoch: 670/1000 Iteration: 6035 Train loss: 0.136675 Train acc: 0.956667\n",
      "Epoch: 671/1000 Iteration: 6040 Train loss: 0.122717 Train acc: 0.955000\n",
      "Epoch: 671/1000 Iteration: 6045 Train loss: 0.110241 Train acc: 0.961667\n",
      "Epoch: 672/1000 Iteration: 6050 Train loss: 0.120750 Train acc: 0.955000\n",
      "Epoch: 672/1000 Iteration: 6050 Validation loss: 0.114382 Validation acc: 0.952778\n",
      "Epoch: 672/1000 Iteration: 6055 Train loss: 0.123419 Train acc: 0.958333\n",
      "Epoch: 673/1000 Iteration: 6060 Train loss: 0.138850 Train acc: 0.948333\n",
      "Epoch: 673/1000 Iteration: 6065 Train loss: 0.100773 Train acc: 0.973333\n",
      "Epoch: 674/1000 Iteration: 6070 Train loss: 0.140035 Train acc: 0.945000\n",
      "Epoch: 674/1000 Iteration: 6075 Train loss: 0.134601 Train acc: 0.948333\n",
      "Epoch: 674/1000 Iteration: 6075 Validation loss: 0.118924 Validation acc: 0.953889\n",
      "Epoch: 675/1000 Iteration: 6080 Train loss: 0.120524 Train acc: 0.948333\n",
      "Epoch: 676/1000 Iteration: 6085 Train loss: 0.123325 Train acc: 0.956667\n",
      "Epoch: 676/1000 Iteration: 6090 Train loss: 0.098767 Train acc: 0.968333\n",
      "Epoch: 677/1000 Iteration: 6095 Train loss: 0.126384 Train acc: 0.963333\n",
      "Epoch: 677/1000 Iteration: 6100 Train loss: 0.123835 Train acc: 0.961667\n",
      "Epoch: 677/1000 Iteration: 6100 Validation loss: 0.117606 Validation acc: 0.953889\n",
      "Epoch: 678/1000 Iteration: 6105 Train loss: 0.137307 Train acc: 0.951667\n",
      "Epoch: 678/1000 Iteration: 6110 Train loss: 0.111715 Train acc: 0.963333\n",
      "Epoch: 679/1000 Iteration: 6115 Train loss: 0.150717 Train acc: 0.946667\n",
      "Epoch: 679/1000 Iteration: 6120 Train loss: 0.132317 Train acc: 0.960000\n",
      "Epoch: 680/1000 Iteration: 6125 Train loss: 0.121528 Train acc: 0.951667\n",
      "Epoch: 680/1000 Iteration: 6125 Validation loss: 0.118587 Validation acc: 0.952778\n",
      "Epoch: 681/1000 Iteration: 6130 Train loss: 0.119495 Train acc: 0.961667\n",
      "Epoch: 681/1000 Iteration: 6135 Train loss: 0.112913 Train acc: 0.958333\n",
      "Epoch: 682/1000 Iteration: 6140 Train loss: 0.107086 Train acc: 0.961667\n",
      "Epoch: 682/1000 Iteration: 6145 Train loss: 0.119663 Train acc: 0.956667\n",
      "Epoch: 683/1000 Iteration: 6150 Train loss: 0.115956 Train acc: 0.956667\n",
      "Epoch: 683/1000 Iteration: 6150 Validation loss: 0.117024 Validation acc: 0.956111\n",
      "Epoch: 683/1000 Iteration: 6155 Train loss: 0.105102 Train acc: 0.961667\n",
      "Epoch: 684/1000 Iteration: 6160 Train loss: 0.155189 Train acc: 0.933333\n",
      "Epoch: 684/1000 Iteration: 6165 Train loss: 0.148082 Train acc: 0.950000\n",
      "Epoch: 685/1000 Iteration: 6170 Train loss: 0.122013 Train acc: 0.958333\n",
      "Epoch: 686/1000 Iteration: 6175 Train loss: 0.116643 Train acc: 0.965000\n",
      "Epoch: 686/1000 Iteration: 6175 Validation loss: 0.116303 Validation acc: 0.956111\n",
      "Epoch: 686/1000 Iteration: 6180 Train loss: 0.090805 Train acc: 0.968333\n",
      "Epoch: 687/1000 Iteration: 6185 Train loss: 0.117229 Train acc: 0.965000\n",
      "Epoch: 687/1000 Iteration: 6190 Train loss: 0.130870 Train acc: 0.960000\n",
      "Epoch: 688/1000 Iteration: 6195 Train loss: 0.124298 Train acc: 0.953333\n",
      "Epoch: 688/1000 Iteration: 6200 Train loss: 0.095952 Train acc: 0.975000\n",
      "Epoch: 688/1000 Iteration: 6200 Validation loss: 0.115980 Validation acc: 0.955555\n",
      "Epoch: 689/1000 Iteration: 6205 Train loss: 0.153635 Train acc: 0.935000\n",
      "Epoch: 689/1000 Iteration: 6210 Train loss: 0.138121 Train acc: 0.961667\n",
      "Epoch: 690/1000 Iteration: 6215 Train loss: 0.119038 Train acc: 0.955000\n",
      "Epoch: 691/1000 Iteration: 6220 Train loss: 0.126126 Train acc: 0.950000\n",
      "Epoch: 691/1000 Iteration: 6225 Train loss: 0.102753 Train acc: 0.961667\n",
      "Epoch: 691/1000 Iteration: 6225 Validation loss: 0.117020 Validation acc: 0.954444\n",
      "Epoch: 692/1000 Iteration: 6230 Train loss: 0.123665 Train acc: 0.956667\n",
      "Epoch: 692/1000 Iteration: 6235 Train loss: 0.115713 Train acc: 0.958333\n",
      "Epoch: 693/1000 Iteration: 6240 Train loss: 0.119446 Train acc: 0.948333\n",
      "Epoch: 693/1000 Iteration: 6245 Train loss: 0.102665 Train acc: 0.966667\n",
      "Epoch: 694/1000 Iteration: 6250 Train loss: 0.153373 Train acc: 0.938333\n",
      "Epoch: 694/1000 Iteration: 6250 Validation loss: 0.116883 Validation acc: 0.955000\n",
      "Epoch: 694/1000 Iteration: 6255 Train loss: 0.138744 Train acc: 0.946667\n",
      "Epoch: 695/1000 Iteration: 6260 Train loss: 0.108452 Train acc: 0.961667\n",
      "Epoch: 696/1000 Iteration: 6265 Train loss: 0.121672 Train acc: 0.956667\n",
      "Epoch: 696/1000 Iteration: 6270 Train loss: 0.109479 Train acc: 0.960000\n",
      "Epoch: 697/1000 Iteration: 6275 Train loss: 0.125445 Train acc: 0.965000\n",
      "Epoch: 697/1000 Iteration: 6275 Validation loss: 0.117655 Validation acc: 0.953333\n",
      "Epoch: 697/1000 Iteration: 6280 Train loss: 0.114154 Train acc: 0.970000\n",
      "Epoch: 698/1000 Iteration: 6285 Train loss: 0.118582 Train acc: 0.951667\n",
      "Epoch: 698/1000 Iteration: 6290 Train loss: 0.097468 Train acc: 0.966667\n",
      "Epoch: 699/1000 Iteration: 6295 Train loss: 0.152434 Train acc: 0.940000\n",
      "Epoch: 699/1000 Iteration: 6300 Train loss: 0.139425 Train acc: 0.955000\n",
      "Epoch: 699/1000 Iteration: 6300 Validation loss: 0.116365 Validation acc: 0.955000\n",
      "Epoch: 700/1000 Iteration: 6305 Train loss: 0.111123 Train acc: 0.958333\n",
      "Epoch: 701/1000 Iteration: 6310 Train loss: 0.116650 Train acc: 0.958333\n",
      "Epoch: 701/1000 Iteration: 6315 Train loss: 0.099045 Train acc: 0.970000\n",
      "Epoch: 702/1000 Iteration: 6320 Train loss: 0.113936 Train acc: 0.965000\n",
      "Epoch: 702/1000 Iteration: 6325 Train loss: 0.119608 Train acc: 0.963333\n",
      "Epoch: 702/1000 Iteration: 6325 Validation loss: 0.117420 Validation acc: 0.956111\n",
      "Epoch: 703/1000 Iteration: 6330 Train loss: 0.128784 Train acc: 0.953333\n",
      "Epoch: 703/1000 Iteration: 6335 Train loss: 0.106912 Train acc: 0.966667\n",
      "Epoch: 704/1000 Iteration: 6340 Train loss: 0.162045 Train acc: 0.928333\n",
      "Epoch: 704/1000 Iteration: 6345 Train loss: 0.129356 Train acc: 0.961667\n",
      "Epoch: 705/1000 Iteration: 6350 Train loss: 0.121037 Train acc: 0.953333\n",
      "Epoch: 705/1000 Iteration: 6350 Validation loss: 0.117254 Validation acc: 0.952778\n",
      "Epoch: 706/1000 Iteration: 6355 Train loss: 0.115126 Train acc: 0.958333\n",
      "Epoch: 706/1000 Iteration: 6360 Train loss: 0.103751 Train acc: 0.956667\n",
      "Epoch: 707/1000 Iteration: 6365 Train loss: 0.106624 Train acc: 0.960000\n",
      "Epoch: 707/1000 Iteration: 6370 Train loss: 0.113097 Train acc: 0.965000\n",
      "Epoch: 708/1000 Iteration: 6375 Train loss: 0.124433 Train acc: 0.951667\n",
      "Epoch: 708/1000 Iteration: 6375 Validation loss: 0.117511 Validation acc: 0.953889\n",
      "Epoch: 708/1000 Iteration: 6380 Train loss: 0.107907 Train acc: 0.966667\n",
      "Epoch: 709/1000 Iteration: 6385 Train loss: 0.162015 Train acc: 0.935000\n",
      "Epoch: 709/1000 Iteration: 6390 Train loss: 0.134802 Train acc: 0.948333\n",
      "Epoch: 710/1000 Iteration: 6395 Train loss: 0.098590 Train acc: 0.968333\n",
      "Epoch: 711/1000 Iteration: 6400 Train loss: 0.116166 Train acc: 0.958333\n",
      "Epoch: 711/1000 Iteration: 6400 Validation loss: 0.118421 Validation acc: 0.953333\n",
      "Epoch: 711/1000 Iteration: 6405 Train loss: 0.096171 Train acc: 0.965000\n",
      "Epoch: 712/1000 Iteration: 6410 Train loss: 0.117307 Train acc: 0.956667\n",
      "Epoch: 712/1000 Iteration: 6415 Train loss: 0.121185 Train acc: 0.958333\n",
      "Epoch: 713/1000 Iteration: 6420 Train loss: 0.127523 Train acc: 0.956667\n",
      "Epoch: 713/1000 Iteration: 6425 Train loss: 0.092624 Train acc: 0.971667\n",
      "Epoch: 713/1000 Iteration: 6425 Validation loss: 0.118545 Validation acc: 0.953889\n",
      "Epoch: 714/1000 Iteration: 6430 Train loss: 0.144131 Train acc: 0.938333\n",
      "Epoch: 714/1000 Iteration: 6435 Train loss: 0.115505 Train acc: 0.966667\n",
      "Epoch: 715/1000 Iteration: 6440 Train loss: 0.117974 Train acc: 0.958333\n",
      "Epoch: 716/1000 Iteration: 6445 Train loss: 0.124452 Train acc: 0.953333\n",
      "Epoch: 716/1000 Iteration: 6450 Train loss: 0.106267 Train acc: 0.960000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 716/1000 Iteration: 6450 Validation loss: 0.120263 Validation acc: 0.952778\n",
      "Epoch: 717/1000 Iteration: 6455 Train loss: 0.109338 Train acc: 0.961667\n",
      "Epoch: 717/1000 Iteration: 6460 Train loss: 0.117051 Train acc: 0.956667\n",
      "Epoch: 718/1000 Iteration: 6465 Train loss: 0.125439 Train acc: 0.953333\n",
      "Epoch: 718/1000 Iteration: 6470 Train loss: 0.112488 Train acc: 0.961667\n",
      "Epoch: 719/1000 Iteration: 6475 Train loss: 0.134892 Train acc: 0.948333\n",
      "Epoch: 719/1000 Iteration: 6475 Validation loss: 0.117839 Validation acc: 0.953333\n",
      "Epoch: 719/1000 Iteration: 6480 Train loss: 0.130202 Train acc: 0.953333\n",
      "Epoch: 720/1000 Iteration: 6485 Train loss: 0.111055 Train acc: 0.958333\n",
      "Epoch: 721/1000 Iteration: 6490 Train loss: 0.112933 Train acc: 0.960000\n",
      "Epoch: 721/1000 Iteration: 6495 Train loss: 0.106809 Train acc: 0.955000\n",
      "Epoch: 722/1000 Iteration: 6500 Train loss: 0.104503 Train acc: 0.970000\n",
      "Epoch: 722/1000 Iteration: 6500 Validation loss: 0.119419 Validation acc: 0.953333\n",
      "Epoch: 722/1000 Iteration: 6505 Train loss: 0.111410 Train acc: 0.960000\n",
      "Epoch: 723/1000 Iteration: 6510 Train loss: 0.123995 Train acc: 0.955000\n",
      "Epoch: 723/1000 Iteration: 6515 Train loss: 0.090521 Train acc: 0.968333\n",
      "Epoch: 724/1000 Iteration: 6520 Train loss: 0.150251 Train acc: 0.940000\n",
      "Epoch: 724/1000 Iteration: 6525 Train loss: 0.138686 Train acc: 0.955000\n",
      "Epoch: 724/1000 Iteration: 6525 Validation loss: 0.120000 Validation acc: 0.953889\n",
      "Epoch: 725/1000 Iteration: 6530 Train loss: 0.106480 Train acc: 0.955000\n",
      "Epoch: 726/1000 Iteration: 6535 Train loss: 0.120931 Train acc: 0.961667\n",
      "Epoch: 726/1000 Iteration: 6540 Train loss: 0.097365 Train acc: 0.963333\n",
      "Epoch: 727/1000 Iteration: 6545 Train loss: 0.118770 Train acc: 0.960000\n",
      "Epoch: 727/1000 Iteration: 6550 Train loss: 0.106044 Train acc: 0.956667\n",
      "Epoch: 727/1000 Iteration: 6550 Validation loss: 0.119496 Validation acc: 0.953333\n",
      "Epoch: 728/1000 Iteration: 6555 Train loss: 0.122235 Train acc: 0.955000\n",
      "Epoch: 728/1000 Iteration: 6560 Train loss: 0.094769 Train acc: 0.968333\n",
      "Epoch: 729/1000 Iteration: 6565 Train loss: 0.150037 Train acc: 0.938333\n",
      "Epoch: 729/1000 Iteration: 6570 Train loss: 0.138195 Train acc: 0.945000\n",
      "Epoch: 730/1000 Iteration: 6575 Train loss: 0.115583 Train acc: 0.955000\n",
      "Epoch: 730/1000 Iteration: 6575 Validation loss: 0.121206 Validation acc: 0.953333\n",
      "Epoch: 731/1000 Iteration: 6580 Train loss: 0.125286 Train acc: 0.951667\n",
      "Epoch: 731/1000 Iteration: 6585 Train loss: 0.103573 Train acc: 0.968333\n",
      "Epoch: 732/1000 Iteration: 6590 Train loss: 0.124822 Train acc: 0.958333\n",
      "Epoch: 732/1000 Iteration: 6595 Train loss: 0.112174 Train acc: 0.965000\n",
      "Epoch: 733/1000 Iteration: 6600 Train loss: 0.122369 Train acc: 0.956667\n",
      "Epoch: 733/1000 Iteration: 6600 Validation loss: 0.120413 Validation acc: 0.953333\n",
      "Epoch: 733/1000 Iteration: 6605 Train loss: 0.099855 Train acc: 0.966667\n",
      "Epoch: 734/1000 Iteration: 6610 Train loss: 0.150842 Train acc: 0.948333\n",
      "Epoch: 734/1000 Iteration: 6615 Train loss: 0.142127 Train acc: 0.960000\n",
      "Epoch: 735/1000 Iteration: 6620 Train loss: 0.104113 Train acc: 0.960000\n",
      "Epoch: 736/1000 Iteration: 6625 Train loss: 0.119459 Train acc: 0.956667\n",
      "Epoch: 736/1000 Iteration: 6625 Validation loss: 0.113567 Validation acc: 0.952778\n",
      "Epoch: 736/1000 Iteration: 6630 Train loss: 0.107203 Train acc: 0.958333\n",
      "Epoch: 737/1000 Iteration: 6635 Train loss: 0.115622 Train acc: 0.958333\n",
      "Epoch: 737/1000 Iteration: 6640 Train loss: 0.115310 Train acc: 0.963333\n",
      "Epoch: 738/1000 Iteration: 6645 Train loss: 0.133948 Train acc: 0.953333\n",
      "Epoch: 738/1000 Iteration: 6650 Train loss: 0.099579 Train acc: 0.968333\n",
      "Epoch: 738/1000 Iteration: 6650 Validation loss: 0.115169 Validation acc: 0.952778\n",
      "Epoch: 739/1000 Iteration: 6655 Train loss: 0.151496 Train acc: 0.945000\n",
      "Epoch: 739/1000 Iteration: 6660 Train loss: 0.130393 Train acc: 0.950000\n",
      "Epoch: 740/1000 Iteration: 6665 Train loss: 0.105778 Train acc: 0.963333\n",
      "Epoch: 741/1000 Iteration: 6670 Train loss: 0.128231 Train acc: 0.956667\n",
      "Epoch: 741/1000 Iteration: 6675 Train loss: 0.099431 Train acc: 0.965000\n",
      "Epoch: 741/1000 Iteration: 6675 Validation loss: 0.116106 Validation acc: 0.954444\n",
      "Epoch: 742/1000 Iteration: 6680 Train loss: 0.103772 Train acc: 0.968333\n",
      "Epoch: 742/1000 Iteration: 6685 Train loss: 0.108491 Train acc: 0.948333\n",
      "Epoch: 743/1000 Iteration: 6690 Train loss: 0.128459 Train acc: 0.945000\n",
      "Epoch: 743/1000 Iteration: 6695 Train loss: 0.099094 Train acc: 0.963333\n",
      "Epoch: 744/1000 Iteration: 6700 Train loss: 0.152426 Train acc: 0.935000\n",
      "Epoch: 744/1000 Iteration: 6700 Validation loss: 0.115404 Validation acc: 0.950556\n",
      "Epoch: 744/1000 Iteration: 6705 Train loss: 0.122277 Train acc: 0.961667\n",
      "Epoch: 745/1000 Iteration: 6710 Train loss: 0.109935 Train acc: 0.953333\n",
      "Epoch: 746/1000 Iteration: 6715 Train loss: 0.113058 Train acc: 0.960000\n",
      "Epoch: 746/1000 Iteration: 6720 Train loss: 0.112140 Train acc: 0.961667\n",
      "Epoch: 747/1000 Iteration: 6725 Train loss: 0.110564 Train acc: 0.958333\n",
      "Epoch: 747/1000 Iteration: 6725 Validation loss: 0.115763 Validation acc: 0.953889\n",
      "Epoch: 747/1000 Iteration: 6730 Train loss: 0.105775 Train acc: 0.958333\n",
      "Epoch: 748/1000 Iteration: 6735 Train loss: 0.127277 Train acc: 0.951667\n",
      "Epoch: 748/1000 Iteration: 6740 Train loss: 0.110130 Train acc: 0.958333\n",
      "Epoch: 749/1000 Iteration: 6745 Train loss: 0.143346 Train acc: 0.948333\n",
      "Epoch: 749/1000 Iteration: 6750 Train loss: 0.122680 Train acc: 0.960000\n",
      "Epoch: 749/1000 Iteration: 6750 Validation loss: 0.114494 Validation acc: 0.953333\n",
      "Epoch: 750/1000 Iteration: 6755 Train loss: 0.108984 Train acc: 0.960000\n",
      "Epoch: 751/1000 Iteration: 6760 Train loss: 0.117225 Train acc: 0.956667\n",
      "Epoch: 751/1000 Iteration: 6765 Train loss: 0.091720 Train acc: 0.965000\n",
      "Epoch: 752/1000 Iteration: 6770 Train loss: 0.097828 Train acc: 0.966667\n",
      "Epoch: 752/1000 Iteration: 6775 Train loss: 0.108643 Train acc: 0.960000\n",
      "Epoch: 752/1000 Iteration: 6775 Validation loss: 0.114735 Validation acc: 0.953333\n",
      "Epoch: 753/1000 Iteration: 6780 Train loss: 0.124561 Train acc: 0.951667\n",
      "Epoch: 753/1000 Iteration: 6785 Train loss: 0.085784 Train acc: 0.971667\n",
      "Epoch: 754/1000 Iteration: 6790 Train loss: 0.142554 Train acc: 0.941667\n",
      "Epoch: 754/1000 Iteration: 6795 Train loss: 0.111966 Train acc: 0.963333\n",
      "Epoch: 755/1000 Iteration: 6800 Train loss: 0.107126 Train acc: 0.958333\n",
      "Epoch: 755/1000 Iteration: 6800 Validation loss: 0.115284 Validation acc: 0.953889\n",
      "Epoch: 756/1000 Iteration: 6805 Train loss: 0.100636 Train acc: 0.971667\n",
      "Epoch: 756/1000 Iteration: 6810 Train loss: 0.107459 Train acc: 0.961667\n",
      "Epoch: 757/1000 Iteration: 6815 Train loss: 0.111918 Train acc: 0.961667\n",
      "Epoch: 757/1000 Iteration: 6820 Train loss: 0.114621 Train acc: 0.960000\n",
      "Epoch: 758/1000 Iteration: 6825 Train loss: 0.131353 Train acc: 0.950000\n",
      "Epoch: 758/1000 Iteration: 6825 Validation loss: 0.113791 Validation acc: 0.952778\n",
      "Epoch: 758/1000 Iteration: 6830 Train loss: 0.099886 Train acc: 0.970000\n",
      "Epoch: 759/1000 Iteration: 6835 Train loss: 0.143033 Train acc: 0.946667\n",
      "Epoch: 759/1000 Iteration: 6840 Train loss: 0.133716 Train acc: 0.953333\n",
      "Epoch: 760/1000 Iteration: 6845 Train loss: 0.109240 Train acc: 0.958333\n",
      "Epoch: 761/1000 Iteration: 6850 Train loss: 0.115768 Train acc: 0.950000\n",
      "Epoch: 761/1000 Iteration: 6850 Validation loss: 0.116213 Validation acc: 0.953333\n",
      "Epoch: 761/1000 Iteration: 6855 Train loss: 0.101499 Train acc: 0.963333\n",
      "Epoch: 762/1000 Iteration: 6860 Train loss: 0.122284 Train acc: 0.956667\n",
      "Epoch: 762/1000 Iteration: 6865 Train loss: 0.100064 Train acc: 0.971667\n",
      "Epoch: 763/1000 Iteration: 6870 Train loss: 0.111911 Train acc: 0.958333\n",
      "Epoch: 763/1000 Iteration: 6875 Train loss: 0.097331 Train acc: 0.966667\n",
      "Epoch: 763/1000 Iteration: 6875 Validation loss: 0.114098 Validation acc: 0.952778\n",
      "Epoch: 764/1000 Iteration: 6880 Train loss: 0.144352 Train acc: 0.945000\n",
      "Epoch: 764/1000 Iteration: 6885 Train loss: 0.124498 Train acc: 0.958333\n",
      "Epoch: 765/1000 Iteration: 6890 Train loss: 0.114415 Train acc: 0.965000\n",
      "Epoch: 766/1000 Iteration: 6895 Train loss: 0.111480 Train acc: 0.951667\n",
      "Epoch: 766/1000 Iteration: 6900 Train loss: 0.104816 Train acc: 0.956667\n",
      "Epoch: 766/1000 Iteration: 6900 Validation loss: 0.118730 Validation acc: 0.951667\n",
      "Epoch: 767/1000 Iteration: 6905 Train loss: 0.098122 Train acc: 0.965000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 767/1000 Iteration: 6910 Train loss: 0.121505 Train acc: 0.956667\n",
      "Epoch: 768/1000 Iteration: 6915 Train loss: 0.124351 Train acc: 0.960000\n",
      "Epoch: 768/1000 Iteration: 6920 Train loss: 0.095311 Train acc: 0.968333\n",
      "Epoch: 769/1000 Iteration: 6925 Train loss: 0.148693 Train acc: 0.960000\n",
      "Epoch: 769/1000 Iteration: 6925 Validation loss: 0.121631 Validation acc: 0.952222\n",
      "Epoch: 769/1000 Iteration: 6930 Train loss: 0.124438 Train acc: 0.955000\n",
      "Epoch: 770/1000 Iteration: 6935 Train loss: 0.109821 Train acc: 0.958333\n",
      "Epoch: 771/1000 Iteration: 6940 Train loss: 0.099246 Train acc: 0.968333\n",
      "Epoch: 771/1000 Iteration: 6945 Train loss: 0.095805 Train acc: 0.968333\n",
      "Epoch: 772/1000 Iteration: 6950 Train loss: 0.105288 Train acc: 0.966667\n",
      "Epoch: 772/1000 Iteration: 6950 Validation loss: 0.113438 Validation acc: 0.953889\n",
      "Epoch: 772/1000 Iteration: 6955 Train loss: 0.110275 Train acc: 0.950000\n",
      "Epoch: 773/1000 Iteration: 6960 Train loss: 0.105075 Train acc: 0.963333\n",
      "Epoch: 773/1000 Iteration: 6965 Train loss: 0.095124 Train acc: 0.965000\n",
      "Epoch: 774/1000 Iteration: 6970 Train loss: 0.144753 Train acc: 0.945000\n",
      "Epoch: 774/1000 Iteration: 6975 Train loss: 0.119250 Train acc: 0.956667\n",
      "Epoch: 774/1000 Iteration: 6975 Validation loss: 0.121278 Validation acc: 0.952778\n",
      "Epoch: 775/1000 Iteration: 6980 Train loss: 0.102567 Train acc: 0.958333\n",
      "Epoch: 776/1000 Iteration: 6985 Train loss: 0.106072 Train acc: 0.965000\n",
      "Epoch: 776/1000 Iteration: 6990 Train loss: 0.094680 Train acc: 0.968333\n",
      "Epoch: 777/1000 Iteration: 6995 Train loss: 0.107552 Train acc: 0.968333\n",
      "Epoch: 777/1000 Iteration: 7000 Train loss: 0.102528 Train acc: 0.958333\n",
      "Epoch: 777/1000 Iteration: 7000 Validation loss: 0.120716 Validation acc: 0.953333\n",
      "Epoch: 778/1000 Iteration: 7005 Train loss: 0.126489 Train acc: 0.956667\n",
      "Epoch: 778/1000 Iteration: 7010 Train loss: 0.090185 Train acc: 0.973333\n",
      "Epoch: 779/1000 Iteration: 7015 Train loss: 0.140865 Train acc: 0.941667\n",
      "Epoch: 779/1000 Iteration: 7020 Train loss: 0.122329 Train acc: 0.953333\n",
      "Epoch: 780/1000 Iteration: 7025 Train loss: 0.118323 Train acc: 0.950000\n",
      "Epoch: 780/1000 Iteration: 7025 Validation loss: 0.121962 Validation acc: 0.952778\n",
      "Epoch: 781/1000 Iteration: 7030 Train loss: 0.099918 Train acc: 0.963333\n",
      "Epoch: 781/1000 Iteration: 7035 Train loss: 0.095007 Train acc: 0.958333\n",
      "Epoch: 782/1000 Iteration: 7040 Train loss: 0.102873 Train acc: 0.968333\n",
      "Epoch: 782/1000 Iteration: 7045 Train loss: 0.110931 Train acc: 0.960000\n",
      "Epoch: 783/1000 Iteration: 7050 Train loss: 0.114869 Train acc: 0.953333\n",
      "Epoch: 783/1000 Iteration: 7050 Validation loss: 0.122639 Validation acc: 0.953333\n",
      "Epoch: 783/1000 Iteration: 7055 Train loss: 0.092984 Train acc: 0.968333\n",
      "Epoch: 784/1000 Iteration: 7060 Train loss: 0.141468 Train acc: 0.941667\n",
      "Epoch: 784/1000 Iteration: 7065 Train loss: 0.105006 Train acc: 0.960000\n",
      "Epoch: 785/1000 Iteration: 7070 Train loss: 0.097555 Train acc: 0.963333\n",
      "Epoch: 786/1000 Iteration: 7075 Train loss: 0.100712 Train acc: 0.961667\n",
      "Epoch: 786/1000 Iteration: 7075 Validation loss: 0.120924 Validation acc: 0.952222\n",
      "Epoch: 786/1000 Iteration: 7080 Train loss: 0.102707 Train acc: 0.961667\n",
      "Epoch: 787/1000 Iteration: 7085 Train loss: 0.100954 Train acc: 0.965000\n",
      "Epoch: 787/1000 Iteration: 7090 Train loss: 0.103261 Train acc: 0.968333\n",
      "Epoch: 788/1000 Iteration: 7095 Train loss: 0.120513 Train acc: 0.948333\n",
      "Epoch: 788/1000 Iteration: 7100 Train loss: 0.096975 Train acc: 0.973333\n",
      "Epoch: 788/1000 Iteration: 7100 Validation loss: 0.120832 Validation acc: 0.953889\n",
      "Epoch: 789/1000 Iteration: 7105 Train loss: 0.140843 Train acc: 0.943333\n",
      "Epoch: 789/1000 Iteration: 7110 Train loss: 0.125897 Train acc: 0.953333\n",
      "Epoch: 790/1000 Iteration: 7115 Train loss: 0.104351 Train acc: 0.955000\n",
      "Epoch: 791/1000 Iteration: 7120 Train loss: 0.110110 Train acc: 0.961667\n",
      "Epoch: 791/1000 Iteration: 7125 Train loss: 0.095124 Train acc: 0.956667\n",
      "Epoch: 791/1000 Iteration: 7125 Validation loss: 0.116272 Validation acc: 0.953333\n",
      "Epoch: 792/1000 Iteration: 7130 Train loss: 0.110815 Train acc: 0.958333\n",
      "Epoch: 792/1000 Iteration: 7135 Train loss: 0.097594 Train acc: 0.970000\n",
      "Epoch: 793/1000 Iteration: 7140 Train loss: 0.118110 Train acc: 0.948333\n",
      "Epoch: 793/1000 Iteration: 7145 Train loss: 0.099511 Train acc: 0.970000\n",
      "Epoch: 794/1000 Iteration: 7150 Train loss: 0.137381 Train acc: 0.948333\n",
      "Epoch: 794/1000 Iteration: 7150 Validation loss: 0.125089 Validation acc: 0.951111\n",
      "Epoch: 794/1000 Iteration: 7155 Train loss: 0.116729 Train acc: 0.960000\n",
      "Epoch: 795/1000 Iteration: 7160 Train loss: 0.118821 Train acc: 0.955000\n",
      "Epoch: 796/1000 Iteration: 7165 Train loss: 0.104988 Train acc: 0.961667\n",
      "Epoch: 796/1000 Iteration: 7170 Train loss: 0.105225 Train acc: 0.958333\n",
      "Epoch: 797/1000 Iteration: 7175 Train loss: 0.116251 Train acc: 0.958333\n",
      "Epoch: 797/1000 Iteration: 7175 Validation loss: 0.117953 Validation acc: 0.951667\n",
      "Epoch: 797/1000 Iteration: 7180 Train loss: 0.097041 Train acc: 0.965000\n",
      "Epoch: 798/1000 Iteration: 7185 Train loss: 0.120501 Train acc: 0.941667\n",
      "Epoch: 798/1000 Iteration: 7190 Train loss: 0.094646 Train acc: 0.970000\n",
      "Epoch: 799/1000 Iteration: 7195 Train loss: 0.146788 Train acc: 0.933333\n",
      "Epoch: 799/1000 Iteration: 7200 Train loss: 0.121400 Train acc: 0.955000\n",
      "Epoch: 799/1000 Iteration: 7200 Validation loss: 0.117446 Validation acc: 0.952778\n",
      "Epoch: 800/1000 Iteration: 7205 Train loss: 0.105421 Train acc: 0.951667\n",
      "Epoch: 801/1000 Iteration: 7210 Train loss: 0.112518 Train acc: 0.963333\n",
      "Epoch: 801/1000 Iteration: 7215 Train loss: 0.100699 Train acc: 0.960000\n",
      "Epoch: 802/1000 Iteration: 7220 Train loss: 0.103561 Train acc: 0.970000\n",
      "Epoch: 802/1000 Iteration: 7225 Train loss: 0.114722 Train acc: 0.960000\n",
      "Epoch: 802/1000 Iteration: 7225 Validation loss: 0.118162 Validation acc: 0.952222\n",
      "Epoch: 803/1000 Iteration: 7230 Train loss: 0.101331 Train acc: 0.958333\n",
      "Epoch: 803/1000 Iteration: 7235 Train loss: 0.092584 Train acc: 0.973333\n",
      "Epoch: 804/1000 Iteration: 7240 Train loss: 0.146257 Train acc: 0.938333\n",
      "Epoch: 804/1000 Iteration: 7245 Train loss: 0.121661 Train acc: 0.961667\n",
      "Epoch: 805/1000 Iteration: 7250 Train loss: 0.108609 Train acc: 0.958333\n",
      "Epoch: 805/1000 Iteration: 7250 Validation loss: 0.119523 Validation acc: 0.952778\n",
      "Epoch: 806/1000 Iteration: 7255 Train loss: 0.104506 Train acc: 0.966667\n",
      "Epoch: 806/1000 Iteration: 7260 Train loss: 0.092508 Train acc: 0.965000\n",
      "Epoch: 807/1000 Iteration: 7265 Train loss: 0.110876 Train acc: 0.961667\n",
      "Epoch: 807/1000 Iteration: 7270 Train loss: 0.091543 Train acc: 0.968333\n",
      "Epoch: 808/1000 Iteration: 7275 Train loss: 0.122266 Train acc: 0.956667\n",
      "Epoch: 808/1000 Iteration: 7275 Validation loss: 0.123662 Validation acc: 0.952778\n",
      "Epoch: 808/1000 Iteration: 7280 Train loss: 0.091721 Train acc: 0.970000\n",
      "Epoch: 809/1000 Iteration: 7285 Train loss: 0.140814 Train acc: 0.950000\n",
      "Epoch: 809/1000 Iteration: 7290 Train loss: 0.124229 Train acc: 0.963333\n",
      "Epoch: 810/1000 Iteration: 7295 Train loss: 0.096558 Train acc: 0.963333\n",
      "Epoch: 811/1000 Iteration: 7300 Train loss: 0.104349 Train acc: 0.966667\n",
      "Epoch: 811/1000 Iteration: 7300 Validation loss: 0.121201 Validation acc: 0.952222\n",
      "Epoch: 811/1000 Iteration: 7305 Train loss: 0.093634 Train acc: 0.965000\n",
      "Epoch: 812/1000 Iteration: 7310 Train loss: 0.101663 Train acc: 0.965000\n",
      "Epoch: 812/1000 Iteration: 7315 Train loss: 0.109595 Train acc: 0.968333\n",
      "Epoch: 813/1000 Iteration: 7320 Train loss: 0.118968 Train acc: 0.955000\n",
      "Epoch: 813/1000 Iteration: 7325 Train loss: 0.091654 Train acc: 0.968333\n",
      "Epoch: 813/1000 Iteration: 7325 Validation loss: 0.114828 Validation acc: 0.953889\n",
      "Epoch: 814/1000 Iteration: 7330 Train loss: 0.139178 Train acc: 0.941667\n",
      "Epoch: 814/1000 Iteration: 7335 Train loss: 0.125823 Train acc: 0.958333\n",
      "Epoch: 815/1000 Iteration: 7340 Train loss: 0.105946 Train acc: 0.958333\n",
      "Epoch: 816/1000 Iteration: 7345 Train loss: 0.117041 Train acc: 0.950000\n",
      "Epoch: 816/1000 Iteration: 7350 Train loss: 0.100272 Train acc: 0.970000\n",
      "Epoch: 816/1000 Iteration: 7350 Validation loss: 0.117303 Validation acc: 0.951667\n",
      "Epoch: 817/1000 Iteration: 7355 Train loss: 0.106355 Train acc: 0.963333\n",
      "Epoch: 817/1000 Iteration: 7360 Train loss: 0.111046 Train acc: 0.961667\n",
      "Epoch: 818/1000 Iteration: 7365 Train loss: 0.126750 Train acc: 0.950000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 818/1000 Iteration: 7370 Train loss: 0.093133 Train acc: 0.968333\n",
      "Epoch: 819/1000 Iteration: 7375 Train loss: 0.143915 Train acc: 0.933333\n",
      "Epoch: 819/1000 Iteration: 7375 Validation loss: 0.115277 Validation acc: 0.952222\n",
      "Epoch: 819/1000 Iteration: 7380 Train loss: 0.114196 Train acc: 0.958333\n",
      "Epoch: 820/1000 Iteration: 7385 Train loss: 0.101015 Train acc: 0.961667\n",
      "Epoch: 821/1000 Iteration: 7390 Train loss: 0.116087 Train acc: 0.951667\n",
      "Epoch: 821/1000 Iteration: 7395 Train loss: 0.099326 Train acc: 0.963333\n",
      "Epoch: 822/1000 Iteration: 7400 Train loss: 0.105627 Train acc: 0.961667\n",
      "Epoch: 822/1000 Iteration: 7400 Validation loss: 0.112937 Validation acc: 0.952778\n",
      "Epoch: 822/1000 Iteration: 7405 Train loss: 0.097671 Train acc: 0.968333\n",
      "Epoch: 823/1000 Iteration: 7410 Train loss: 0.119667 Train acc: 0.951667\n",
      "Epoch: 823/1000 Iteration: 7415 Train loss: 0.093495 Train acc: 0.968333\n",
      "Epoch: 824/1000 Iteration: 7420 Train loss: 0.167705 Train acc: 0.940000\n",
      "Epoch: 824/1000 Iteration: 7425 Train loss: 0.123318 Train acc: 0.958333\n",
      "Epoch: 824/1000 Iteration: 7425 Validation loss: 0.112320 Validation acc: 0.952778\n",
      "Epoch: 825/1000 Iteration: 7430 Train loss: 0.099542 Train acc: 0.958333\n",
      "Epoch: 826/1000 Iteration: 7435 Train loss: 0.112625 Train acc: 0.960000\n",
      "Epoch: 826/1000 Iteration: 7440 Train loss: 0.095550 Train acc: 0.965000\n",
      "Epoch: 827/1000 Iteration: 7445 Train loss: 0.123105 Train acc: 0.955000\n",
      "Epoch: 827/1000 Iteration: 7450 Train loss: 0.100182 Train acc: 0.966667\n",
      "Epoch: 827/1000 Iteration: 7450 Validation loss: 0.116797 Validation acc: 0.952222\n",
      "Epoch: 828/1000 Iteration: 7455 Train loss: 0.117017 Train acc: 0.960000\n",
      "Epoch: 828/1000 Iteration: 7460 Train loss: 0.091408 Train acc: 0.970000\n",
      "Epoch: 829/1000 Iteration: 7465 Train loss: 0.131676 Train acc: 0.948333\n",
      "Epoch: 829/1000 Iteration: 7470 Train loss: 0.117979 Train acc: 0.965000\n",
      "Epoch: 830/1000 Iteration: 7475 Train loss: 0.106989 Train acc: 0.960000\n",
      "Epoch: 830/1000 Iteration: 7475 Validation loss: 0.114949 Validation acc: 0.953333\n",
      "Epoch: 831/1000 Iteration: 7480 Train loss: 0.107604 Train acc: 0.958333\n",
      "Epoch: 831/1000 Iteration: 7485 Train loss: 0.104628 Train acc: 0.961667\n",
      "Epoch: 832/1000 Iteration: 7490 Train loss: 0.098490 Train acc: 0.966667\n",
      "Epoch: 832/1000 Iteration: 7495 Train loss: 0.095382 Train acc: 0.968333\n",
      "Epoch: 833/1000 Iteration: 7500 Train loss: 0.123881 Train acc: 0.948333\n",
      "Epoch: 833/1000 Iteration: 7500 Validation loss: 0.116147 Validation acc: 0.953333\n",
      "Epoch: 833/1000 Iteration: 7505 Train loss: 0.087591 Train acc: 0.968333\n",
      "Epoch: 834/1000 Iteration: 7510 Train loss: 0.128472 Train acc: 0.943333\n",
      "Epoch: 834/1000 Iteration: 7515 Train loss: 0.117497 Train acc: 0.961667\n",
      "Epoch: 835/1000 Iteration: 7520 Train loss: 0.114692 Train acc: 0.955000\n",
      "Epoch: 836/1000 Iteration: 7525 Train loss: 0.107333 Train acc: 0.963333\n",
      "Epoch: 836/1000 Iteration: 7525 Validation loss: 0.110688 Validation acc: 0.952778\n",
      "Epoch: 836/1000 Iteration: 7530 Train loss: 0.111927 Train acc: 0.963333\n",
      "Epoch: 837/1000 Iteration: 7535 Train loss: 0.148198 Train acc: 0.955000\n",
      "Epoch: 837/1000 Iteration: 7540 Train loss: 0.115152 Train acc: 0.953333\n",
      "Epoch: 838/1000 Iteration: 7545 Train loss: 0.116885 Train acc: 0.953333\n",
      "Epoch: 838/1000 Iteration: 7550 Train loss: 0.102665 Train acc: 0.965000\n",
      "Epoch: 838/1000 Iteration: 7550 Validation loss: 0.118596 Validation acc: 0.953889\n",
      "Epoch: 839/1000 Iteration: 7555 Train loss: 0.155457 Train acc: 0.936667\n",
      "Epoch: 839/1000 Iteration: 7560 Train loss: 0.125166 Train acc: 0.956667\n",
      "Epoch: 840/1000 Iteration: 7565 Train loss: 0.096713 Train acc: 0.968333\n",
      "Epoch: 841/1000 Iteration: 7570 Train loss: 0.111572 Train acc: 0.958333\n",
      "Epoch: 841/1000 Iteration: 7575 Train loss: 0.089695 Train acc: 0.973333\n",
      "Epoch: 841/1000 Iteration: 7575 Validation loss: 0.116555 Validation acc: 0.952222\n",
      "Epoch: 842/1000 Iteration: 7580 Train loss: 0.099202 Train acc: 0.968333\n",
      "Epoch: 842/1000 Iteration: 7585 Train loss: 0.095652 Train acc: 0.963333\n",
      "Epoch: 843/1000 Iteration: 7590 Train loss: 0.118135 Train acc: 0.955000\n",
      "Epoch: 843/1000 Iteration: 7595 Train loss: 0.105260 Train acc: 0.963333\n",
      "Epoch: 844/1000 Iteration: 7600 Train loss: 0.146047 Train acc: 0.930000\n",
      "Epoch: 844/1000 Iteration: 7600 Validation loss: 0.116491 Validation acc: 0.953333\n",
      "Epoch: 844/1000 Iteration: 7605 Train loss: 0.114646 Train acc: 0.955000\n",
      "Epoch: 845/1000 Iteration: 7610 Train loss: 0.108525 Train acc: 0.955000\n",
      "Epoch: 846/1000 Iteration: 7615 Train loss: 0.100776 Train acc: 0.965000\n",
      "Epoch: 846/1000 Iteration: 7620 Train loss: 0.098496 Train acc: 0.960000\n",
      "Epoch: 847/1000 Iteration: 7625 Train loss: 0.109494 Train acc: 0.956667\n",
      "Epoch: 847/1000 Iteration: 7625 Validation loss: 0.119095 Validation acc: 0.952222\n",
      "Epoch: 847/1000 Iteration: 7630 Train loss: 0.100890 Train acc: 0.970000\n",
      "Epoch: 848/1000 Iteration: 7635 Train loss: 0.107238 Train acc: 0.956667\n",
      "Epoch: 848/1000 Iteration: 7640 Train loss: 0.100183 Train acc: 0.968333\n",
      "Epoch: 849/1000 Iteration: 7645 Train loss: 0.150985 Train acc: 0.940000\n",
      "Epoch: 849/1000 Iteration: 7650 Train loss: 0.126670 Train acc: 0.960000\n",
      "Epoch: 849/1000 Iteration: 7650 Validation loss: 0.108050 Validation acc: 0.951667\n",
      "Epoch: 850/1000 Iteration: 7655 Train loss: 0.109367 Train acc: 0.956667\n",
      "Epoch: 851/1000 Iteration: 7660 Train loss: 0.106553 Train acc: 0.958333\n",
      "Epoch: 851/1000 Iteration: 7665 Train loss: 0.095545 Train acc: 0.971667\n",
      "Epoch: 852/1000 Iteration: 7670 Train loss: 0.104475 Train acc: 0.970000\n",
      "Epoch: 852/1000 Iteration: 7675 Train loss: 0.111470 Train acc: 0.963333\n",
      "Epoch: 852/1000 Iteration: 7675 Validation loss: 0.106162 Validation acc: 0.953889\n",
      "Epoch: 853/1000 Iteration: 7680 Train loss: 0.118310 Train acc: 0.951667\n",
      "Epoch: 853/1000 Iteration: 7685 Train loss: 0.098888 Train acc: 0.968333\n",
      "Epoch: 854/1000 Iteration: 7690 Train loss: 0.164448 Train acc: 0.935000\n",
      "Epoch: 854/1000 Iteration: 7695 Train loss: 0.130300 Train acc: 0.951667\n",
      "Epoch: 855/1000 Iteration: 7700 Train loss: 0.113365 Train acc: 0.951667\n",
      "Epoch: 855/1000 Iteration: 7700 Validation loss: 0.123527 Validation acc: 0.951111\n",
      "Epoch: 856/1000 Iteration: 7705 Train loss: 0.117445 Train acc: 0.960000\n",
      "Epoch: 856/1000 Iteration: 7710 Train loss: 0.091057 Train acc: 0.968333\n",
      "Epoch: 857/1000 Iteration: 7715 Train loss: 0.100405 Train acc: 0.966667\n",
      "Epoch: 857/1000 Iteration: 7720 Train loss: 0.105382 Train acc: 0.968333\n",
      "Epoch: 858/1000 Iteration: 7725 Train loss: 0.122988 Train acc: 0.946667\n",
      "Epoch: 858/1000 Iteration: 7725 Validation loss: 0.114093 Validation acc: 0.952778\n",
      "Epoch: 858/1000 Iteration: 7730 Train loss: 0.084485 Train acc: 0.975000\n",
      "Epoch: 859/1000 Iteration: 7735 Train loss: 0.139823 Train acc: 0.935000\n",
      "Epoch: 859/1000 Iteration: 7740 Train loss: 0.119779 Train acc: 0.960000\n",
      "Epoch: 860/1000 Iteration: 7745 Train loss: 0.103786 Train acc: 0.960000\n",
      "Epoch: 861/1000 Iteration: 7750 Train loss: 0.097557 Train acc: 0.965000\n",
      "Epoch: 861/1000 Iteration: 7750 Validation loss: 0.114265 Validation acc: 0.952222\n",
      "Epoch: 861/1000 Iteration: 7755 Train loss: 0.096942 Train acc: 0.961667\n",
      "Epoch: 862/1000 Iteration: 7760 Train loss: 0.107478 Train acc: 0.963333\n",
      "Epoch: 862/1000 Iteration: 7765 Train loss: 0.102637 Train acc: 0.966667\n",
      "Epoch: 863/1000 Iteration: 7770 Train loss: 0.121108 Train acc: 0.945000\n",
      "Epoch: 863/1000 Iteration: 7775 Train loss: 0.083071 Train acc: 0.973333\n",
      "Epoch: 863/1000 Iteration: 7775 Validation loss: 0.110816 Validation acc: 0.952778\n",
      "Epoch: 864/1000 Iteration: 7780 Train loss: 0.142884 Train acc: 0.940000\n",
      "Epoch: 864/1000 Iteration: 7785 Train loss: 0.125016 Train acc: 0.958333\n",
      "Epoch: 865/1000 Iteration: 7790 Train loss: 0.105705 Train acc: 0.965000\n",
      "Epoch: 866/1000 Iteration: 7795 Train loss: 0.107927 Train acc: 0.961667\n",
      "Epoch: 866/1000 Iteration: 7800 Train loss: 0.098833 Train acc: 0.960000\n",
      "Epoch: 866/1000 Iteration: 7800 Validation loss: 0.111471 Validation acc: 0.953333\n",
      "Epoch: 867/1000 Iteration: 7805 Train loss: 0.109201 Train acc: 0.961667\n",
      "Epoch: 867/1000 Iteration: 7810 Train loss: 0.101243 Train acc: 0.960000\n",
      "Epoch: 868/1000 Iteration: 7815 Train loss: 0.116109 Train acc: 0.953333\n",
      "Epoch: 868/1000 Iteration: 7820 Train loss: 0.088734 Train acc: 0.965000\n",
      "Epoch: 869/1000 Iteration: 7825 Train loss: 0.150772 Train acc: 0.933333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 869/1000 Iteration: 7825 Validation loss: 0.113114 Validation acc: 0.953333\n",
      "Epoch: 869/1000 Iteration: 7830 Train loss: 0.123745 Train acc: 0.958333\n",
      "Epoch: 870/1000 Iteration: 7835 Train loss: 0.101457 Train acc: 0.955000\n",
      "Epoch: 871/1000 Iteration: 7840 Train loss: 0.110910 Train acc: 0.956667\n",
      "Epoch: 871/1000 Iteration: 7845 Train loss: 0.088807 Train acc: 0.966667\n",
      "Epoch: 872/1000 Iteration: 7850 Train loss: 0.098810 Train acc: 0.965000\n",
      "Epoch: 872/1000 Iteration: 7850 Validation loss: 0.116075 Validation acc: 0.953333\n",
      "Epoch: 872/1000 Iteration: 7855 Train loss: 0.102033 Train acc: 0.963333\n",
      "Epoch: 873/1000 Iteration: 7860 Train loss: 0.115236 Train acc: 0.950000\n",
      "Epoch: 873/1000 Iteration: 7865 Train loss: 0.087851 Train acc: 0.970000\n",
      "Epoch: 874/1000 Iteration: 7870 Train loss: 0.136899 Train acc: 0.946667\n",
      "Epoch: 874/1000 Iteration: 7875 Train loss: 0.131340 Train acc: 0.955000\n",
      "Epoch: 874/1000 Iteration: 7875 Validation loss: 0.114291 Validation acc: 0.952778\n",
      "Epoch: 875/1000 Iteration: 7880 Train loss: 0.096503 Train acc: 0.963333\n",
      "Epoch: 876/1000 Iteration: 7885 Train loss: 0.112398 Train acc: 0.953333\n",
      "Epoch: 876/1000 Iteration: 7890 Train loss: 0.091184 Train acc: 0.971667\n",
      "Epoch: 877/1000 Iteration: 7895 Train loss: 0.096726 Train acc: 0.971667\n",
      "Epoch: 877/1000 Iteration: 7900 Train loss: 0.098077 Train acc: 0.968333\n",
      "Epoch: 877/1000 Iteration: 7900 Validation loss: 0.115745 Validation acc: 0.955000\n",
      "Epoch: 878/1000 Iteration: 7905 Train loss: 0.120111 Train acc: 0.948333\n",
      "Epoch: 878/1000 Iteration: 7910 Train loss: 0.096022 Train acc: 0.961667\n",
      "Epoch: 879/1000 Iteration: 7915 Train loss: 0.135570 Train acc: 0.948333\n",
      "Epoch: 879/1000 Iteration: 7920 Train loss: 0.116067 Train acc: 0.960000\n",
      "Epoch: 880/1000 Iteration: 7925 Train loss: 0.101981 Train acc: 0.950000\n",
      "Epoch: 880/1000 Iteration: 7925 Validation loss: 0.111775 Validation acc: 0.954444\n",
      "Epoch: 881/1000 Iteration: 7930 Train loss: 0.111230 Train acc: 0.950000\n",
      "Epoch: 881/1000 Iteration: 7935 Train loss: 0.085762 Train acc: 0.961667\n",
      "Epoch: 882/1000 Iteration: 7940 Train loss: 0.101225 Train acc: 0.963333\n",
      "Epoch: 882/1000 Iteration: 7945 Train loss: 0.094851 Train acc: 0.968333\n",
      "Epoch: 883/1000 Iteration: 7950 Train loss: 0.120077 Train acc: 0.946667\n",
      "Epoch: 883/1000 Iteration: 7950 Validation loss: 0.113460 Validation acc: 0.953333\n",
      "Epoch: 883/1000 Iteration: 7955 Train loss: 0.091032 Train acc: 0.965000\n",
      "Epoch: 884/1000 Iteration: 7960 Train loss: 0.137099 Train acc: 0.948333\n",
      "Epoch: 884/1000 Iteration: 7965 Train loss: 0.110831 Train acc: 0.956667\n",
      "Epoch: 885/1000 Iteration: 7970 Train loss: 0.097619 Train acc: 0.963333\n",
      "Epoch: 886/1000 Iteration: 7975 Train loss: 0.102515 Train acc: 0.960000\n",
      "Epoch: 886/1000 Iteration: 7975 Validation loss: 0.107198 Validation acc: 0.953889\n",
      "Epoch: 886/1000 Iteration: 7980 Train loss: 0.100276 Train acc: 0.965000\n",
      "Epoch: 887/1000 Iteration: 7985 Train loss: 0.095729 Train acc: 0.970000\n",
      "Epoch: 887/1000 Iteration: 7990 Train loss: 0.101103 Train acc: 0.963333\n",
      "Epoch: 888/1000 Iteration: 7995 Train loss: 0.115627 Train acc: 0.951667\n",
      "Epoch: 888/1000 Iteration: 8000 Train loss: 0.085802 Train acc: 0.968333\n",
      "Epoch: 888/1000 Iteration: 8000 Validation loss: 0.111426 Validation acc: 0.953889\n",
      "Epoch: 889/1000 Iteration: 8005 Train loss: 0.125467 Train acc: 0.943333\n",
      "Epoch: 889/1000 Iteration: 8010 Train loss: 0.124641 Train acc: 0.960000\n",
      "Epoch: 890/1000 Iteration: 8015 Train loss: 0.116876 Train acc: 0.945000\n",
      "Epoch: 891/1000 Iteration: 8020 Train loss: 0.102867 Train acc: 0.961667\n",
      "Epoch: 891/1000 Iteration: 8025 Train loss: 0.100921 Train acc: 0.951667\n",
      "Epoch: 891/1000 Iteration: 8025 Validation loss: 0.110648 Validation acc: 0.954444\n",
      "Epoch: 892/1000 Iteration: 8030 Train loss: 0.113527 Train acc: 0.960000\n",
      "Epoch: 892/1000 Iteration: 8035 Train loss: 0.096484 Train acc: 0.966667\n",
      "Epoch: 893/1000 Iteration: 8040 Train loss: 0.114360 Train acc: 0.955000\n",
      "Epoch: 893/1000 Iteration: 8045 Train loss: 0.085543 Train acc: 0.965000\n",
      "Epoch: 894/1000 Iteration: 8050 Train loss: 0.130343 Train acc: 0.946667\n",
      "Epoch: 894/1000 Iteration: 8050 Validation loss: 0.110777 Validation acc: 0.955000\n",
      "Epoch: 894/1000 Iteration: 8055 Train loss: 0.128638 Train acc: 0.966667\n",
      "Epoch: 895/1000 Iteration: 8060 Train loss: 0.101091 Train acc: 0.965000\n",
      "Epoch: 896/1000 Iteration: 8065 Train loss: 0.112079 Train acc: 0.951667\n",
      "Epoch: 896/1000 Iteration: 8070 Train loss: 0.087746 Train acc: 0.965000\n",
      "Epoch: 897/1000 Iteration: 8075 Train loss: 0.100283 Train acc: 0.963333\n",
      "Epoch: 897/1000 Iteration: 8075 Validation loss: 0.110713 Validation acc: 0.956111\n",
      "Epoch: 897/1000 Iteration: 8080 Train loss: 0.095355 Train acc: 0.968333\n",
      "Epoch: 898/1000 Iteration: 8085 Train loss: 0.114090 Train acc: 0.958333\n",
      "Epoch: 898/1000 Iteration: 8090 Train loss: 0.083627 Train acc: 0.975000\n",
      "Epoch: 899/1000 Iteration: 8095 Train loss: 0.131484 Train acc: 0.936667\n",
      "Epoch: 899/1000 Iteration: 8100 Train loss: 0.142096 Train acc: 0.948333\n",
      "Epoch: 899/1000 Iteration: 8100 Validation loss: 0.111795 Validation acc: 0.953333\n",
      "Epoch: 900/1000 Iteration: 8105 Train loss: 0.113977 Train acc: 0.951667\n",
      "Epoch: 901/1000 Iteration: 8110 Train loss: 0.109021 Train acc: 0.960000\n",
      "Epoch: 901/1000 Iteration: 8115 Train loss: 0.094256 Train acc: 0.961667\n",
      "Epoch: 902/1000 Iteration: 8120 Train loss: 0.103311 Train acc: 0.963333\n",
      "Epoch: 902/1000 Iteration: 8125 Train loss: 0.090388 Train acc: 0.970000\n",
      "Epoch: 902/1000 Iteration: 8125 Validation loss: 0.111912 Validation acc: 0.953333\n",
      "Epoch: 903/1000 Iteration: 8130 Train loss: 0.118558 Train acc: 0.950000\n",
      "Epoch: 903/1000 Iteration: 8135 Train loss: 0.090256 Train acc: 0.965000\n",
      "Epoch: 904/1000 Iteration: 8140 Train loss: 0.126505 Train acc: 0.946667\n",
      "Epoch: 904/1000 Iteration: 8145 Train loss: 0.110783 Train acc: 0.965000\n",
      "Epoch: 905/1000 Iteration: 8150 Train loss: 0.106738 Train acc: 0.951667\n",
      "Epoch: 905/1000 Iteration: 8150 Validation loss: 0.112438 Validation acc: 0.955000\n",
      "Epoch: 906/1000 Iteration: 8155 Train loss: 0.113557 Train acc: 0.956667\n",
      "Epoch: 906/1000 Iteration: 8160 Train loss: 0.102951 Train acc: 0.966667\n",
      "Epoch: 907/1000 Iteration: 8165 Train loss: 0.106306 Train acc: 0.961667\n",
      "Epoch: 907/1000 Iteration: 8170 Train loss: 0.098543 Train acc: 0.963333\n",
      "Epoch: 908/1000 Iteration: 8175 Train loss: 0.113922 Train acc: 0.956667\n",
      "Epoch: 908/1000 Iteration: 8175 Validation loss: 0.113851 Validation acc: 0.956667\n",
      "Epoch: 908/1000 Iteration: 8180 Train loss: 0.089093 Train acc: 0.968333\n",
      "Epoch: 909/1000 Iteration: 8185 Train loss: 0.137835 Train acc: 0.946667\n",
      "Epoch: 909/1000 Iteration: 8190 Train loss: 0.103159 Train acc: 0.961667\n",
      "Epoch: 910/1000 Iteration: 8195 Train loss: 0.106607 Train acc: 0.963333\n",
      "Epoch: 911/1000 Iteration: 8200 Train loss: 0.104805 Train acc: 0.961667\n",
      "Epoch: 911/1000 Iteration: 8200 Validation loss: 0.110971 Validation acc: 0.953889\n",
      "Epoch: 911/1000 Iteration: 8205 Train loss: 0.082299 Train acc: 0.961667\n",
      "Epoch: 912/1000 Iteration: 8210 Train loss: 0.104003 Train acc: 0.958333\n",
      "Epoch: 912/1000 Iteration: 8215 Train loss: 0.092403 Train acc: 0.958333\n",
      "Epoch: 913/1000 Iteration: 8220 Train loss: 0.119248 Train acc: 0.951667\n",
      "Epoch: 913/1000 Iteration: 8225 Train loss: 0.085772 Train acc: 0.975000\n",
      "Epoch: 913/1000 Iteration: 8225 Validation loss: 0.111312 Validation acc: 0.955555\n",
      "Epoch: 914/1000 Iteration: 8230 Train loss: 0.132222 Train acc: 0.943333\n",
      "Epoch: 914/1000 Iteration: 8235 Train loss: 0.120981 Train acc: 0.946667\n",
      "Epoch: 915/1000 Iteration: 8240 Train loss: 0.102065 Train acc: 0.965000\n",
      "Epoch: 916/1000 Iteration: 8245 Train loss: 0.105359 Train acc: 0.956667\n",
      "Epoch: 916/1000 Iteration: 8250 Train loss: 0.091906 Train acc: 0.970000\n",
      "Epoch: 916/1000 Iteration: 8250 Validation loss: 0.111219 Validation acc: 0.953333\n",
      "Epoch: 917/1000 Iteration: 8255 Train loss: 0.095618 Train acc: 0.968333\n",
      "Epoch: 917/1000 Iteration: 8260 Train loss: 0.094928 Train acc: 0.965000\n",
      "Epoch: 918/1000 Iteration: 8265 Train loss: 0.124118 Train acc: 0.948333\n",
      "Epoch: 918/1000 Iteration: 8270 Train loss: 0.087990 Train acc: 0.961667\n",
      "Epoch: 919/1000 Iteration: 8275 Train loss: 0.130268 Train acc: 0.948333\n",
      "Epoch: 919/1000 Iteration: 8275 Validation loss: 0.107705 Validation acc: 0.955555\n",
      "Epoch: 919/1000 Iteration: 8280 Train loss: 0.122032 Train acc: 0.961667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 920/1000 Iteration: 8285 Train loss: 0.106959 Train acc: 0.955000\n",
      "Epoch: 921/1000 Iteration: 8290 Train loss: 0.117778 Train acc: 0.955000\n",
      "Epoch: 921/1000 Iteration: 8295 Train loss: 0.092173 Train acc: 0.966667\n",
      "Epoch: 922/1000 Iteration: 8300 Train loss: 0.096359 Train acc: 0.960000\n",
      "Epoch: 922/1000 Iteration: 8300 Validation loss: 0.110107 Validation acc: 0.955555\n",
      "Epoch: 922/1000 Iteration: 8305 Train loss: 0.090356 Train acc: 0.965000\n",
      "Epoch: 923/1000 Iteration: 8310 Train loss: 0.113684 Train acc: 0.956667\n",
      "Epoch: 923/1000 Iteration: 8315 Train loss: 0.095214 Train acc: 0.975000\n",
      "Epoch: 924/1000 Iteration: 8320 Train loss: 0.144874 Train acc: 0.931667\n",
      "Epoch: 924/1000 Iteration: 8325 Train loss: 0.111493 Train acc: 0.955000\n",
      "Epoch: 924/1000 Iteration: 8325 Validation loss: 0.107176 Validation acc: 0.954444\n",
      "Epoch: 925/1000 Iteration: 8330 Train loss: 0.097101 Train acc: 0.955000\n",
      "Epoch: 926/1000 Iteration: 8335 Train loss: 0.098102 Train acc: 0.956667\n",
      "Epoch: 926/1000 Iteration: 8340 Train loss: 0.089154 Train acc: 0.961667\n",
      "Epoch: 927/1000 Iteration: 8345 Train loss: 0.093516 Train acc: 0.975000\n",
      "Epoch: 927/1000 Iteration: 8350 Train loss: 0.098946 Train acc: 0.968333\n",
      "Epoch: 927/1000 Iteration: 8350 Validation loss: 0.109020 Validation acc: 0.955000\n",
      "Epoch: 928/1000 Iteration: 8355 Train loss: 0.097551 Train acc: 0.965000\n",
      "Epoch: 928/1000 Iteration: 8360 Train loss: 0.093756 Train acc: 0.965000\n",
      "Epoch: 929/1000 Iteration: 8365 Train loss: 0.130170 Train acc: 0.938333\n",
      "Epoch: 929/1000 Iteration: 8370 Train loss: 0.109131 Train acc: 0.961667\n",
      "Epoch: 930/1000 Iteration: 8375 Train loss: 0.116845 Train acc: 0.965000\n",
      "Epoch: 930/1000 Iteration: 8375 Validation loss: 0.106795 Validation acc: 0.955000\n",
      "Epoch: 931/1000 Iteration: 8380 Train loss: 0.111442 Train acc: 0.955000\n",
      "Epoch: 931/1000 Iteration: 8385 Train loss: 0.079274 Train acc: 0.970000\n",
      "Epoch: 932/1000 Iteration: 8390 Train loss: 0.093578 Train acc: 0.963333\n",
      "Epoch: 932/1000 Iteration: 8395 Train loss: 0.099591 Train acc: 0.973333\n",
      "Epoch: 933/1000 Iteration: 8400 Train loss: 0.124580 Train acc: 0.953333\n",
      "Epoch: 933/1000 Iteration: 8400 Validation loss: 0.108584 Validation acc: 0.954444\n",
      "Epoch: 933/1000 Iteration: 8405 Train loss: 0.083102 Train acc: 0.971667\n",
      "Epoch: 934/1000 Iteration: 8410 Train loss: 0.128409 Train acc: 0.940000\n",
      "Epoch: 934/1000 Iteration: 8415 Train loss: 0.113363 Train acc: 0.955000\n",
      "Epoch: 935/1000 Iteration: 8420 Train loss: 0.107101 Train acc: 0.958333\n",
      "Epoch: 936/1000 Iteration: 8425 Train loss: 0.099388 Train acc: 0.956667\n",
      "Epoch: 936/1000 Iteration: 8425 Validation loss: 0.108714 Validation acc: 0.954444\n",
      "Epoch: 936/1000 Iteration: 8430 Train loss: 0.086677 Train acc: 0.961667\n",
      "Epoch: 937/1000 Iteration: 8435 Train loss: 0.096920 Train acc: 0.968333\n",
      "Epoch: 937/1000 Iteration: 8440 Train loss: 0.092874 Train acc: 0.965000\n",
      "Epoch: 938/1000 Iteration: 8445 Train loss: 0.121780 Train acc: 0.945000\n",
      "Epoch: 938/1000 Iteration: 8450 Train loss: 0.093694 Train acc: 0.971667\n",
      "Epoch: 938/1000 Iteration: 8450 Validation loss: 0.110924 Validation acc: 0.953889\n",
      "Epoch: 939/1000 Iteration: 8455 Train loss: 0.129124 Train acc: 0.941667\n",
      "Epoch: 939/1000 Iteration: 8460 Train loss: 0.106863 Train acc: 0.961667\n",
      "Epoch: 940/1000 Iteration: 8465 Train loss: 0.095177 Train acc: 0.960000\n",
      "Epoch: 941/1000 Iteration: 8470 Train loss: 0.104304 Train acc: 0.956667\n",
      "Epoch: 941/1000 Iteration: 8475 Train loss: 0.089392 Train acc: 0.960000\n",
      "Epoch: 941/1000 Iteration: 8475 Validation loss: 0.105541 Validation acc: 0.953333\n",
      "Epoch: 942/1000 Iteration: 8480 Train loss: 0.094753 Train acc: 0.965000\n",
      "Epoch: 942/1000 Iteration: 8485 Train loss: 0.088976 Train acc: 0.965000\n",
      "Epoch: 943/1000 Iteration: 8490 Train loss: 0.108773 Train acc: 0.950000\n",
      "Epoch: 943/1000 Iteration: 8495 Train loss: 0.089785 Train acc: 0.965000\n",
      "Epoch: 944/1000 Iteration: 8500 Train loss: 0.130386 Train acc: 0.938333\n",
      "Epoch: 944/1000 Iteration: 8500 Validation loss: 0.109280 Validation acc: 0.953333\n",
      "Epoch: 944/1000 Iteration: 8505 Train loss: 0.114549 Train acc: 0.955000\n",
      "Epoch: 945/1000 Iteration: 8510 Train loss: 0.096859 Train acc: 0.963333\n",
      "Epoch: 946/1000 Iteration: 8515 Train loss: 0.103571 Train acc: 0.961667\n",
      "Epoch: 946/1000 Iteration: 8520 Train loss: 0.080141 Train acc: 0.970000\n",
      "Epoch: 947/1000 Iteration: 8525 Train loss: 0.094032 Train acc: 0.966667\n",
      "Epoch: 947/1000 Iteration: 8525 Validation loss: 0.107785 Validation acc: 0.953333\n",
      "Epoch: 947/1000 Iteration: 8530 Train loss: 0.088964 Train acc: 0.966667\n",
      "Epoch: 948/1000 Iteration: 8535 Train loss: 0.095796 Train acc: 0.958333\n",
      "Epoch: 948/1000 Iteration: 8540 Train loss: 0.080251 Train acc: 0.973333\n",
      "Epoch: 949/1000 Iteration: 8545 Train loss: 0.127360 Train acc: 0.945000\n",
      "Epoch: 949/1000 Iteration: 8550 Train loss: 0.106148 Train acc: 0.953333\n",
      "Epoch: 949/1000 Iteration: 8550 Validation loss: 0.107969 Validation acc: 0.953333\n",
      "Epoch: 950/1000 Iteration: 8555 Train loss: 0.099795 Train acc: 0.965000\n",
      "Epoch: 951/1000 Iteration: 8560 Train loss: 0.100346 Train acc: 0.955000\n",
      "Epoch: 951/1000 Iteration: 8565 Train loss: 0.080553 Train acc: 0.973333\n",
      "Epoch: 952/1000 Iteration: 8570 Train loss: 0.099980 Train acc: 0.961667\n",
      "Epoch: 952/1000 Iteration: 8575 Train loss: 0.094331 Train acc: 0.968333\n",
      "Epoch: 952/1000 Iteration: 8575 Validation loss: 0.109287 Validation acc: 0.952778\n",
      "Epoch: 953/1000 Iteration: 8580 Train loss: 0.119373 Train acc: 0.951667\n",
      "Epoch: 953/1000 Iteration: 8585 Train loss: 0.077788 Train acc: 0.978333\n",
      "Epoch: 954/1000 Iteration: 8590 Train loss: 0.120655 Train acc: 0.948333\n",
      "Epoch: 954/1000 Iteration: 8595 Train loss: 0.110851 Train acc: 0.961667\n",
      "Epoch: 955/1000 Iteration: 8600 Train loss: 0.097506 Train acc: 0.950000\n",
      "Epoch: 955/1000 Iteration: 8600 Validation loss: 0.109907 Validation acc: 0.953889\n",
      "Epoch: 956/1000 Iteration: 8605 Train loss: 0.093696 Train acc: 0.958333\n",
      "Epoch: 956/1000 Iteration: 8610 Train loss: 0.078335 Train acc: 0.966667\n",
      "Epoch: 957/1000 Iteration: 8615 Train loss: 0.097832 Train acc: 0.955000\n",
      "Epoch: 957/1000 Iteration: 8620 Train loss: 0.085303 Train acc: 0.968333\n",
      "Epoch: 958/1000 Iteration: 8625 Train loss: 0.113140 Train acc: 0.941667\n",
      "Epoch: 958/1000 Iteration: 8625 Validation loss: 0.109848 Validation acc: 0.953333\n",
      "Epoch: 958/1000 Iteration: 8630 Train loss: 0.079516 Train acc: 0.973333\n",
      "Epoch: 959/1000 Iteration: 8635 Train loss: 0.128178 Train acc: 0.948333\n",
      "Epoch: 959/1000 Iteration: 8640 Train loss: 0.126709 Train acc: 0.956667\n",
      "Epoch: 960/1000 Iteration: 8645 Train loss: 0.109728 Train acc: 0.955000\n",
      "Epoch: 961/1000 Iteration: 8650 Train loss: 0.094978 Train acc: 0.955000\n",
      "Epoch: 961/1000 Iteration: 8650 Validation loss: 0.105735 Validation acc: 0.951667\n",
      "Epoch: 961/1000 Iteration: 8655 Train loss: 0.102785 Train acc: 0.955000\n",
      "Epoch: 962/1000 Iteration: 8660 Train loss: 0.095740 Train acc: 0.956667\n",
      "Epoch: 962/1000 Iteration: 8665 Train loss: 0.091552 Train acc: 0.968333\n",
      "Epoch: 963/1000 Iteration: 8670 Train loss: 0.120582 Train acc: 0.950000\n",
      "Epoch: 963/1000 Iteration: 8675 Train loss: 0.078463 Train acc: 0.971667\n",
      "Epoch: 963/1000 Iteration: 8675 Validation loss: 0.105996 Validation acc: 0.953333\n",
      "Epoch: 964/1000 Iteration: 8680 Train loss: 0.133347 Train acc: 0.943333\n",
      "Epoch: 964/1000 Iteration: 8685 Train loss: 0.106862 Train acc: 0.960000\n",
      "Epoch: 965/1000 Iteration: 8690 Train loss: 0.102623 Train acc: 0.948333\n",
      "Epoch: 966/1000 Iteration: 8695 Train loss: 0.087845 Train acc: 0.958333\n",
      "Epoch: 966/1000 Iteration: 8700 Train loss: 0.090158 Train acc: 0.958333\n",
      "Epoch: 966/1000 Iteration: 8700 Validation loss: 0.109691 Validation acc: 0.953889\n",
      "Epoch: 967/1000 Iteration: 8705 Train loss: 0.098798 Train acc: 0.961667\n",
      "Epoch: 967/1000 Iteration: 8710 Train loss: 0.105392 Train acc: 0.951667\n",
      "Epoch: 968/1000 Iteration: 8715 Train loss: 0.099122 Train acc: 0.960000\n",
      "Epoch: 968/1000 Iteration: 8720 Train loss: 0.104208 Train acc: 0.966667\n",
      "Epoch: 969/1000 Iteration: 8725 Train loss: 0.131158 Train acc: 0.943333\n",
      "Epoch: 969/1000 Iteration: 8725 Validation loss: 0.104602 Validation acc: 0.954444\n",
      "Epoch: 969/1000 Iteration: 8730 Train loss: 0.106007 Train acc: 0.963333\n",
      "Epoch: 970/1000 Iteration: 8735 Train loss: 0.102578 Train acc: 0.951667\n",
      "Epoch: 971/1000 Iteration: 8740 Train loss: 0.089198 Train acc: 0.961667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 971/1000 Iteration: 8745 Train loss: 0.087068 Train acc: 0.963333\n",
      "Epoch: 972/1000 Iteration: 8750 Train loss: 0.100597 Train acc: 0.960000\n",
      "Epoch: 972/1000 Iteration: 8750 Validation loss: 0.108658 Validation acc: 0.953333\n",
      "Epoch: 972/1000 Iteration: 8755 Train loss: 0.090181 Train acc: 0.963333\n",
      "Epoch: 973/1000 Iteration: 8760 Train loss: 0.107542 Train acc: 0.963333\n",
      "Epoch: 973/1000 Iteration: 8765 Train loss: 0.082469 Train acc: 0.973333\n",
      "Epoch: 974/1000 Iteration: 8770 Train loss: 0.125524 Train acc: 0.948333\n",
      "Epoch: 974/1000 Iteration: 8775 Train loss: 0.107201 Train acc: 0.956667\n",
      "Epoch: 974/1000 Iteration: 8775 Validation loss: 0.104967 Validation acc: 0.954444\n",
      "Epoch: 975/1000 Iteration: 8780 Train loss: 0.103808 Train acc: 0.956667\n",
      "Epoch: 976/1000 Iteration: 8785 Train loss: 0.101687 Train acc: 0.951667\n",
      "Epoch: 976/1000 Iteration: 8790 Train loss: 0.085602 Train acc: 0.966667\n",
      "Epoch: 977/1000 Iteration: 8795 Train loss: 0.098654 Train acc: 0.963333\n",
      "Epoch: 977/1000 Iteration: 8800 Train loss: 0.098432 Train acc: 0.965000\n",
      "Epoch: 977/1000 Iteration: 8800 Validation loss: 0.110653 Validation acc: 0.951667\n",
      "Epoch: 978/1000 Iteration: 8805 Train loss: 0.112808 Train acc: 0.953333\n",
      "Epoch: 978/1000 Iteration: 8810 Train loss: 0.080989 Train acc: 0.966667\n",
      "Epoch: 979/1000 Iteration: 8815 Train loss: 0.122805 Train acc: 0.945000\n",
      "Epoch: 979/1000 Iteration: 8820 Train loss: 0.121246 Train acc: 0.946667\n",
      "Epoch: 980/1000 Iteration: 8825 Train loss: 0.097315 Train acc: 0.963333\n",
      "Epoch: 980/1000 Iteration: 8825 Validation loss: 0.107041 Validation acc: 0.952778\n",
      "Epoch: 981/1000 Iteration: 8830 Train loss: 0.103605 Train acc: 0.951667\n",
      "Epoch: 981/1000 Iteration: 8835 Train loss: 0.083846 Train acc: 0.965000\n",
      "Epoch: 982/1000 Iteration: 8840 Train loss: 0.111481 Train acc: 0.961667\n",
      "Epoch: 982/1000 Iteration: 8845 Train loss: 0.089780 Train acc: 0.970000\n",
      "Epoch: 983/1000 Iteration: 8850 Train loss: 0.096453 Train acc: 0.965000\n",
      "Epoch: 983/1000 Iteration: 8850 Validation loss: 0.108102 Validation acc: 0.952778\n",
      "Epoch: 983/1000 Iteration: 8855 Train loss: 0.075390 Train acc: 0.968333\n",
      "Epoch: 984/1000 Iteration: 8860 Train loss: 0.117742 Train acc: 0.943333\n",
      "Epoch: 984/1000 Iteration: 8865 Train loss: 0.107837 Train acc: 0.955000\n",
      "Epoch: 985/1000 Iteration: 8870 Train loss: 0.105234 Train acc: 0.955000\n",
      "Epoch: 986/1000 Iteration: 8875 Train loss: 0.085465 Train acc: 0.970000\n",
      "Epoch: 986/1000 Iteration: 8875 Validation loss: 0.106650 Validation acc: 0.955555\n",
      "Epoch: 986/1000 Iteration: 8880 Train loss: 0.083431 Train acc: 0.970000\n",
      "Epoch: 987/1000 Iteration: 8885 Train loss: 0.090374 Train acc: 0.963333\n",
      "Epoch: 987/1000 Iteration: 8890 Train loss: 0.100808 Train acc: 0.960000\n",
      "Epoch: 988/1000 Iteration: 8895 Train loss: 0.109544 Train acc: 0.951667\n",
      "Epoch: 988/1000 Iteration: 8900 Train loss: 0.075696 Train acc: 0.973333\n",
      "Epoch: 988/1000 Iteration: 8900 Validation loss: 0.108752 Validation acc: 0.954444\n",
      "Epoch: 989/1000 Iteration: 8905 Train loss: 0.114843 Train acc: 0.945000\n",
      "Epoch: 989/1000 Iteration: 8910 Train loss: 0.102820 Train acc: 0.955000\n",
      "Epoch: 990/1000 Iteration: 8915 Train loss: 0.104212 Train acc: 0.956667\n",
      "Epoch: 991/1000 Iteration: 8920 Train loss: 0.099445 Train acc: 0.956667\n",
      "Epoch: 991/1000 Iteration: 8925 Train loss: 0.080417 Train acc: 0.966667\n",
      "Epoch: 991/1000 Iteration: 8925 Validation loss: 0.108342 Validation acc: 0.955555\n",
      "Epoch: 992/1000 Iteration: 8930 Train loss: 0.092246 Train acc: 0.965000\n",
      "Epoch: 992/1000 Iteration: 8935 Train loss: 0.086267 Train acc: 0.965000\n",
      "Epoch: 993/1000 Iteration: 8940 Train loss: 0.102990 Train acc: 0.956667\n",
      "Epoch: 993/1000 Iteration: 8945 Train loss: 0.083404 Train acc: 0.971667\n",
      "Epoch: 994/1000 Iteration: 8950 Train loss: 0.121738 Train acc: 0.946667\n",
      "Epoch: 994/1000 Iteration: 8950 Validation loss: 0.107991 Validation acc: 0.954444\n",
      "Epoch: 994/1000 Iteration: 8955 Train loss: 0.113507 Train acc: 0.950000\n",
      "Epoch: 995/1000 Iteration: 8960 Train loss: 0.096215 Train acc: 0.965000\n",
      "Epoch: 996/1000 Iteration: 8965 Train loss: 0.101455 Train acc: 0.955000\n",
      "Epoch: 996/1000 Iteration: 8970 Train loss: 0.076059 Train acc: 0.971667\n",
      "Epoch: 997/1000 Iteration: 8975 Train loss: 0.092005 Train acc: 0.965000\n",
      "Epoch: 997/1000 Iteration: 8975 Validation loss: 0.106196 Validation acc: 0.957778\n",
      "Epoch: 997/1000 Iteration: 8980 Train loss: 0.088670 Train acc: 0.960000\n",
      "Epoch: 998/1000 Iteration: 8985 Train loss: 0.104014 Train acc: 0.945000\n",
      "Epoch: 998/1000 Iteration: 8990 Train loss: 0.075535 Train acc: 0.971667\n",
      "Epoch: 999/1000 Iteration: 8995 Train loss: 0.126129 Train acc: 0.948333\n",
      "Epoch: 999/1000 Iteration: 9000 Train loss: 0.106734 Train acc: 0.960000\n",
      "Epoch: 999/1000 Iteration: 9000 Validation loss: 0.106181 Validation acc: 0.952778\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # Initialize \n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, \n",
    "                    initial_state : state, learning_rate_ : learning_rate}\n",
    "            \n",
    "            loss, _ , state, acc = sess.run([cost, optimizer, final_state, accuracy], \n",
    "                                             feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 25 iterations\n",
    "            if (iteration%25 == 0):\n",
    "                \n",
    "                # Initiate for validation set\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0, initial_state : val_state}\n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, state_v, acc_v = sess.run([cost, final_state, accuracy], feed_dict = feed)\n",
    "                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints/har-lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAF3CAYAAAC2bHyQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2866c1d7c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 25 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2866c1d7e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 25 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\har-lstm.ckpt\n",
      "Test accuracy: 0.876667\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1,\n",
    "                initial_state: test_state}\n",
    "        \n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
